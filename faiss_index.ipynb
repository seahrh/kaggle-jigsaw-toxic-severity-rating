{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997680ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T01:16:01.519669Z",
     "iopub.status.busy": "2021-08-19T01:16:01.516812Z",
     "iopub.status.idle": "2021-08-19T01:16:05.587561Z",
     "shell.execute_reply": "2021-08-19T01:16:05.587858Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pathlib\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Any\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2278a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', em_active=['paraphrase-MiniLM-L6-v2'], em_models={'paraphrase-MiniLM-L6-v2': ModelConf(directory='pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2', max_seq_length=128, batch_size=1000), 'all-MiniLM-L6-v2': ModelConf(directory='pretrained\\\\sentence-transformers\\\\all-MiniLM-L6-v2', max_seq_length=256, batch_size=512), 'all-mpnet-base-v2': ModelConf(directory='pretrained/sentence-transformers/all-mpnet-base-v2', max_seq_length=384, batch_size=128)}, search_d_max=1.5, search_c=50, search_k=100, search_nlist=1000, search_index_file='output/ruddit.index')\n",
      "device=0, NVIDIA GeForce GTX 1060 6GB\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class ModelConf(NamedTuple):\n",
    "    directory: str\n",
    "    max_seq_length: int\n",
    "    batch_size: int\n",
    "\n",
    "\n",
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    em_active: List[str] = [\"paraphrase-MiniLM-L6-v2\"]\n",
    "    em_models: Dict[str, ModelConf] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": ModelConf(\n",
    "            directory=f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "            max_seq_length=128,\n",
    "            batch_size=1000,\n",
    "        ),\n",
    "        \"all-MiniLM-L6-v2\": ModelConf(\n",
    "            directory=str(pathlib.Path(f\"{pretrained_dir}sentence-transformers/all-MiniLM-L6-v2\")),\n",
    "            max_seq_length=256,\n",
    "            batch_size=512,\n",
    "        ),\n",
    "        \"all-mpnet-base-v2\": ModelConf(\n",
    "            directory=f\"{pretrained_dir}sentence-transformers/all-mpnet-base-v2\",\n",
    "            max_seq_length=384,\n",
    "            batch_size=128,\n",
    "        ),\n",
    "    }\n",
    "    search_d_max: float = 1.5\n",
    "    search_c: int = 50\n",
    "    search_k: int = 100\n",
    "    search_nlist: int = 1000\n",
    "    search_index_file: str = \"output/ruddit.index\"\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8f5b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T01:16:08.631503Z",
     "iopub.status.busy": "2021-08-19T01:16:08.631181Z",
     "iopub.status.idle": "2021-08-19T01:16:08.632651Z",
     "shell.execute_reply": "2021-08-19T01:16:08.632960Z"
    }
   },
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25528a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   5710 non-null   int32  \n",
      " 1   bws     5710 non-null   float32\n",
      " 2   worker  5710 non-null   int8   \n",
      " 3   text    5710 non-null   object \n",
      " 4   text1   5710 non-null   object \n",
      " 5   text2   5710 non-null   object \n",
      " 6   text3   5710 non-null   object \n",
      "dtypes: float32(1), int32(1), int8(1), object(4)\n",
      "memory usage: 228.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/pre_ruddit.parquet\")\n",
    "bws = list(df[\"bws\"])\n",
    "ruddit_text2 = list(df[\"text2\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3921d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14251 entries, 0 to 14250\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    14251 non-null  object\n",
      " 1   text1   14251 non-null  object\n",
      " 2   text2   14251 non-null  object\n",
      " 3   text3   14251 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 445.5+ KB\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_parquet(\"input/pre_val.parquet\")\n",
    "val_text = list(val_df[\"text\"])\n",
    "val_text2 = list(val_df[\"text2\"])\n",
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160ff0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186644 entries, 0 to 186643\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   worker  186644 non-null  int8  \n",
      " 1   text    186644 non-null  object\n",
      " 2   text1   186644 non-null  object\n",
      " 3   text2   186644 non-null  object\n",
      " 4   text3   186644 non-null  object\n",
      "dtypes: int8(1), object(4)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "js18_df = pd.read_parquet(\"input/pre_js18.parquet\")\n",
    "js18_text2 = list(js18_df[\"text2\"])\n",
    "js18_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b43c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-02-06 14:01:19,255 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-02-06 14:01:19,255 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-02-06 14:01:19,255 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-02-06 14:01:19,255 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebba1663bef4ec89e12812c6ff34414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(206605, 384)\n",
      "ruddit_em.shape=(5710, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_em.shape=(14251, 384)\n",
      "js18_em.shape=(186644, 384)\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = ruddit_text2 + val_text2 + js18_text2\n",
    "for name in conf.em_active:\n",
    "    print(name)\n",
    "    model = SentenceTransformer(conf.em_models[name].directory, device=conf.device)\n",
    "    model.max_seq_length = conf.em_models[name].max_seq_length\n",
    "    em = model.encode(sentences=sentences, \n",
    "                      batch_size=conf.em_models[name].batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "    print(f\"em.shape={em.shape}\")\n",
    "    faiss.normalize_L2(em)\n",
    "    cols = [f\"{name}_{i:04d}\" for i in range(em.shape[1])]\n",
    "    ruddit_em = em[:len(df)]\n",
    "    print(f\"ruddit_em.shape={ruddit_em.shape}\")\n",
    "    df[cols] = ruddit_em\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    i = len(df)\n",
    "    val_em = em[i:i + len(val_df)]\n",
    "    print(f\"val_em.shape={val_em.shape}\")\n",
    "    val_df[cols] = val_em\n",
    "    val_df[cols] = val_df[cols].astype(np.float32)\n",
    "    i += len(val_df)\n",
    "    js18_em = em[i:i + len(js18_df)]\n",
    "    print(f\"js18_em.shape={js18_em.shape}\")\n",
    "    js18_df[cols] = js18_em\n",
    "    js18_df[cols] = js18_df[cols].astype(np.float32)\n",
    "    del model\n",
    "    gc.collect()\n",
    "em_cols = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd3cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 824 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet(\"output/em_ruddit.parquet\", index=False)\n",
    "val_df.to_parquet(\"output/em_val.parquet\", index=False)\n",
    "del df, val_df, sentences\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e229058",
   "metadata": {},
   "source": [
    "# Ruddit dataset\n",
    "- Seed dataset with BWS label\n",
    "- Generate embeddings\n",
    "- Build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4808815b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T03:32:37.293316Z",
     "iopub.status.busy": "2021-08-19T03:32:37.292956Z",
     "iopub.status.idle": "2021-08-19T03:44:33.918014Z",
     "shell.execute_reply": "2021-08-19T03:44:33.918333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 921 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = ruddit_em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)  # this remains the same\n",
    "index = faiss.IndexIVFPQ(quantizer, d, conf.search_nlist, m, 8)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index.verbose = True\n",
    "index.train(ruddit_em)\n",
    "index.add(ruddit_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a108f9bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T03:44:33.923028Z",
     "iopub.status.busy": "2021-08-19T03:44:33.922697Z",
     "iopub.status.idle": "2021-08-19T03:44:34.523183Z",
     "shell.execute_reply": "2021-08-19T03:44:34.522831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss.write_index(index, conf.search_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d81663e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T03:44:34.526195Z",
     "iopub.status.busy": "2021-08-19T03:44:34.525870Z",
     "iopub.status.idle": "2021-08-19T03:44:34.845463Z",
     "shell.execute_reply": "2021-08-19T03:44:34.845735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntotal=5710, is_trained=True\n",
      "Wall time: 26.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = faiss.read_index(conf.search_index_file)\n",
    "print(f\"ntotal={index.ntotal}, is_trained={index.is_trained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd762189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T03:44:34.848901Z",
     "iopub.status.busy": "2021-08-19T03:44:34.848508Z",
     "iopub.status.idle": "2021-08-19T03:44:34.859771Z",
     "shell.execute_reply": "2021-08-19T03:44:34.860032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I=array([[   0,    5,    4, 2886],\n",
      "       [   1, 4966, 3859, 1648],\n",
      "       [   2,    7, 3918,   16],\n",
      "       [   3,   23, 3783,  881],\n",
      "       [   4,   31, 3903,   10],\n",
      "       [   5,   10, 2694, 3903],\n",
      "       [   6, 1818,  316,   -1],\n",
      "       [   7,    2,   16, 3905],\n",
      "       [   8,   12, 1693,   18],\n",
      "       [   9,  563, 2454, 2451],\n",
      "       [  10,    4, 2694,    5],\n",
      "       [  11,   16,    7,    2],\n",
      "       [  12,    8, 2890,   18],\n",
      "       [  13, 2443, 5021, 5626],\n",
      "       [  14,   26,   33, 3913],\n",
      "       [  15, 3135, 3515, 3130],\n",
      "       [  16,   11,    7,    2],\n",
      "       [  17,   19,   30, 3917],\n",
      "       [  18,    8,  194, 3914],\n",
      "       [  19,   30, 3917, 1446]], dtype=int64)\n",
      "D=array([[4.3200651e-01, 6.8623567e-01, 6.9459498e-01, 7.3324448e-01],\n",
      "       [4.5601249e-01, 8.4324878e-01, 8.6190856e-01, 9.0924489e-01],\n",
      "       [2.2245908e-01, 2.9274365e-01, 4.3219829e-01, 4.6194434e-01],\n",
      "       [3.1575781e-01, 5.9827942e-01, 6.0513955e-01, 6.4260429e-01],\n",
      "       [2.5046504e-01, 4.3624276e-01, 4.3940505e-01, 4.5014071e-01],\n",
      "       [3.4714153e-01, 6.1827552e-01, 6.1982763e-01, 6.2784570e-01],\n",
      "       [3.1673640e-01, 7.0801121e-01, 7.0892423e-01, 3.4028235e+38],\n",
      "       [2.4430148e-01, 3.2127157e-01, 4.9147990e-01, 5.0237554e-01],\n",
      "       [1.8763758e-01, 3.6073241e-01, 3.6162835e-01, 3.8031042e-01],\n",
      "       [3.2598114e-01, 6.1278725e-01, 6.4480782e-01, 6.5091956e-01],\n",
      "       [2.9347646e-01, 4.8144823e-01, 5.1644796e-01, 5.2014470e-01],\n",
      "       [4.0097132e-01, 6.3855052e-01, 6.7772138e-01, 6.9741821e-01],\n",
      "       [2.8624368e-01, 4.3935418e-01, 4.4642523e-01, 5.0779593e-01],\n",
      "       [4.3796036e-01, 6.7040902e-01, 6.8486327e-01, 7.9984045e-01],\n",
      "       [3.0450088e-01, 5.7280058e-01, 5.9080720e-01, 6.4901495e-01],\n",
      "       [4.7927040e-01, 7.8313875e-01, 8.1538785e-01, 8.4787005e-01],\n",
      "       [3.9407945e-01, 6.6635561e-01, 6.7628235e-01, 6.7669648e-01],\n",
      "       [3.1769678e-01, 5.0289762e-01, 5.1445335e-01, 5.5156612e-01],\n",
      "       [2.4197364e-01, 4.4945037e-01, 4.6514913e-01, 4.7279292e-01],\n",
      "       [2.4591143e-01, 3.4466153e-01, 3.9564544e-01, 4.2601711e-01]],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 1\n",
    "k = 4\n",
    "distances, ids = index.search(ruddit_em[:20], k)  # sanity check\n",
    "print(f\"I={repr(ids)}\\nD={repr(distances)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d7a32",
   "metadata": {},
   "source": [
    "# Validation dataset\n",
    "- Estimate BWS label based on kNN similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3162a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I=array([[2013, 5191, 5448, 2850, 4644, 5449, 2512, 4735, 5418, 2024, 3990,\n",
      "        3839, 3622, 3640, 3356, 2838, 4625, 4231, 2267, 2016, 3995, 2196,\n",
      "        4353, 5534, 3204, 5072, 2438, 5296, 1799, 1984, 4655, 3741, 5052,\n",
      "        2121, 4551, 4693, 3079,  798, 5502, 3384, 2425, 2844, 4340, 4306,\n",
      "        2379, 1476, 2336, 4531, 1484, 4529, 2009, 2123, 2333, 2354, 4506,\n",
      "        5687, 2161,  342,   87, 4654, 1500, 2489, 4089,  189, 3077, 3487,\n",
      "         343, 5539, 1980, 2055,  660, 3181, 2259, 1685, 3703, 4889, 4630,\n",
      "        2007, 5600, 5517,  530, 2406, 5258, 3215, 4891, 2120, 3126, 2430,\n",
      "        2796, 2461, 3366, 4290, 1707, 4631, 2019,  555, 5338, 4394, 4451,\n",
      "        2124],\n",
      "       [1993, 2603, 4865, 3462, 2602, 3463, 3591, 3461, 1985, 4123, 2482,\n",
      "        2339, 2500, 2902, 2137, 3483, 2738, 3691, 2258, 2133, 2833, 2751,\n",
      "        3569, 2494, 3986, 3267, 2333, 2594, 2151, 1987, 4643, 2188, 3142,\n",
      "        3589, 4317, 3337, 3249, 2336, 3747, 2300, 3558, 3587, 2120, 4412,\n",
      "        3413, 2596, 4667, 3425, 3319, 2918, 2737, 2317, 2042, 3044, 3430,\n",
      "        3861, 5154, 3474, 2597, 4578, 2755, 2588, 3467, 3329, 1464, 4573,\n",
      "        3260, 4669, 2547, 1805, 3481, 4621, 2589, 2746, 3608, 2493, 2750,\n",
      "        5482, 3535, 3321,  918, 2128, 2740, 2314, 3786, 2134, 3466, 3324,\n",
      "        2468, 3424, 5270, 3269, 4745, 3236, 3697, 2298, 4893, 2324, 5211,\n",
      "        4998],\n",
      "       [2186, 5239, 3001, 5497,  680, 2066,  725, 2409, 1503, 4957,  342,\n",
      "        2221, 3097, 4278, 5526, 2440, 5678, 4483, 5310, 1577,  210, 4491,\n",
      "         558,  841, 3158, 2269, 4593, 3375, 2431, 4925,  487, 3286, 5603,\n",
      "        3487, 4761, 2230, 2420, 1593,  457,  343, 2422,  718, 5132,  458,\n",
      "        4812, 4431, 5643, 4343, 5073, 3416, 5410, 1748, 4698, 1799, 2116,\n",
      "        4903, 3489, 2337, 5131, 5038, 4729, 1294,  654, 2993, 5568, 5464,\n",
      "        4820,  472, 2268, 3014, 5021, 4535,  861,  736, 1275, 3383, 4014,\n",
      "        5626, 4921, 4607,  488, 2236, 1710,  806, 3035,  436, 4603,  771,\n",
      "        5133, 1271, 5037, 1303,  802, 2187, 3794, 2824, 1484, 5683,  200,\n",
      "        4154],\n",
      "       [2067, 3948, 5142,  832, 3765,  289, 2760, 5094, 3702, 1231, 5055,\n",
      "        4569, 2920,  305, 1200,  273, 3631,  830, 2466,  275, 5067, 2743,\n",
      "        5087, 1206, 2658, 1207, 5472,  835, 2073, 4969, 5096,  842, 4238,\n",
      "        3954, 4057, 3448, 1036, 5380, 3935, 2699, 2075, 3226, 1639, 1869,\n",
      "        4134, 1553, 1554, 3794, 2286, 1018, 2777, 2788, 1030, 1129, 4661,\n",
      "        1191, 2802, 4237, 4963, 3789, 5377, 2668, 1371, 4923, 1583, 1303,\n",
      "        3431,  279,  153, 4848,  283,  297, 3266, 5075, 5374,  788, 1257,\n",
      "        2768,  294,  680, 4927, 1173, 3433, 3412, 1185, 3951,  280, 1198,\n",
      "         529,  848, 1176, 4795, 3833,  291,  737, 1208, 3774,  310,  163,\n",
      "        1659],\n",
      "       [1503, 2337, 3356, 5418, 2830, 4735, 4017, 2430, 4943, 3852, 1561,\n",
      "        4442, 5321, 3215, 5475, 3327, 2259, 5632, 3247, 4278, 5653, 4654,\n",
      "        1396, 1382, 4625, 3077, 5624, 3204, 2183, 3211, 1982, 1483, 5348,\n",
      "        2911, 2035, 2844, 2427, 1365, 1484, 5052, 4665, 5007, 4429, 1710,\n",
      "        3559, 4337, 4630, 2044, 4657, 5076, 2761, 3097, 5456,  431, 4638,\n",
      "        2153, 5213, 3986, 3487, 2425, 2796, 1984, 5449, 3422, 4013, 5363,\n",
      "        1924, 3326, 5073, 1515, 3438, 1360, 1501, 1617, 5338, 2381, 1375,\n",
      "        4231, 2208, 5672, 4631, 5243,  798, 2325, 5167, 2221,  782, 2440,\n",
      "        3021, 4581, 2467, 3842, 1861, 1232, 2163, 4483,  538, 3198, 2438,\n",
      "        4041]], dtype=int64)\n",
      "D=array([[0.77765644, 0.78265536, 0.788769  , 0.7927439 , 0.7934243 ,\n",
      "        0.7997074 , 0.8111062 , 0.81239307, 0.81712973, 0.8289469 ,\n",
      "        0.8310975 , 0.8330785 , 0.83527595, 0.83548295, 0.84297127,\n",
      "        0.8444843 , 0.84842896, 0.8505047 , 0.8530753 , 0.8539642 ,\n",
      "        0.8571842 , 0.85788864, 0.8587132 , 0.8600451 , 0.86057955,\n",
      "        0.8628492 , 0.86800814, 0.869774  , 0.87189245, 0.87292063,\n",
      "        0.87517864, 0.87692285, 0.87736374, 0.87813073, 0.8793297 ,\n",
      "        0.8793632 , 0.8816788 , 0.88216156, 0.8828446 , 0.8828834 ,\n",
      "        0.8857713 , 0.8873214 , 0.890309  , 0.89202774, 0.8957947 ,\n",
      "        0.8994725 , 0.9026242 , 0.9032626 , 0.90475833, 0.9048366 ,\n",
      "        0.90494984, 0.9076055 , 0.9077169 , 0.90847594, 0.9115112 ,\n",
      "        0.91270185, 0.91293734, 0.9131802 , 0.91496885, 0.9152731 ,\n",
      "        0.916044  , 0.92039955, 0.9251423 , 0.9289621 , 0.9301671 ,\n",
      "        0.9306689 , 0.93125397, 0.9313321 , 0.9330069 , 0.9336957 ,\n",
      "        0.93380195, 0.93414116, 0.93430734, 0.93436706, 0.934782  ,\n",
      "        0.9358959 , 0.9360791 , 0.9366601 , 0.9378283 , 0.93857145,\n",
      "        0.93943685, 0.939756  , 0.94071794, 0.942151  , 0.94251424,\n",
      "        0.94297045, 0.9431916 , 0.94385874, 0.94471633, 0.9462599 ,\n",
      "        0.9468726 , 0.94838583, 0.9484539 , 0.94866616, 0.95094573,\n",
      "        0.95318013, 0.95373654, 0.95393085, 0.9546474 , 0.95587486],\n",
      "       [1.1257701 , 1.1278027 , 1.1306387 , 1.1309291 , 1.1390477 ,\n",
      "        1.1390567 , 1.1406192 , 1.14608   , 1.1479311 , 1.1482079 ,\n",
      "        1.1497815 , 1.1522155 , 1.1565229 , 1.1566538 , 1.1596596 ,\n",
      "        1.1630788 , 1.1634053 , 1.1662531 , 1.169078  , 1.1743102 ,\n",
      "        1.1764065 , 1.1823732 , 1.1834341 , 1.1836809 , 1.1840634 ,\n",
      "        1.1906621 , 1.1906794 , 1.1915462 , 1.1927495 , 1.194923  ,\n",
      "        1.1986513 , 1.1987344 , 1.1989561 , 1.199179  , 1.2014049 ,\n",
      "        1.2022704 , 1.2036264 , 1.2038221 , 1.2038403 , 1.2060553 ,\n",
      "        1.2062247 , 1.2075372 , 1.2075796 , 1.2094778 , 1.2098304 ,\n",
      "        1.2100247 , 1.2108535 , 1.2127131 , 1.213199  , 1.2140172 ,\n",
      "        1.2149667 , 1.2156249 , 1.2197123 , 1.2201505 , 1.2203617 ,\n",
      "        1.2206975 , 1.2207879 , 1.2234476 , 1.2254598 , 1.2258053 ,\n",
      "        1.2261112 , 1.2272621 , 1.2272813 , 1.2282186 , 1.2285696 ,\n",
      "        1.2323519 , 1.2336283 , 1.2354709 , 1.2375036 , 1.2383733 ,\n",
      "        1.2437905 , 1.2446345 , 1.2447702 , 1.2451007 , 1.2462838 ,\n",
      "        1.2493321 , 1.2504816 , 1.2505972 , 1.2507385 , 1.2512746 ,\n",
      "        1.2513462 , 1.2520247 , 1.2530174 , 1.254164  , 1.2555363 ,\n",
      "        1.2560313 , 1.2561847 , 1.2576004 , 1.2591708 , 1.2616324 ,\n",
      "        1.2618366 , 1.26311   , 1.2641666 , 1.2653606 , 1.2668827 ,\n",
      "        1.268122  , 1.2687492 , 1.2694547 , 1.272748  , 1.273738  ],\n",
      "       [0.9446285 , 0.9821432 , 0.9904949 , 0.99379456, 1.0013918 ,\n",
      "        1.0116769 , 1.0138898 , 1.0161415 , 1.0161666 , 1.0175827 ,\n",
      "        1.0219682 , 1.0226467 , 1.0271926 , 1.0292661 , 1.0331402 ,\n",
      "        1.0332917 , 1.0337367 , 1.0346572 , 1.0387095 , 1.0420327 ,\n",
      "        1.042239  , 1.045078  , 1.0456944 , 1.0465848 , 1.0476283 ,\n",
      "        1.0502243 , 1.0504882 , 1.0507706 , 1.0513606 , 1.0534961 ,\n",
      "        1.0537667 , 1.0559862 , 1.0563304 , 1.0566454 , 1.0569766 ,\n",
      "        1.0578631 , 1.0580664 , 1.0590556 , 1.0603935 , 1.060425  ,\n",
      "        1.0629897 , 1.0633203 , 1.063388  , 1.0637231 , 1.0639579 ,\n",
      "        1.0641928 , 1.0659567 , 1.0661869 , 1.0684326 , 1.0697263 ,\n",
      "        1.0717266 , 1.071984  , 1.0729613 , 1.0732063 , 1.0746962 ,\n",
      "        1.0768572 , 1.0781342 , 1.0782479 , 1.0783823 , 1.0786092 ,\n",
      "        1.0795406 , 1.0799761 , 1.0808481 , 1.0813977 , 1.0817612 ,\n",
      "        1.0819184 , 1.0824062 , 1.0827504 , 1.0843462 , 1.0876119 ,\n",
      "        1.0882518 , 1.088416  , 1.0886344 , 1.088681  , 1.0894213 ,\n",
      "        1.0896189 , 1.0903947 , 1.0912486 , 1.0915213 , 1.0917239 ,\n",
      "        1.0918882 , 1.0923783 , 1.0927012 , 1.0929154 , 1.0930511 ,\n",
      "        1.094115  , 1.0944731 , 1.0946618 , 1.0948868 , 1.0953714 ,\n",
      "        1.0966378 , 1.0973601 , 1.0980136 , 1.0982845 , 1.0996208 ,\n",
      "        1.1005764 , 1.1019738 , 1.1037239 , 1.1045285 , 1.1048492 ],\n",
      "       [0.86414176, 0.87400293, 0.91943246, 0.92211056, 0.926638  ,\n",
      "        0.9294769 , 0.9298959 , 0.9359511 , 0.94261914, 0.9464347 ,\n",
      "        0.9556664 , 0.9788329 , 0.9830757 , 0.99233603, 0.99813026,\n",
      "        1.0018739 , 1.0035324 , 1.0040796 , 1.008616  , 1.0095363 ,\n",
      "        1.0142055 , 1.0202122 , 1.0215946 , 1.023394  , 1.0237672 ,\n",
      "        1.0245135 , 1.0261482 , 1.0262841 , 1.026614  , 1.0322309 ,\n",
      "        1.0330985 , 1.034964  , 1.0353006 , 1.0373471 , 1.0380062 ,\n",
      "        1.0388652 , 1.0398607 , 1.0438787 , 1.0476164 , 1.0498737 ,\n",
      "        1.0516584 , 1.0518315 , 1.0535842 , 1.0564885 , 1.0592957 ,\n",
      "        1.0598757 , 1.0612512 , 1.061864  , 1.0638059 , 1.0666744 ,\n",
      "        1.0737853 , 1.0739894 , 1.0754051 , 1.0781146 , 1.0803127 ,\n",
      "        1.0804288 , 1.0817168 , 1.0847533 , 1.0857543 , 1.0868449 ,\n",
      "        1.0888902 , 1.0889058 , 1.0918665 , 1.0931882 , 1.0972402 ,\n",
      "        1.0975457 , 1.0979731 , 1.099187  , 1.0998955 , 1.101019  ,\n",
      "        1.1018986 , 1.1022366 , 1.1049796 , 1.106493  , 1.1065775 ,\n",
      "        1.1071879 , 1.1074545 , 1.1146078 , 1.1148655 , 1.1169075 ,\n",
      "        1.1197695 , 1.1200821 , 1.1209304 , 1.1209525 , 1.121345  ,\n",
      "        1.1217189 , 1.1220843 , 1.1225412 , 1.1231326 , 1.1242659 ,\n",
      "        1.1290454 , 1.1301721 , 1.1323317 , 1.1323583 , 1.1328254 ,\n",
      "        1.1331823 , 1.1333407 , 1.135802  , 1.1358451 , 1.1358941 ],\n",
      "       [0.8906063 , 0.90630364, 0.92433405, 0.9245105 , 0.9286981 ,\n",
      "        0.9309145 , 0.9373356 , 0.9416735 , 0.9430215 , 0.9431859 ,\n",
      "        0.9432857 , 0.94768035, 0.95049304, 0.9579699 , 0.9606622 ,\n",
      "        0.9610243 , 0.96541595, 0.9687691 , 0.971627  , 0.9755997 ,\n",
      "        0.97893906, 0.98030335, 0.98185414, 0.98325926, 0.98648727,\n",
      "        0.9874265 , 0.98823404, 0.9896158 , 0.9908891 , 0.9909601 ,\n",
      "        0.9955807 , 0.99767685, 0.99902225, 1.0014696 , 1.0030975 ,\n",
      "        1.0084352 , 1.0097795 , 1.0101745 , 1.0113089 , 1.0115982 ,\n",
      "        1.0125177 , 1.0137758 , 1.013815  , 1.0151666 , 1.015733  ,\n",
      "        1.0212322 , 1.0215023 , 1.0230879 , 1.0232248 , 1.0236332 ,\n",
      "        1.0246879 , 1.026673  , 1.027615  , 1.0276904 , 1.0299273 ,\n",
      "        1.032913  , 1.0335381 , 1.0353241 , 1.0356672 , 1.0357873 ,\n",
      "        1.0369812 , 1.0380845 , 1.0383133 , 1.0384415 , 1.039349  ,\n",
      "        1.0410315 , 1.0420469 , 1.0420597 , 1.0425391 , 1.0427902 ,\n",
      "        1.0427998 , 1.0438213 , 1.0459684 , 1.0463821 , 1.0480638 ,\n",
      "        1.0500835 , 1.0503855 , 1.0511264 , 1.0521455 , 1.0524461 ,\n",
      "        1.053785  , 1.0567493 , 1.0604284 , 1.0604738 , 1.0606115 ,\n",
      "        1.0637276 , 1.0638791 , 1.0669384 , 1.067505  , 1.0679369 ,\n",
      "        1.0686344 , 1.0688467 , 1.0693852 , 1.0716554 , 1.0724784 ,\n",
      "        1.0726255 , 1.0732527 , 1.0748396 , 1.0749385 , 1.0779022 ]],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = conf.search_c\n",
    "distances, ids = index.search(val_em, conf.search_k)  # sanity check\n",
    "lim = 5\n",
    "print(f\"I={repr(ids[:lim])}\\nD={repr(distances[:lim])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b0ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "i=0, \" Go rot in hell you evil liittle bastard. \" \"\n",
      "j=0, > or speaking ill of the country. Gods not sending you to hell because you said \"America [sucks; be very bad or unpleasant]!\"\n",
      "j=1, Evil? No, you are not evil. The absolute worst thing anyone could say about you is that you are a selfish, moral blank whose lazy cynicism and sneering, ironic take on the world encapsulates everything wrong with a generation.\n",
      "j=2, And may you rot in hell my good sir for no one is good enough for heaven not even you delusional folks.\n",
      "j=3, that line low-key broke my faith that Americans had any semblance of shame. For God's sake he is advocating collective punishment and the wholesale slaughter of women and children whose only crime is they are RELATED TO BAD GUYS. The Yemen raid made me want to cry, we killed an eight year old girl.\n",
      "j=4, [Dude; friend] would shake his baby to hell\n",
      "========\n",
      "i=1, Bamafuck has to be stopped. Please help me keep the Styx pages integ intact!\n",
      "j=0, Gaunt's Ghosts -series of Warhammer 40k -lore. Band of brothers meets starship troopers. Wonderful drama, action and humor.\n",
      "j=1, On the bright side at least they are playing that Ekko remix...During the second break...\n",
      "j=2, I was not referring to that article at all!I was frustrated not being able to get on and go to where I wanted to go!As far as site's!It was like try again 10 minutes?When I want something I want it now!And that happened all the time!That and over again asking for my password???I ran out of passwords!And my email I gave 10 times I bet!As I said I lost my temper and I guess I do not know what I am doing!!I apologize!\n",
      "j=3, Just checked them out and i quite like their music, will be looking into them thanks!\n",
      "j=4, it is sad to say but I think this finally the year that Yellowstar misses Worlds. RIP RECORD\n",
      "========\n",
      "i=2, Image tagging Look mate, what IS your problem with where images come from? They make wikipedia a better place, regardless of source (and for the record I think that ALL of my images qualify as fair use). you are actually working against everything that is good about wikipedia, systematically going after people and questioning everything they do. Who told you to do this? Why take the 'law' into your own hands? Ask yourself this: who are you protecting? You want to play cops and robbers, go and joing the freaking police. Do something useful, rather than wasting your life on here. What is your job? Cos this are not real life buddy, and if its your only hobby, I feel bad for you. I mean really bad. I thinks it is quite sad that your only reason for using wikipedia is to actively reverse what other people do, rather than to actively create content. I will review all the images you 'helpfully' tagged for me, but I am getting real tired of you ducking me man. Peace out.\n",
      "j=0, I look at [porn; pornography], cats and cat [porn; pornography]. I feel like I am using it wrong\n",
      "j=1, Youre in private mode? Cmon OP you couldnt have posted this on a different website? No instead you got to advertise your website with a stupid pay wall system to make me read the rest of the article? You can go fuck yourself OP\n",
      "j=2, Shoot the modmail a photo of your recruiter business cards with your PII blacked out and your username on it.\n",
      "j=3, But muh blah. People like yourself have no real defense to anything because you are always wrong so you attack. Enjoy the party for the next 6 years. I know I will be.\n",
      "j=4, With the sheer amount of content the site has, it is probably really fucking expensive to run it .\n",
      "========\n",
      "i=3, \" Well I used to work up at the mall for a store (which has since closed), and I know all the inside \"\"dirt\"\" as to why nobody wants to bring any new business, industry, or stores here. I cannot get into the specific details (that is an entirely different topic), but I can tell you that the entire mall has been a money loser for several years now. Cambridge Shopping Centers has placed it up for sale time and time again. Nobody wants it, and I do not blame them. If Sears ever decides to pull out of there, they might as shut the entire place down and bulldoze it, because the land is worth more than the mall itself. Everything is going Northside anyway. Downtown Chatham has been a cesspool ever since the recession of the 90's, and it never fully recovered. And the Capitol Theatre? Give me a break. They might as well give up on that too. it is been what? Over ten years now, and after all the time and money that was [pissed; to be drunk or made very annoyed] away on that thing, we stil are not any closer to it being finished, or having a final completion date. As far as Chatham as a city goes, I have never seen so many unsavoury, shady people in my life. Not everyone is like that, I agree, but yes it would seem as though Chatham does qualify as the welfare capitol ontario. Drugs, unwed mothers, crackheads, dropouts, second and third generation \"\"welfare families\",\" a plethora of health problems, and well you get the pitcure. Is it any wonder why the younger crowd is leaving in droves? I cannot say that I blame them. The grass IS greener on the other side. Chatham's prime was over a long time ago. it is London and points East that you want to be...\"\n",
      "j=0, People who hold up the line at the grocery store with bags of change and mounds of coupons.\n",
      "j=1, what is the big deal? If a store does not offer you the level of customer satisfaction you demand you think you can get a better experience somewhere else then go for it, shop elsewhere. it is capitalism. Not too hard. I respect Walgreens for allowing their employees the latitude to work without compromising their principles. That takes guts and shows appreciation for their employees as people. Walgreens is a first rate store. They even pay you money for getting in shape. How awesome is that? Balance rewards for healthy choices. Check it out. I have made over $40 from it. I wish all stores were that cool. Only drugstore I will use.\n",
      "j=2, I do not think you understand. If a company goes bankrupt they do not have any say on where their money goes. Even if they wanted to sell their remaining assets and spend the money on clean-up, it would not be allowed. From now on (in Canada) it will actually be mandatory. That in turn scares off investors, because if the company they invest in goes bankrupt there is an even lower chance of them seeing any of their money back.\n",
      "j=3, Well... Recently amazon opened a development branch in my area, and they published job listings offering way above market value. There are maaany people living very nicely thanks to amazon.\n",
      "j=4, No fuck no. I work in the film industry and deal with rich people (celebrities and actors). No, they have raging parties and get entitled more than average person. If they are renting it, they will care LESS about it because it is not their responsibility! They do not care if they get damage deposits back, that is toilet paper money to them. They are probably more likely to trash a place. Even if they pay for the damage, now you have to deal with fixing it. Ugh. The sweet spot would be people who are middle income and trying to build a nest egg of their own for buying property. People who actually want damage deposits back when they move out.\n",
      "========\n",
      "i=4, \" January 3, 2007 Joe Beaudoin Jr. ANOTHER performer (a REAL superstar) who you did not immediatly revert back to lies and delusions. Thanks? (For keeping the/MY corrections. [BTW; by the way]: that comes from the word \"\"correct!\"\") WOW, you have TWO, so far! This [porn; pornography] area is SO perfect. (I ask you, again, why does Angela Oliver get special protection and her total fabrications remain as gospel?) \"\n",
      "j=0, Fuck, you are hilarious, but you are also a dick. But do not worry, I have learned from my early mistakes, I know my limits. There is no \"Should have done\" though, hindsight does not roll in the real world. Young me was a [twat; profanity for a woman's vagina], older me, less so.\n",
      "j=1, Who the heck gilded you?\n",
      "j=2, Father: Oh hell [naw; no], you gon have to catch me!\n",
      "j=3, The person who shoots. Jesus fuck.\n",
      "j=4, Two questions 1) Why does this cock get so much news coverage? 2) Why does not he just shut the fuck up?\n"
     ]
    }
   ],
   "source": [
    "for i in range(ids[:lim].shape[0]):\n",
    "    print(f\"========\\ni={i}, {val_text2[i]}\")\n",
    "    for j in range(lim):\n",
    "        if ids[i][j] == -1:\n",
    "            continue\n",
    "        print(f\"j={j}, {ruddit_text2[ids[i][j]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc0852f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 14251/14251 [00:07<00:00, 2034.37it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "for i in tqdm(range(ids.shape[0])):\n",
    "    v = 0\n",
    "    sims = []\n",
    "    for j in range(ids.shape[1]):\n",
    "        if ids[i][j] == -1 or distances[i][j] >= conf.search_d_max:\n",
    "            break\n",
    "        d_norm = distances[i][j] / conf.search_d_max\n",
    "        sims.append(1 - d_norm)\n",
    "    sm = sum(sims)\n",
    "    for j, s in enumerate(sims):\n",
    "        v += s / sm * bws[ids[i][j]] \n",
    "    preds[val_text[i]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8fd7283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30108 entries, 0 to 30107\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   worker      30108 non-null  int64 \n",
      " 1   less_toxic  30108 non-null  object\n",
      " 2   more_toxic  30108 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 705.8+ KB\n"
     ]
    }
   ],
   "source": [
    "vdf = pd.read_csv(\"input/validation_data.csv\", engine=\"c\", low_memory=False)\n",
    "vdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a27b9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Agreement with Annotators=0.6498\n"
     ]
    }
   ],
   "source": [
    "score = mylib.comp_metric(preds, validation_data=vdf)\n",
    "print(f\"Average Agreement with Annotators={score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73537142",
   "metadata": {},
   "source": [
    "# Jigsaw 2018 dataset\n",
    "- Pseudo labelling: weighted BWS score based on kNN similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a439300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I=array([[ 641, 2162,  676,  652,  927,  651,  647, 2899, 5569, 4669,  646,\n",
      "        3044, 4252, 2404,  679,  452,  667,  663,  639,  732,  126, 5130,\n",
      "        3788, 5692, 2394, 3806, 3986,  659,  653,  662, 5655, 1297, 5595,\n",
      "        4743,  655, 1449, 3842, 1113,  497, 3683,  669,  678, 2755, 2411,\n",
      "        4670,  494,  489, 1547, 2431, 3789, 2596, 3012, 2750,  668, 5384,\n",
      "        3604,  658, 1303, 2904, 3457, 2063, 2372, 2444, 2455,  538, 5512,\n",
      "         675, 2898,  648, 3587, 2470, 3926, 4718, 2415,  650, 4963,  666,\n",
      "         487, 3591, 2975, 2422, 2151,  471,  470,  664, 2463,  640, 3024,\n",
      "        4758, 3699, 4413,  453, 4383, 5308,  657, 4605, 2442,  654, 3499,\n",
      "        2255],\n",
      "       [3069,  431, 3063, 4337, 3326, 5634, 5122, 5509, 1019, 3961, 3187,\n",
      "        5272, 5164, 2793, 3748, 2163, 3956, 5709, 3959, 3420, 4285, 3026,\n",
      "        3028, 3013, 3421, 3626, 4757, 4581, 4722, 5120, 2485, 1382, 3327,\n",
      "        1543, 5124, 3596, 2606, 5242, 2893, 1451, 5339, 4631, 1533,  960,\n",
      "        5220, 2672, 4628, 4654, 5338, 3646, 3077, 3289, 2498, 4571, 1479,\n",
      "        2801, 1969, 1448, 4624, 3313, 3156, 3348, 4191, 1550, 5422, 2408,\n",
      "        5100, 5432, 2680, 3361, 4394, 3070, 2980, 4577, 4442, 3644, 2726,\n",
      "        2509, 4612, 4758, 4516, 1545, 4899, 4723, 2723, 1292, 5119, 4672,\n",
      "        5141, 5696, 5053, 3845, 4635, 2117, 1722, 2956, 1636, 4625, 2157,\n",
      "        2023],\n",
      "       [ 939, 1297,  527, 5524, 5420, 1386,  927, 2911, 3798, 1365, 5213,\n",
      "        5525, 3793,  653, 1979, 3796, 5357, 5693, 1449,  652,  669,  402,\n",
      "        3777, 2431, 5526, 5243, 5259,  946, 2594, 2695,  646, 3786, 2121,\n",
      "        3147, 4234, 5303,  639,  677, 1364,  333, 2062, 3141, 5612, 5483,\n",
      "        3635, 5049, 5641, 3160, 4718, 5480,  679, 5310, 3158, 2427,  651,\n",
      "         984, 4824, 5244, 4773, 2236, 5251, 5384, 3144, 2230, 1182, 1932,\n",
      "        5691, 4648, 5639,  667, 5687, 5265,  313, 5342, 2471, 3393, 4043,\n",
      "        5063,  348, 1644, 3375,  790, 5696, 5307, 5309,  661, 4252, 5519,\n",
      "        5150, 5026, 2944, 5530, 3185, 5299,  324, 1360, 2596,  314,  281,\n",
      "         403],\n",
      "       [3375, 3158,  538, 1297, 2431, 5626, 4967, 5632,  148, 3796, 4718,\n",
      "        1362, 5349,  167,  324, 5384, 5600, 4423, 5019, 1361, 3184, 3227,\n",
      "        4426, 2230,  150, 2404, 4820, 5599, 1396, 5357, 4453, 1376, 2269,\n",
      "        3386, 4962, 4959, 2236, 3932, 4541,  790, 5348,  469, 5021, 2443,\n",
      "        4441,  780, 4260, 5445, 4924,  999, 3992,  796, 2835, 1359,  785,\n",
      "         408,  732,   13, 3383, 1414, 5444,  550, 4861, 1883, 4968,  358,\n",
      "         470,  497, 5313, 3149,  967, 2227,  128, 5076, 4413, 2575,  326,\n",
      "        3393,  578, 3604, 4903, 5314, 5596, 5239, 1644,  652,  533, 1134,\n",
      "        4698,  641,  718, 4220, 3994, 2888, 5342, 5595, 1371,  473,  487,\n",
      "        2394],\n",
      "       [ 940,  247,  941, 4461,  954,  926,  931,  943,  956,  929, 1096,\n",
      "         482,  366, 1310,  242, 3920, 5005,  261, 4510,  934,  257,  882,\n",
      "         485,  922,  920,  256, 5046, 4500, 3971,  263, 3902, 1112,  977,\n",
      "         228, 5185,  953, 4052, 5172,  484,  245,   95, 3901,  915,  469,\n",
      "         910,   53,  938,  936, 5532, 2002,  754, 4968, 4906, 4075,  494,\n",
      "         423,  233, 1644,  470,  253,   13,  948,  951,  478,  483,   96,\n",
      "         455,  140, 4556, 3977,  952, 4594, 2835,  914, 5626, 5324,  452,\n",
      "        3899,   51,  458, 4739,  250, 3875, 5342, 1092, 5599, 5365,  942,\n",
      "        4541, 3184,  937,  222,  786,  358, 4151,  487,  775, 2879, 2599,\n",
      "        2230]], dtype=int64)\n",
      "D=array([[0.8773361 , 0.9031817 , 0.92488307, 0.9798186 , 0.99935097,\n",
      "        1.0114393 , 1.0189738 , 1.0216228 , 1.0241148 , 1.029805  ,\n",
      "        1.0334314 , 1.0480199 , 1.0601723 , 1.069243  , 1.0703382 ,\n",
      "        1.0741873 , 1.0781786 , 1.0797611 , 1.0802656 , 1.0808611 ,\n",
      "        1.0836828 , 1.0876429 , 1.0965216 , 1.0967778 , 1.1023343 ,\n",
      "        1.1026521 , 1.1033112 , 1.103461  , 1.1047128 , 1.1049044 ,\n",
      "        1.1061399 , 1.1093882 , 1.1101989 , 1.1118472 , 1.1136366 ,\n",
      "        1.1150947 , 1.1204692 , 1.1209724 , 1.1220508 , 1.1229205 ,\n",
      "        1.1234028 , 1.1241856 , 1.1272887 , 1.1288607 , 1.1295075 ,\n",
      "        1.1300267 , 1.1304185 , 1.1312952 , 1.1317538 , 1.1325331 ,\n",
      "        1.1344734 , 1.1350173 , 1.1356987 , 1.1360329 , 1.1366826 ,\n",
      "        1.1375062 , 1.1388503 , 1.1392976 , 1.1426488 , 1.1430726 ,\n",
      "        1.1436818 , 1.1445341 , 1.1446828 , 1.1449261 , 1.1458224 ,\n",
      "        1.146461  , 1.146616  , 1.1477286 , 1.149333  , 1.1507124 ,\n",
      "        1.1516651 , 1.1517358 , 1.1520365 , 1.1531272 , 1.1541245 ,\n",
      "        1.154416  , 1.1571513 , 1.157576  , 1.1576692 , 1.1593313 ,\n",
      "        1.1596127 , 1.16276   , 1.165659  , 1.1662331 , 1.1669562 ,\n",
      "        1.1703029 , 1.1705422 , 1.1706402 , 1.1716425 , 1.1740934 ,\n",
      "        1.1741234 , 1.1751006 , 1.1760193 , 1.1788175 , 1.178866  ,\n",
      "        1.181631  , 1.183182  , 1.1880924 , 1.1887802 , 1.1889291 ],\n",
      "       [0.88819003, 0.89393634, 0.93463814, 0.9394394 , 0.94023746,\n",
      "        0.94335544, 0.9615389 , 0.9708852 , 0.9790727 , 0.98002607,\n",
      "        0.988904  , 0.9907615 , 0.99862105, 1.0010916 , 1.0013374 ,\n",
      "        1.0047942 , 1.0093162 , 1.0176567 , 1.0199147 , 1.0229186 ,\n",
      "        1.0293168 , 1.0319829 , 1.0419217 , 1.0426693 , 1.0457228 ,\n",
      "        1.0458837 , 1.0466366 , 1.0467128 , 1.0476348 , 1.0493133 ,\n",
      "        1.0495564 , 1.0500259 , 1.0522403 , 1.0573893 , 1.0616869 ,\n",
      "        1.06251   , 1.0643265 , 1.0667744 , 1.0668461 , 1.0682138 ,\n",
      "        1.0702436 , 1.0751703 , 1.0810916 , 1.0824386 , 1.0869797 ,\n",
      "        1.0889491 , 1.0894836 , 1.0898551 , 1.0935755 , 1.0952225 ,\n",
      "        1.0960141 , 1.0966088 , 1.09699   , 1.0981522 , 1.0982432 ,\n",
      "        1.100284  , 1.1008664 , 1.1034669 , 1.1047157 , 1.1056768 ,\n",
      "        1.1061188 , 1.1066201 , 1.1066533 , 1.1066834 , 1.1085169 ,\n",
      "        1.10967   , 1.1099671 , 1.1118095 , 1.1133813 , 1.1147997 ,\n",
      "        1.1169356 , 1.1173267 , 1.1195943 , 1.1196963 , 1.1225467 ,\n",
      "        1.1251093 , 1.1262783 , 1.1301415 , 1.1315161 , 1.1319532 ,\n",
      "        1.1333162 , 1.1336678 , 1.1336889 , 1.1377393 , 1.1392444 ,\n",
      "        1.14073   , 1.1407834 , 1.141222  , 1.1415461 , 1.1415949 ,\n",
      "        1.1439978 , 1.1445525 , 1.1458232 , 1.1469713 , 1.147554  ,\n",
      "        1.1504794 , 1.1511103 , 1.1513767 , 1.1526624 , 1.1544129 ],\n",
      "       [0.93802524, 1.0257063 , 1.0290642 , 1.0297216 , 1.0323992 ,\n",
      "        1.0416905 , 1.0424687 , 1.0425359 , 1.0495013 , 1.0525609 ,\n",
      "        1.0553538 , 1.0559886 , 1.0587156 , 1.0594827 , 1.0612347 ,\n",
      "        1.0650201 , 1.0688765 , 1.0709481 , 1.0780374 , 1.0806535 ,\n",
      "        1.0844887 , 1.0867411 , 1.0886608 , 1.0927962 , 1.0933418 ,\n",
      "        1.0940046 , 1.095401  , 1.097383  , 1.0994552 , 1.1009384 ,\n",
      "        1.1023779 , 1.1028421 , 1.1033559 , 1.1057216 , 1.1066822 ,\n",
      "        1.1085728 , 1.1086229 , 1.1099644 , 1.110651  , 1.1110835 ,\n",
      "        1.1136134 , 1.1151218 , 1.116572  , 1.1176903 , 1.1185338 ,\n",
      "        1.1191132 , 1.120145  , 1.125506  , 1.1261481 , 1.1290927 ,\n",
      "        1.129281  , 1.1312219 , 1.1316644 , 1.132503  , 1.1350559 ,\n",
      "        1.1350809 , 1.1365895 , 1.1370375 , 1.1413229 , 1.1421419 ,\n",
      "        1.1428709 , 1.1428787 , 1.1443092 , 1.1465235 , 1.1474025 ,\n",
      "        1.147842  , 1.148145  , 1.1483059 , 1.148636  , 1.14969   ,\n",
      "        1.1520395 , 1.1531656 , 1.1537044 , 1.1552303 , 1.1576566 ,\n",
      "        1.1609839 , 1.1613086 , 1.1613798 , 1.1619352 , 1.162333  ,\n",
      "        1.163102  , 1.1631627 , 1.1647826 , 1.1664672 , 1.1666629 ,\n",
      "        1.1678828 , 1.1680022 , 1.1684494 , 1.169873  , 1.1703101 ,\n",
      "        1.1711293 , 1.1722401 , 1.1732275 , 1.1734247 , 1.1737916 ,\n",
      "        1.1744316 , 1.1752931 , 1.1768129 , 1.1768252 , 1.1780512 ],\n",
      "       [0.829034  , 0.8291517 , 0.8383083 , 0.8572227 , 0.91331565,\n",
      "        0.9136812 , 0.91427994, 0.9228061 , 0.9245001 , 0.9263016 ,\n",
      "        0.92701805, 0.92885673, 0.94246423, 0.94501877, 0.9458405 ,\n",
      "        0.94601214, 0.95035315, 0.95119596, 0.9615119 , 0.96245265,\n",
      "        0.9627521 , 0.9656138 , 0.9723191 , 0.97296935, 0.97571254,\n",
      "        0.97589064, 0.98213583, 0.9827768 , 0.9838196 , 0.98414254,\n",
      "        0.9878806 , 0.9892634 , 0.9894771 , 0.9920812 , 0.9955896 ,\n",
      "        0.9964377 , 0.99756056, 0.99959755, 1.0022612 , 1.0030936 ,\n",
      "        1.0107566 , 1.0112636 , 1.0115175 , 1.0152018 , 1.0168066 ,\n",
      "        1.019478  , 1.0199776 , 1.0208313 , 1.0243726 , 1.026224  ,\n",
      "        1.0306628 , 1.0310379 , 1.0322511 , 1.0333722 , 1.0350155 ,\n",
      "        1.0389552 , 1.0393606 , 1.0397718 , 1.0400776 , 1.0405091 ,\n",
      "        1.0421231 , 1.0429593 , 1.0438899 , 1.0465506 , 1.047044  ,\n",
      "        1.047743  , 1.0480033 , 1.0480173 , 1.0490098 , 1.0490736 ,\n",
      "        1.0498935 , 1.0500295 , 1.0503362 , 1.0505942 , 1.051012  ,\n",
      "        1.0526447 , 1.0528123 , 1.053465  , 1.0539753 , 1.055011  ,\n",
      "        1.0552301 , 1.0556858 , 1.0569311 , 1.0572968 , 1.0590943 ,\n",
      "        1.0595453 , 1.0608897 , 1.0621753 , 1.063445  , 1.0638671 ,\n",
      "        1.0639673 , 1.0659102 , 1.067164  , 1.0692121 , 1.0700034 ,\n",
      "        1.0707936 , 1.0710998 , 1.0722466 , 1.0725411 , 1.0728003 ],\n",
      "       [0.7409966 , 0.8350545 , 0.8718936 , 0.8755113 , 0.8788638 ,\n",
      "        0.8841846 , 0.8896621 , 0.8999655 , 0.90458524, 0.91759   ,\n",
      "        0.9202765 , 0.94307834, 0.9431806 , 0.9596194 , 0.96058345,\n",
      "        0.9627205 , 0.9627755 , 0.96324664, 0.97853714, 0.98157144,\n",
      "        0.98232985, 0.9826114 , 0.9827797 , 0.9855607 , 0.9890482 ,\n",
      "        0.995034  , 0.99625546, 0.9965963 , 0.9977057 , 1.0015231 ,\n",
      "        1.0017241 , 1.0053014 , 1.0109037 , 1.0110639 , 1.0145297 ,\n",
      "        1.0156001 , 1.0170927 , 1.0225111 , 1.0246996 , 1.027506  ,\n",
      "        1.0392994 , 1.04089   , 1.0417488 , 1.0423905 , 1.0435746 ,\n",
      "        1.0473536 , 1.0505496 , 1.0505977 , 1.0536143 , 1.054352  ,\n",
      "        1.0549234 , 1.0581516 , 1.0596201 , 1.0643842 , 1.0659711 ,\n",
      "        1.0679102 , 1.0679553 , 1.0690073 , 1.0725713 , 1.0752281 ,\n",
      "        1.0770793 , 1.078738  , 1.079525  , 1.0816257 , 1.0816795 ,\n",
      "        1.0816928 , 1.0828316 , 1.0831835 , 1.0843859 , 1.0874213 ,\n",
      "        1.0875342 , 1.0881133 , 1.0915722 , 1.0926552 , 1.0931201 ,\n",
      "        1.0934362 , 1.0942783 , 1.0944312 , 1.0965482 , 1.0969024 ,\n",
      "        1.0972675 , 1.0991852 , 1.0992417 , 1.0998114 , 1.1018916 ,\n",
      "        1.1026671 , 1.1027694 , 1.1029229 , 1.1040252 , 1.1060995 ,\n",
      "        1.1066242 , 1.1068382 , 1.1082206 , 1.1095922 , 1.1101207 ,\n",
      "        1.1114125 , 1.1133056 , 1.1149702 , 1.115138  , 1.1161623 ]],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = conf.search_c\n",
    "distances, ids = index.search(js18_em, conf.search_k)  # sanity check\n",
    "lim = 5\n",
    "print(f\"I={repr(ids[:lim])}\\nD={repr(distances[:lim])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94d116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "i=0, Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They were not vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please do not remove the template from the talk page since I am retired now.\n",
      "j=0, Just to give a different view. From a modding perspective, the redesign finally adds, or is in the process of adding, a lot of native tools that help make moderation a lot easier for new [mods; forum moderator]. You do not have to be a CSS wizard now to set up a good looking subreddit. There are native removal reasons that will hopefully end up in mobile apps instead of being a computer only feature from toolbox. Flair filtering is finally happening. Posting requirements will work properly instead of having Automod remove posts and comments. Yes, there a lot of complaints from [mods; forum moderator] about the redesign, but the improvements made by admins over the past few months have been incredible and show that they are listening to feedback. Just check /r/redesign weekly and you will see.\n",
      "j=1, lowkey salty the [mods; forum moderator] removed this thread due to breaking rule 3. thanks though for anyone that joined in before it was removed and put in great content\n",
      "j=2, What I was expecting with the redesign was purely a change of color scheme to orange, and maybe some of the boxes/graphics have differently shaped contours/gradients. However I was fully expecting everything to remain pretty much the same place. I really would not have been opposed it. I actually like the orange color scheme over blue (Not that it would matter for night mode).\n",
      "j=3, Yes, it probably could have. However, I would put a lot of money down on it being a lot more difficult to implement, taking a lot longer to arrive, and some of the solutions being more of a workaround than if they were built in from the start. For admins, it is a two birds with one stone situation. Update [mod; forum moderator] tools and make the site more user friendly to new people and [mods; forum moderator]. Also, it still is in beta. If there is something you do not like, post it to redesign with why you do not like it and how you think it should be changed. If you have followed the redesign from the start, there have been a lot of big and small improvements that come from redditors providing feedback. it is come a long way and it still has a ways to go, but I feel optimistic.\n",
      "j=4, You should update your original text to reflect, or you will keep getting the same argument over and over.\n",
      "========\n",
      "i=1, D'[aww; expression of endearment or affection]! He matches this background colour I am seemingly stuck with. Thanks. (talk) 21:51, January 11, 2016 (UTC)\n",
      "j=0, Not only that, but he is clearly stifling laughter.\n",
      "j=1, Just had my post removed for speaking truth . [Lmao; laughing my ass off] (grinning face with smiling eyes)\n",
      "j=2, He has that little chuckle and then gets right into the character [lmao; laughing my ass off]\n",
      "j=3, Beautiful. Just beautiful. His sincerity is apparent both from the writing style and lack of spelling errors.\n",
      "j=4, I see you too are a man of culture [Wink or smirk]\n",
      "========\n",
      "i=2, Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "j=0, That is a shame that OP has to edit his post in order to keep people from talking about something he never mentioned.\n",
      "j=1, I really like how this post has changed from CMV to \"shit on the racist, xenophobic, transphobic, homophobic, (...) [cunt; profanity for a woman's vagina]! he is a bigot! I am going to put words in his mouth!\" I think I will stop replying to comments like yours from now.\n",
      "j=2, How about they report the news, instead of figuring out the best way to manipulate it?\n",
      "j=3, Fuck this [libtard; liberal retard; slur for a person with left-wing political views] page all it does is complaining about Trump and not actual world politics\n",
      "j=4, I would start by not clicking on things that make me upset. there is plenty to look at, why get bent out of shape over a political cartoon? We can all just go to another thread about how much of a blubbering moron Trump is and actually have context for it. This nothing more than a circle jerk, I might find it amusing, but here is a jerk for everyone, we should look for it together! Like I just opened pol and there is a post about Trump ramping up his lies from 60 to 100 a week. We can go over there and talk. Or just keep getting mad at a cartoon.\n",
      "========\n",
      "i=3, Your vandalism to the Matt Shirvington article has been reverted. Please do not do it again, or you will be banned.\n",
      "j=0, As a reminder, this subreddit [is for civil discussion.] (/r/politics/[wiki; a website or database developed collaboratively by an online community]/index#wiki_be_civil) In general, be courteous to others. Attack ideas, not users. Personal insults, [shill; a person engaged in covert advertising] or troll accusations, hate speech, **any** advocating or wishing death/physical harm, and other rule violations can result in a permanent ban. If you see comments in violation of our rules, please report them. *** *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit] (/message/compose/?to [Skeptical, annoyed, undecided, uneasy or hesitant] r/politics) if you have any questions or concerns.*\n",
      "j=1, As a reminder, this subreddit [is for civil discussion.] (/r/politics/[wiki; a website or database developed collaboratively by an online community]/index#wiki_be_civil) In general, be courteous to others. Attack ideas, not users. Personal insults, [shill; a person engaged in covert advertising] or troll accusations, hate speech, and other incivility violations can result in a permanent ban. If you see comments in violation of our rules, please report them. *** *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit] (/message/compose/?to [Skeptical, annoyed, undecided, uneasy or hesitant] r/politics) if you have any questions or concerns.*\n",
      "j=2, yep, sorry. i think where you lost me was \"pressuring\" which read like censorship to me.\n",
      "j=3, I really like how this post has changed from CMV to \"shit on the racist, xenophobic, transphobic, homophobic, (...) [cunt; profanity for a woman's vagina]! he is a bigot! I am going to put words in his mouth!\" I think I will stop replying to comments like yours from now.\n",
      "j=4, How is 'being PC' a circlejerk? it is just being polite and generally thoughtful of others. What he is suggesting is pointing out why they are being dicks at IGTHFT by making them the target of the offensive jokes.\n",
      "========\n",
      "i=4, Sorry if the word 'nonse' was offensive to you. Anyway, I am not intending to write anything in the article (wow they would jump on me for vandalism), I am merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it is almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics?\n",
      "j=0, Well I am a human. Which is animal... many humans breed even when they have genetic defects. Eugenics is exactly the forced prevention of specific people from breeding. In our context, those who find certain varieties of human superior, think those other forms have genetic defects... thus Eugenics is also the presence of laws preventing defect based breeding (all of this on a philosophical level just in case you take offense) yet we pretty much agree eugenics is bad. On a more real life example. The border collie is exceptionally smart. It was bred for specific traits, some of them come with defects. Yet it ended up making a magnificently efficient sheep herder. Good comes with the bad. Even if the word *selective* is *subjective*\n",
      "j=1, Your comment on the Nazis drawing a false moral equivalence between ideology fueled eugenics and not wanting more kids to be born with rare genetic disorders. I think that genetic testing and discouraging two people with recessive disorders from breeding would be a good thing, and not all comparable to nazi beliefs if racial purity and superiority. That being said, if siblings wanted to have a baby, it should be required that they take blood samples to\n",
      "j=2, This law would be impossible to pass and even harder to enforce as ALL animals have genetic defects. To be living is to have genetic defects.\n",
      "j=3, Enough hiding, fire up the annihilator gene\n",
      "j=4, Every living thing everywhere has a \"genetic defect.\" Right now, you have at least one half of a gene that, if activated in your children, would lead to disastrous results. If you have a kid with someone, they also put in that kid's genetic code at least half of at least one disease that you would never want to have. it is only when the genes are \"active\" that we see the disease. This why inbreeding is so dangerous, and why homogeneous ethnic groups are at great risk for some diseases and at lower risk for others. If you want to ban selectively breeding based on this, you would have to ban all breeding in general.\n"
     ]
    }
   ],
   "source": [
    "for i in range(ids[:lim].shape[0]):\n",
    "    print(f\"========\\ni={i}, {js18_text2[i]}\")\n",
    "    for j in range(lim):\n",
    "        if ids[i][j] == -1:\n",
    "            continue\n",
    "        print(f\"j={j}, {ruddit_text2[ids[i][j]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d10148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 186644/186644 [01:31<00:00, 2046.42it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(ids.shape[0])):\n",
    "    v = 0\n",
    "    sims = []\n",
    "    for j in range(ids.shape[1]):\n",
    "        if ids[i][j] == -1 or distances[i][j] >= conf.search_d_max:\n",
    "            break\n",
    "        d_norm = distances[i][j] / conf.search_d_max\n",
    "        sims.append(1 - d_norm)\n",
    "    sm = sum(sims)\n",
    "    for j, s in enumerate(sims):\n",
    "        v += s / sm * bws[ids[i][j]] \n",
    "    preds.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63653c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    186644.000000\n",
       "mean         -0.025723\n",
       "std           0.126421\n",
       "min          -0.457159\n",
       "1%           -0.290170\n",
       "5%           -0.212564\n",
       "10%          -0.170844\n",
       "20%          -0.123635\n",
       "30%          -0.091432\n",
       "40%          -0.064997\n",
       "50%          -0.039428\n",
       "60%          -0.011678\n",
       "70%           0.020655\n",
       "80%           0.065970\n",
       "90%           0.141055\n",
       "95%           0.208229\n",
       "99%           0.347912\n",
       "max           0.533427\n",
       "Name: bws, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"bws\"\n",
    "js18_df[col] = preds\n",
    "js18_df[col] = js18_df[col].astype(np.float32)\n",
    "js18_df[col].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706aecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186644 entries, 0 to 186643\n",
      "Data columns (total 390 columns):\n",
      " #    Column                        Non-Null Count   Dtype  \n",
      "---   ------                        --------------   -----  \n",
      " 0    bws                           186644 non-null  float32\n",
      " 1    worker                        186644 non-null  int8   \n",
      " 2    text                          186644 non-null  object \n",
      " 3    text1                         186644 non-null  object \n",
      " 4    text2                         186644 non-null  object \n",
      " 5    text3                         186644 non-null  object \n",
      " 6    paraphrase-MiniLM-L6-v2_0000  186644 non-null  float32\n",
      " 7    paraphrase-MiniLM-L6-v2_0001  186644 non-null  float32\n",
      " 8    paraphrase-MiniLM-L6-v2_0002  186644 non-null  float32\n",
      " 9    paraphrase-MiniLM-L6-v2_0003  186644 non-null  float32\n",
      " 10   paraphrase-MiniLM-L6-v2_0004  186644 non-null  float32\n",
      " 11   paraphrase-MiniLM-L6-v2_0005  186644 non-null  float32\n",
      " 12   paraphrase-MiniLM-L6-v2_0006  186644 non-null  float32\n",
      " 13   paraphrase-MiniLM-L6-v2_0007  186644 non-null  float32\n",
      " 14   paraphrase-MiniLM-L6-v2_0008  186644 non-null  float32\n",
      " 15   paraphrase-MiniLM-L6-v2_0009  186644 non-null  float32\n",
      " 16   paraphrase-MiniLM-L6-v2_0010  186644 non-null  float32\n",
      " 17   paraphrase-MiniLM-L6-v2_0011  186644 non-null  float32\n",
      " 18   paraphrase-MiniLM-L6-v2_0012  186644 non-null  float32\n",
      " 19   paraphrase-MiniLM-L6-v2_0013  186644 non-null  float32\n",
      " 20   paraphrase-MiniLM-L6-v2_0014  186644 non-null  float32\n",
      " 21   paraphrase-MiniLM-L6-v2_0015  186644 non-null  float32\n",
      " 22   paraphrase-MiniLM-L6-v2_0016  186644 non-null  float32\n",
      " 23   paraphrase-MiniLM-L6-v2_0017  186644 non-null  float32\n",
      " 24   paraphrase-MiniLM-L6-v2_0018  186644 non-null  float32\n",
      " 25   paraphrase-MiniLM-L6-v2_0019  186644 non-null  float32\n",
      " 26   paraphrase-MiniLM-L6-v2_0020  186644 non-null  float32\n",
      " 27   paraphrase-MiniLM-L6-v2_0021  186644 non-null  float32\n",
      " 28   paraphrase-MiniLM-L6-v2_0022  186644 non-null  float32\n",
      " 29   paraphrase-MiniLM-L6-v2_0023  186644 non-null  float32\n",
      " 30   paraphrase-MiniLM-L6-v2_0024  186644 non-null  float32\n",
      " 31   paraphrase-MiniLM-L6-v2_0025  186644 non-null  float32\n",
      " 32   paraphrase-MiniLM-L6-v2_0026  186644 non-null  float32\n",
      " 33   paraphrase-MiniLM-L6-v2_0027  186644 non-null  float32\n",
      " 34   paraphrase-MiniLM-L6-v2_0028  186644 non-null  float32\n",
      " 35   paraphrase-MiniLM-L6-v2_0029  186644 non-null  float32\n",
      " 36   paraphrase-MiniLM-L6-v2_0030  186644 non-null  float32\n",
      " 37   paraphrase-MiniLM-L6-v2_0031  186644 non-null  float32\n",
      " 38   paraphrase-MiniLM-L6-v2_0032  186644 non-null  float32\n",
      " 39   paraphrase-MiniLM-L6-v2_0033  186644 non-null  float32\n",
      " 40   paraphrase-MiniLM-L6-v2_0034  186644 non-null  float32\n",
      " 41   paraphrase-MiniLM-L6-v2_0035  186644 non-null  float32\n",
      " 42   paraphrase-MiniLM-L6-v2_0036  186644 non-null  float32\n",
      " 43   paraphrase-MiniLM-L6-v2_0037  186644 non-null  float32\n",
      " 44   paraphrase-MiniLM-L6-v2_0038  186644 non-null  float32\n",
      " 45   paraphrase-MiniLM-L6-v2_0039  186644 non-null  float32\n",
      " 46   paraphrase-MiniLM-L6-v2_0040  186644 non-null  float32\n",
      " 47   paraphrase-MiniLM-L6-v2_0041  186644 non-null  float32\n",
      " 48   paraphrase-MiniLM-L6-v2_0042  186644 non-null  float32\n",
      " 49   paraphrase-MiniLM-L6-v2_0043  186644 non-null  float32\n",
      " 50   paraphrase-MiniLM-L6-v2_0044  186644 non-null  float32\n",
      " 51   paraphrase-MiniLM-L6-v2_0045  186644 non-null  float32\n",
      " 52   paraphrase-MiniLM-L6-v2_0046  186644 non-null  float32\n",
      " 53   paraphrase-MiniLM-L6-v2_0047  186644 non-null  float32\n",
      " 54   paraphrase-MiniLM-L6-v2_0048  186644 non-null  float32\n",
      " 55   paraphrase-MiniLM-L6-v2_0049  186644 non-null  float32\n",
      " 56   paraphrase-MiniLM-L6-v2_0050  186644 non-null  float32\n",
      " 57   paraphrase-MiniLM-L6-v2_0051  186644 non-null  float32\n",
      " 58   paraphrase-MiniLM-L6-v2_0052  186644 non-null  float32\n",
      " 59   paraphrase-MiniLM-L6-v2_0053  186644 non-null  float32\n",
      " 60   paraphrase-MiniLM-L6-v2_0054  186644 non-null  float32\n",
      " 61   paraphrase-MiniLM-L6-v2_0055  186644 non-null  float32\n",
      " 62   paraphrase-MiniLM-L6-v2_0056  186644 non-null  float32\n",
      " 63   paraphrase-MiniLM-L6-v2_0057  186644 non-null  float32\n",
      " 64   paraphrase-MiniLM-L6-v2_0058  186644 non-null  float32\n",
      " 65   paraphrase-MiniLM-L6-v2_0059  186644 non-null  float32\n",
      " 66   paraphrase-MiniLM-L6-v2_0060  186644 non-null  float32\n",
      " 67   paraphrase-MiniLM-L6-v2_0061  186644 non-null  float32\n",
      " 68   paraphrase-MiniLM-L6-v2_0062  186644 non-null  float32\n",
      " 69   paraphrase-MiniLM-L6-v2_0063  186644 non-null  float32\n",
      " 70   paraphrase-MiniLM-L6-v2_0064  186644 non-null  float32\n",
      " 71   paraphrase-MiniLM-L6-v2_0065  186644 non-null  float32\n",
      " 72   paraphrase-MiniLM-L6-v2_0066  186644 non-null  float32\n",
      " 73   paraphrase-MiniLM-L6-v2_0067  186644 non-null  float32\n",
      " 74   paraphrase-MiniLM-L6-v2_0068  186644 non-null  float32\n",
      " 75   paraphrase-MiniLM-L6-v2_0069  186644 non-null  float32\n",
      " 76   paraphrase-MiniLM-L6-v2_0070  186644 non-null  float32\n",
      " 77   paraphrase-MiniLM-L6-v2_0071  186644 non-null  float32\n",
      " 78   paraphrase-MiniLM-L6-v2_0072  186644 non-null  float32\n",
      " 79   paraphrase-MiniLM-L6-v2_0073  186644 non-null  float32\n",
      " 80   paraphrase-MiniLM-L6-v2_0074  186644 non-null  float32\n",
      " 81   paraphrase-MiniLM-L6-v2_0075  186644 non-null  float32\n",
      " 82   paraphrase-MiniLM-L6-v2_0076  186644 non-null  float32\n",
      " 83   paraphrase-MiniLM-L6-v2_0077  186644 non-null  float32\n",
      " 84   paraphrase-MiniLM-L6-v2_0078  186644 non-null  float32\n",
      " 85   paraphrase-MiniLM-L6-v2_0079  186644 non-null  float32\n",
      " 86   paraphrase-MiniLM-L6-v2_0080  186644 non-null  float32\n",
      " 87   paraphrase-MiniLM-L6-v2_0081  186644 non-null  float32\n",
      " 88   paraphrase-MiniLM-L6-v2_0082  186644 non-null  float32\n",
      " 89   paraphrase-MiniLM-L6-v2_0083  186644 non-null  float32\n",
      " 90   paraphrase-MiniLM-L6-v2_0084  186644 non-null  float32\n",
      " 91   paraphrase-MiniLM-L6-v2_0085  186644 non-null  float32\n",
      " 92   paraphrase-MiniLM-L6-v2_0086  186644 non-null  float32\n",
      " 93   paraphrase-MiniLM-L6-v2_0087  186644 non-null  float32\n",
      " 94   paraphrase-MiniLM-L6-v2_0088  186644 non-null  float32\n",
      " 95   paraphrase-MiniLM-L6-v2_0089  186644 non-null  float32\n",
      " 96   paraphrase-MiniLM-L6-v2_0090  186644 non-null  float32\n",
      " 97   paraphrase-MiniLM-L6-v2_0091  186644 non-null  float32\n",
      " 98   paraphrase-MiniLM-L6-v2_0092  186644 non-null  float32\n",
      " 99   paraphrase-MiniLM-L6-v2_0093  186644 non-null  float32\n",
      " 100  paraphrase-MiniLM-L6-v2_0094  186644 non-null  float32\n",
      " 101  paraphrase-MiniLM-L6-v2_0095  186644 non-null  float32\n",
      " 102  paraphrase-MiniLM-L6-v2_0096  186644 non-null  float32\n",
      " 103  paraphrase-MiniLM-L6-v2_0097  186644 non-null  float32\n",
      " 104  paraphrase-MiniLM-L6-v2_0098  186644 non-null  float32\n",
      " 105  paraphrase-MiniLM-L6-v2_0099  186644 non-null  float32\n",
      " 106  paraphrase-MiniLM-L6-v2_0100  186644 non-null  float32\n",
      " 107  paraphrase-MiniLM-L6-v2_0101  186644 non-null  float32\n",
      " 108  paraphrase-MiniLM-L6-v2_0102  186644 non-null  float32\n",
      " 109  paraphrase-MiniLM-L6-v2_0103  186644 non-null  float32\n",
      " 110  paraphrase-MiniLM-L6-v2_0104  186644 non-null  float32\n",
      " 111  paraphrase-MiniLM-L6-v2_0105  186644 non-null  float32\n",
      " 112  paraphrase-MiniLM-L6-v2_0106  186644 non-null  float32\n",
      " 113  paraphrase-MiniLM-L6-v2_0107  186644 non-null  float32\n",
      " 114  paraphrase-MiniLM-L6-v2_0108  186644 non-null  float32\n",
      " 115  paraphrase-MiniLM-L6-v2_0109  186644 non-null  float32\n",
      " 116  paraphrase-MiniLM-L6-v2_0110  186644 non-null  float32\n",
      " 117  paraphrase-MiniLM-L6-v2_0111  186644 non-null  float32\n",
      " 118  paraphrase-MiniLM-L6-v2_0112  186644 non-null  float32\n",
      " 119  paraphrase-MiniLM-L6-v2_0113  186644 non-null  float32\n",
      " 120  paraphrase-MiniLM-L6-v2_0114  186644 non-null  float32\n",
      " 121  paraphrase-MiniLM-L6-v2_0115  186644 non-null  float32\n",
      " 122  paraphrase-MiniLM-L6-v2_0116  186644 non-null  float32\n",
      " 123  paraphrase-MiniLM-L6-v2_0117  186644 non-null  float32\n",
      " 124  paraphrase-MiniLM-L6-v2_0118  186644 non-null  float32\n",
      " 125  paraphrase-MiniLM-L6-v2_0119  186644 non-null  float32\n",
      " 126  paraphrase-MiniLM-L6-v2_0120  186644 non-null  float32\n",
      " 127  paraphrase-MiniLM-L6-v2_0121  186644 non-null  float32\n",
      " 128  paraphrase-MiniLM-L6-v2_0122  186644 non-null  float32\n",
      " 129  paraphrase-MiniLM-L6-v2_0123  186644 non-null  float32\n",
      " 130  paraphrase-MiniLM-L6-v2_0124  186644 non-null  float32\n",
      " 131  paraphrase-MiniLM-L6-v2_0125  186644 non-null  float32\n",
      " 132  paraphrase-MiniLM-L6-v2_0126  186644 non-null  float32\n",
      " 133  paraphrase-MiniLM-L6-v2_0127  186644 non-null  float32\n",
      " 134  paraphrase-MiniLM-L6-v2_0128  186644 non-null  float32\n",
      " 135  paraphrase-MiniLM-L6-v2_0129  186644 non-null  float32\n",
      " 136  paraphrase-MiniLM-L6-v2_0130  186644 non-null  float32\n",
      " 137  paraphrase-MiniLM-L6-v2_0131  186644 non-null  float32\n",
      " 138  paraphrase-MiniLM-L6-v2_0132  186644 non-null  float32\n",
      " 139  paraphrase-MiniLM-L6-v2_0133  186644 non-null  float32\n",
      " 140  paraphrase-MiniLM-L6-v2_0134  186644 non-null  float32\n",
      " 141  paraphrase-MiniLM-L6-v2_0135  186644 non-null  float32\n",
      " 142  paraphrase-MiniLM-L6-v2_0136  186644 non-null  float32\n",
      " 143  paraphrase-MiniLM-L6-v2_0137  186644 non-null  float32\n",
      " 144  paraphrase-MiniLM-L6-v2_0138  186644 non-null  float32\n",
      " 145  paraphrase-MiniLM-L6-v2_0139  186644 non-null  float32\n",
      " 146  paraphrase-MiniLM-L6-v2_0140  186644 non-null  float32\n",
      " 147  paraphrase-MiniLM-L6-v2_0141  186644 non-null  float32\n",
      " 148  paraphrase-MiniLM-L6-v2_0142  186644 non-null  float32\n",
      " 149  paraphrase-MiniLM-L6-v2_0143  186644 non-null  float32\n",
      " 150  paraphrase-MiniLM-L6-v2_0144  186644 non-null  float32\n",
      " 151  paraphrase-MiniLM-L6-v2_0145  186644 non-null  float32\n",
      " 152  paraphrase-MiniLM-L6-v2_0146  186644 non-null  float32\n",
      " 153  paraphrase-MiniLM-L6-v2_0147  186644 non-null  float32\n",
      " 154  paraphrase-MiniLM-L6-v2_0148  186644 non-null  float32\n",
      " 155  paraphrase-MiniLM-L6-v2_0149  186644 non-null  float32\n",
      " 156  paraphrase-MiniLM-L6-v2_0150  186644 non-null  float32\n",
      " 157  paraphrase-MiniLM-L6-v2_0151  186644 non-null  float32\n",
      " 158  paraphrase-MiniLM-L6-v2_0152  186644 non-null  float32\n",
      " 159  paraphrase-MiniLM-L6-v2_0153  186644 non-null  float32\n",
      " 160  paraphrase-MiniLM-L6-v2_0154  186644 non-null  float32\n",
      " 161  paraphrase-MiniLM-L6-v2_0155  186644 non-null  float32\n",
      " 162  paraphrase-MiniLM-L6-v2_0156  186644 non-null  float32\n",
      " 163  paraphrase-MiniLM-L6-v2_0157  186644 non-null  float32\n",
      " 164  paraphrase-MiniLM-L6-v2_0158  186644 non-null  float32\n",
      " 165  paraphrase-MiniLM-L6-v2_0159  186644 non-null  float32\n",
      " 166  paraphrase-MiniLM-L6-v2_0160  186644 non-null  float32\n",
      " 167  paraphrase-MiniLM-L6-v2_0161  186644 non-null  float32\n",
      " 168  paraphrase-MiniLM-L6-v2_0162  186644 non-null  float32\n",
      " 169  paraphrase-MiniLM-L6-v2_0163  186644 non-null  float32\n",
      " 170  paraphrase-MiniLM-L6-v2_0164  186644 non-null  float32\n",
      " 171  paraphrase-MiniLM-L6-v2_0165  186644 non-null  float32\n",
      " 172  paraphrase-MiniLM-L6-v2_0166  186644 non-null  float32\n",
      " 173  paraphrase-MiniLM-L6-v2_0167  186644 non-null  float32\n",
      " 174  paraphrase-MiniLM-L6-v2_0168  186644 non-null  float32\n",
      " 175  paraphrase-MiniLM-L6-v2_0169  186644 non-null  float32\n",
      " 176  paraphrase-MiniLM-L6-v2_0170  186644 non-null  float32\n",
      " 177  paraphrase-MiniLM-L6-v2_0171  186644 non-null  float32\n",
      " 178  paraphrase-MiniLM-L6-v2_0172  186644 non-null  float32\n",
      " 179  paraphrase-MiniLM-L6-v2_0173  186644 non-null  float32\n",
      " 180  paraphrase-MiniLM-L6-v2_0174  186644 non-null  float32\n",
      " 181  paraphrase-MiniLM-L6-v2_0175  186644 non-null  float32\n",
      " 182  paraphrase-MiniLM-L6-v2_0176  186644 non-null  float32\n",
      " 183  paraphrase-MiniLM-L6-v2_0177  186644 non-null  float32\n",
      " 184  paraphrase-MiniLM-L6-v2_0178  186644 non-null  float32\n",
      " 185  paraphrase-MiniLM-L6-v2_0179  186644 non-null  float32\n",
      " 186  paraphrase-MiniLM-L6-v2_0180  186644 non-null  float32\n",
      " 187  paraphrase-MiniLM-L6-v2_0181  186644 non-null  float32\n",
      " 188  paraphrase-MiniLM-L6-v2_0182  186644 non-null  float32\n",
      " 189  paraphrase-MiniLM-L6-v2_0183  186644 non-null  float32\n",
      " 190  paraphrase-MiniLM-L6-v2_0184  186644 non-null  float32\n",
      " 191  paraphrase-MiniLM-L6-v2_0185  186644 non-null  float32\n",
      " 192  paraphrase-MiniLM-L6-v2_0186  186644 non-null  float32\n",
      " 193  paraphrase-MiniLM-L6-v2_0187  186644 non-null  float32\n",
      " 194  paraphrase-MiniLM-L6-v2_0188  186644 non-null  float32\n",
      " 195  paraphrase-MiniLM-L6-v2_0189  186644 non-null  float32\n",
      " 196  paraphrase-MiniLM-L6-v2_0190  186644 non-null  float32\n",
      " 197  paraphrase-MiniLM-L6-v2_0191  186644 non-null  float32\n",
      " 198  paraphrase-MiniLM-L6-v2_0192  186644 non-null  float32\n",
      " 199  paraphrase-MiniLM-L6-v2_0193  186644 non-null  float32\n",
      " 200  paraphrase-MiniLM-L6-v2_0194  186644 non-null  float32\n",
      " 201  paraphrase-MiniLM-L6-v2_0195  186644 non-null  float32\n",
      " 202  paraphrase-MiniLM-L6-v2_0196  186644 non-null  float32\n",
      " 203  paraphrase-MiniLM-L6-v2_0197  186644 non-null  float32\n",
      " 204  paraphrase-MiniLM-L6-v2_0198  186644 non-null  float32\n",
      " 205  paraphrase-MiniLM-L6-v2_0199  186644 non-null  float32\n",
      " 206  paraphrase-MiniLM-L6-v2_0200  186644 non-null  float32\n",
      " 207  paraphrase-MiniLM-L6-v2_0201  186644 non-null  float32\n",
      " 208  paraphrase-MiniLM-L6-v2_0202  186644 non-null  float32\n",
      " 209  paraphrase-MiniLM-L6-v2_0203  186644 non-null  float32\n",
      " 210  paraphrase-MiniLM-L6-v2_0204  186644 non-null  float32\n",
      " 211  paraphrase-MiniLM-L6-v2_0205  186644 non-null  float32\n",
      " 212  paraphrase-MiniLM-L6-v2_0206  186644 non-null  float32\n",
      " 213  paraphrase-MiniLM-L6-v2_0207  186644 non-null  float32\n",
      " 214  paraphrase-MiniLM-L6-v2_0208  186644 non-null  float32\n",
      " 215  paraphrase-MiniLM-L6-v2_0209  186644 non-null  float32\n",
      " 216  paraphrase-MiniLM-L6-v2_0210  186644 non-null  float32\n",
      " 217  paraphrase-MiniLM-L6-v2_0211  186644 non-null  float32\n",
      " 218  paraphrase-MiniLM-L6-v2_0212  186644 non-null  float32\n",
      " 219  paraphrase-MiniLM-L6-v2_0213  186644 non-null  float32\n",
      " 220  paraphrase-MiniLM-L6-v2_0214  186644 non-null  float32\n",
      " 221  paraphrase-MiniLM-L6-v2_0215  186644 non-null  float32\n",
      " 222  paraphrase-MiniLM-L6-v2_0216  186644 non-null  float32\n",
      " 223  paraphrase-MiniLM-L6-v2_0217  186644 non-null  float32\n",
      " 224  paraphrase-MiniLM-L6-v2_0218  186644 non-null  float32\n",
      " 225  paraphrase-MiniLM-L6-v2_0219  186644 non-null  float32\n",
      " 226  paraphrase-MiniLM-L6-v2_0220  186644 non-null  float32\n",
      " 227  paraphrase-MiniLM-L6-v2_0221  186644 non-null  float32\n",
      " 228  paraphrase-MiniLM-L6-v2_0222  186644 non-null  float32\n",
      " 229  paraphrase-MiniLM-L6-v2_0223  186644 non-null  float32\n",
      " 230  paraphrase-MiniLM-L6-v2_0224  186644 non-null  float32\n",
      " 231  paraphrase-MiniLM-L6-v2_0225  186644 non-null  float32\n",
      " 232  paraphrase-MiniLM-L6-v2_0226  186644 non-null  float32\n",
      " 233  paraphrase-MiniLM-L6-v2_0227  186644 non-null  float32\n",
      " 234  paraphrase-MiniLM-L6-v2_0228  186644 non-null  float32\n",
      " 235  paraphrase-MiniLM-L6-v2_0229  186644 non-null  float32\n",
      " 236  paraphrase-MiniLM-L6-v2_0230  186644 non-null  float32\n",
      " 237  paraphrase-MiniLM-L6-v2_0231  186644 non-null  float32\n",
      " 238  paraphrase-MiniLM-L6-v2_0232  186644 non-null  float32\n",
      " 239  paraphrase-MiniLM-L6-v2_0233  186644 non-null  float32\n",
      " 240  paraphrase-MiniLM-L6-v2_0234  186644 non-null  float32\n",
      " 241  paraphrase-MiniLM-L6-v2_0235  186644 non-null  float32\n",
      " 242  paraphrase-MiniLM-L6-v2_0236  186644 non-null  float32\n",
      " 243  paraphrase-MiniLM-L6-v2_0237  186644 non-null  float32\n",
      " 244  paraphrase-MiniLM-L6-v2_0238  186644 non-null  float32\n",
      " 245  paraphrase-MiniLM-L6-v2_0239  186644 non-null  float32\n",
      " 246  paraphrase-MiniLM-L6-v2_0240  186644 non-null  float32\n",
      " 247  paraphrase-MiniLM-L6-v2_0241  186644 non-null  float32\n",
      " 248  paraphrase-MiniLM-L6-v2_0242  186644 non-null  float32\n",
      " 249  paraphrase-MiniLM-L6-v2_0243  186644 non-null  float32\n",
      " 250  paraphrase-MiniLM-L6-v2_0244  186644 non-null  float32\n",
      " 251  paraphrase-MiniLM-L6-v2_0245  186644 non-null  float32\n",
      " 252  paraphrase-MiniLM-L6-v2_0246  186644 non-null  float32\n",
      " 253  paraphrase-MiniLM-L6-v2_0247  186644 non-null  float32\n",
      " 254  paraphrase-MiniLM-L6-v2_0248  186644 non-null  float32\n",
      " 255  paraphrase-MiniLM-L6-v2_0249  186644 non-null  float32\n",
      " 256  paraphrase-MiniLM-L6-v2_0250  186644 non-null  float32\n",
      " 257  paraphrase-MiniLM-L6-v2_0251  186644 non-null  float32\n",
      " 258  paraphrase-MiniLM-L6-v2_0252  186644 non-null  float32\n",
      " 259  paraphrase-MiniLM-L6-v2_0253  186644 non-null  float32\n",
      " 260  paraphrase-MiniLM-L6-v2_0254  186644 non-null  float32\n",
      " 261  paraphrase-MiniLM-L6-v2_0255  186644 non-null  float32\n",
      " 262  paraphrase-MiniLM-L6-v2_0256  186644 non-null  float32\n",
      " 263  paraphrase-MiniLM-L6-v2_0257  186644 non-null  float32\n",
      " 264  paraphrase-MiniLM-L6-v2_0258  186644 non-null  float32\n",
      " 265  paraphrase-MiniLM-L6-v2_0259  186644 non-null  float32\n",
      " 266  paraphrase-MiniLM-L6-v2_0260  186644 non-null  float32\n",
      " 267  paraphrase-MiniLM-L6-v2_0261  186644 non-null  float32\n",
      " 268  paraphrase-MiniLM-L6-v2_0262  186644 non-null  float32\n",
      " 269  paraphrase-MiniLM-L6-v2_0263  186644 non-null  float32\n",
      " 270  paraphrase-MiniLM-L6-v2_0264  186644 non-null  float32\n",
      " 271  paraphrase-MiniLM-L6-v2_0265  186644 non-null  float32\n",
      " 272  paraphrase-MiniLM-L6-v2_0266  186644 non-null  float32\n",
      " 273  paraphrase-MiniLM-L6-v2_0267  186644 non-null  float32\n",
      " 274  paraphrase-MiniLM-L6-v2_0268  186644 non-null  float32\n",
      " 275  paraphrase-MiniLM-L6-v2_0269  186644 non-null  float32\n",
      " 276  paraphrase-MiniLM-L6-v2_0270  186644 non-null  float32\n",
      " 277  paraphrase-MiniLM-L6-v2_0271  186644 non-null  float32\n",
      " 278  paraphrase-MiniLM-L6-v2_0272  186644 non-null  float32\n",
      " 279  paraphrase-MiniLM-L6-v2_0273  186644 non-null  float32\n",
      " 280  paraphrase-MiniLM-L6-v2_0274  186644 non-null  float32\n",
      " 281  paraphrase-MiniLM-L6-v2_0275  186644 non-null  float32\n",
      " 282  paraphrase-MiniLM-L6-v2_0276  186644 non-null  float32\n",
      " 283  paraphrase-MiniLM-L6-v2_0277  186644 non-null  float32\n",
      " 284  paraphrase-MiniLM-L6-v2_0278  186644 non-null  float32\n",
      " 285  paraphrase-MiniLM-L6-v2_0279  186644 non-null  float32\n",
      " 286  paraphrase-MiniLM-L6-v2_0280  186644 non-null  float32\n",
      " 287  paraphrase-MiniLM-L6-v2_0281  186644 non-null  float32\n",
      " 288  paraphrase-MiniLM-L6-v2_0282  186644 non-null  float32\n",
      " 289  paraphrase-MiniLM-L6-v2_0283  186644 non-null  float32\n",
      " 290  paraphrase-MiniLM-L6-v2_0284  186644 non-null  float32\n",
      " 291  paraphrase-MiniLM-L6-v2_0285  186644 non-null  float32\n",
      " 292  paraphrase-MiniLM-L6-v2_0286  186644 non-null  float32\n",
      " 293  paraphrase-MiniLM-L6-v2_0287  186644 non-null  float32\n",
      " 294  paraphrase-MiniLM-L6-v2_0288  186644 non-null  float32\n",
      " 295  paraphrase-MiniLM-L6-v2_0289  186644 non-null  float32\n",
      " 296  paraphrase-MiniLM-L6-v2_0290  186644 non-null  float32\n",
      " 297  paraphrase-MiniLM-L6-v2_0291  186644 non-null  float32\n",
      " 298  paraphrase-MiniLM-L6-v2_0292  186644 non-null  float32\n",
      " 299  paraphrase-MiniLM-L6-v2_0293  186644 non-null  float32\n",
      " 300  paraphrase-MiniLM-L6-v2_0294  186644 non-null  float32\n",
      " 301  paraphrase-MiniLM-L6-v2_0295  186644 non-null  float32\n",
      " 302  paraphrase-MiniLM-L6-v2_0296  186644 non-null  float32\n",
      " 303  paraphrase-MiniLM-L6-v2_0297  186644 non-null  float32\n",
      " 304  paraphrase-MiniLM-L6-v2_0298  186644 non-null  float32\n",
      " 305  paraphrase-MiniLM-L6-v2_0299  186644 non-null  float32\n",
      " 306  paraphrase-MiniLM-L6-v2_0300  186644 non-null  float32\n",
      " 307  paraphrase-MiniLM-L6-v2_0301  186644 non-null  float32\n",
      " 308  paraphrase-MiniLM-L6-v2_0302  186644 non-null  float32\n",
      " 309  paraphrase-MiniLM-L6-v2_0303  186644 non-null  float32\n",
      " 310  paraphrase-MiniLM-L6-v2_0304  186644 non-null  float32\n",
      " 311  paraphrase-MiniLM-L6-v2_0305  186644 non-null  float32\n",
      " 312  paraphrase-MiniLM-L6-v2_0306  186644 non-null  float32\n",
      " 313  paraphrase-MiniLM-L6-v2_0307  186644 non-null  float32\n",
      " 314  paraphrase-MiniLM-L6-v2_0308  186644 non-null  float32\n",
      " 315  paraphrase-MiniLM-L6-v2_0309  186644 non-null  float32\n",
      " 316  paraphrase-MiniLM-L6-v2_0310  186644 non-null  float32\n",
      " 317  paraphrase-MiniLM-L6-v2_0311  186644 non-null  float32\n",
      " 318  paraphrase-MiniLM-L6-v2_0312  186644 non-null  float32\n",
      " 319  paraphrase-MiniLM-L6-v2_0313  186644 non-null  float32\n",
      " 320  paraphrase-MiniLM-L6-v2_0314  186644 non-null  float32\n",
      " 321  paraphrase-MiniLM-L6-v2_0315  186644 non-null  float32\n",
      " 322  paraphrase-MiniLM-L6-v2_0316  186644 non-null  float32\n",
      " 323  paraphrase-MiniLM-L6-v2_0317  186644 non-null  float32\n",
      " 324  paraphrase-MiniLM-L6-v2_0318  186644 non-null  float32\n",
      " 325  paraphrase-MiniLM-L6-v2_0319  186644 non-null  float32\n",
      " 326  paraphrase-MiniLM-L6-v2_0320  186644 non-null  float32\n",
      " 327  paraphrase-MiniLM-L6-v2_0321  186644 non-null  float32\n",
      " 328  paraphrase-MiniLM-L6-v2_0322  186644 non-null  float32\n",
      " 329  paraphrase-MiniLM-L6-v2_0323  186644 non-null  float32\n",
      " 330  paraphrase-MiniLM-L6-v2_0324  186644 non-null  float32\n",
      " 331  paraphrase-MiniLM-L6-v2_0325  186644 non-null  float32\n",
      " 332  paraphrase-MiniLM-L6-v2_0326  186644 non-null  float32\n",
      " 333  paraphrase-MiniLM-L6-v2_0327  186644 non-null  float32\n",
      " 334  paraphrase-MiniLM-L6-v2_0328  186644 non-null  float32\n",
      " 335  paraphrase-MiniLM-L6-v2_0329  186644 non-null  float32\n",
      " 336  paraphrase-MiniLM-L6-v2_0330  186644 non-null  float32\n",
      " 337  paraphrase-MiniLM-L6-v2_0331  186644 non-null  float32\n",
      " 338  paraphrase-MiniLM-L6-v2_0332  186644 non-null  float32\n",
      " 339  paraphrase-MiniLM-L6-v2_0333  186644 non-null  float32\n",
      " 340  paraphrase-MiniLM-L6-v2_0334  186644 non-null  float32\n",
      " 341  paraphrase-MiniLM-L6-v2_0335  186644 non-null  float32\n",
      " 342  paraphrase-MiniLM-L6-v2_0336  186644 non-null  float32\n",
      " 343  paraphrase-MiniLM-L6-v2_0337  186644 non-null  float32\n",
      " 344  paraphrase-MiniLM-L6-v2_0338  186644 non-null  float32\n",
      " 345  paraphrase-MiniLM-L6-v2_0339  186644 non-null  float32\n",
      " 346  paraphrase-MiniLM-L6-v2_0340  186644 non-null  float32\n",
      " 347  paraphrase-MiniLM-L6-v2_0341  186644 non-null  float32\n",
      " 348  paraphrase-MiniLM-L6-v2_0342  186644 non-null  float32\n",
      " 349  paraphrase-MiniLM-L6-v2_0343  186644 non-null  float32\n",
      " 350  paraphrase-MiniLM-L6-v2_0344  186644 non-null  float32\n",
      " 351  paraphrase-MiniLM-L6-v2_0345  186644 non-null  float32\n",
      " 352  paraphrase-MiniLM-L6-v2_0346  186644 non-null  float32\n",
      " 353  paraphrase-MiniLM-L6-v2_0347  186644 non-null  float32\n",
      " 354  paraphrase-MiniLM-L6-v2_0348  186644 non-null  float32\n",
      " 355  paraphrase-MiniLM-L6-v2_0349  186644 non-null  float32\n",
      " 356  paraphrase-MiniLM-L6-v2_0350  186644 non-null  float32\n",
      " 357  paraphrase-MiniLM-L6-v2_0351  186644 non-null  float32\n",
      " 358  paraphrase-MiniLM-L6-v2_0352  186644 non-null  float32\n",
      " 359  paraphrase-MiniLM-L6-v2_0353  186644 non-null  float32\n",
      " 360  paraphrase-MiniLM-L6-v2_0354  186644 non-null  float32\n",
      " 361  paraphrase-MiniLM-L6-v2_0355  186644 non-null  float32\n",
      " 362  paraphrase-MiniLM-L6-v2_0356  186644 non-null  float32\n",
      " 363  paraphrase-MiniLM-L6-v2_0357  186644 non-null  float32\n",
      " 364  paraphrase-MiniLM-L6-v2_0358  186644 non-null  float32\n",
      " 365  paraphrase-MiniLM-L6-v2_0359  186644 non-null  float32\n",
      " 366  paraphrase-MiniLM-L6-v2_0360  186644 non-null  float32\n",
      " 367  paraphrase-MiniLM-L6-v2_0361  186644 non-null  float32\n",
      " 368  paraphrase-MiniLM-L6-v2_0362  186644 non-null  float32\n",
      " 369  paraphrase-MiniLM-L6-v2_0363  186644 non-null  float32\n",
      " 370  paraphrase-MiniLM-L6-v2_0364  186644 non-null  float32\n",
      " 371  paraphrase-MiniLM-L6-v2_0365  186644 non-null  float32\n",
      " 372  paraphrase-MiniLM-L6-v2_0366  186644 non-null  float32\n",
      " 373  paraphrase-MiniLM-L6-v2_0367  186644 non-null  float32\n",
      " 374  paraphrase-MiniLM-L6-v2_0368  186644 non-null  float32\n",
      " 375  paraphrase-MiniLM-L6-v2_0369  186644 non-null  float32\n",
      " 376  paraphrase-MiniLM-L6-v2_0370  186644 non-null  float32\n",
      " 377  paraphrase-MiniLM-L6-v2_0371  186644 non-null  float32\n",
      " 378  paraphrase-MiniLM-L6-v2_0372  186644 non-null  float32\n",
      " 379  paraphrase-MiniLM-L6-v2_0373  186644 non-null  float32\n",
      " 380  paraphrase-MiniLM-L6-v2_0374  186644 non-null  float32\n",
      " 381  paraphrase-MiniLM-L6-v2_0375  186644 non-null  float32\n",
      " 382  paraphrase-MiniLM-L6-v2_0376  186644 non-null  float32\n",
      " 383  paraphrase-MiniLM-L6-v2_0377  186644 non-null  float32\n",
      " 384  paraphrase-MiniLM-L6-v2_0378  186644 non-null  float32\n",
      " 385  paraphrase-MiniLM-L6-v2_0379  186644 non-null  float32\n",
      " 386  paraphrase-MiniLM-L6-v2_0380  186644 non-null  float32\n",
      " 387  paraphrase-MiniLM-L6-v2_0381  186644 non-null  float32\n",
      " 388  paraphrase-MiniLM-L6-v2_0382  186644 non-null  float32\n",
      " 389  paraphrase-MiniLM-L6-v2_0383  186644 non-null  float32\n",
      "dtypes: float32(385), int8(1), object(4)\n",
      "memory usage: 280.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cols = [\"bws\", \"worker\", \"text\", \"text1\", \"text2\", \"text3\"]\n",
    "cols += em_cols\n",
    "js18_df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "437c53fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "js18_df[cols].to_parquet(\"output/em_js18.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
