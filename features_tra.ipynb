{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b888a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import rankdata\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import textstat\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8f39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', dtfy_model_max_length=512, dtfy_batch_size=256, dtfy_models={'dto_': 'pretrained/unitaryai/detoxify/toxic_original-c1212f89.ckpt', 'dtu_': 'pretrained/unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt', 'dtm_': 'pretrained/unitaryai/detoxify/multilingual_debiased-0b549669.ckpt'}, dtfy_configs={'dto_': 'pretrained/bert-base-uncased', 'dtu_': 'pretrained/roberta-base', 'dtm_': 'pretrained/xlm-roberta-base'}, tweeteval_model_max_length=512, tweeteval_batch_size=64, tweeteval_models={'te_roberta_off': 'pretrained/cardiffnlp/twitter-roberta-base-offensive', 'te_roberta_emo_anger': 'pretrained/cardiffnlp/twitter-roberta-base-emotion', 'te_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-roberta-base-sentiment', 'te_roberta_iro': 'pretrained/cardiffnlp/twitter-roberta-base-irony', 'te_xlm_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-xlm-roberta-base-sentiment'}, tweeteval_label_index={'te_roberta_off': 1, 'te_roberta_emo_anger': 0, 'te_roberta_snt_neg': 0, 'te_roberta_iro': 1, 'te_xlm_roberta_snt_neg': 0}, hatebert_model_max_length=512, hatebert_batch_size=128, hatebert_models={'hb_bert_off': 'pretrained/hatebert/bert-offenseval', 'hb_bert_abu': 'pretrained/hatebert/bert-abuseval', 'hb_hatebert_off': 'pretrained/hatebert/hatebert-offenseval', 'hb_hatebert_abu': 'pretrained/hatebert/hatebert-abuseval'}, em_max_seq_length=128, em_batch_size=1000, em_models={'paraphrase-MiniLM-L6-v2': 'pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2'})\n",
      "NVIDIA GeForce GTX 1060 6GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    dtfy_model_max_length: int = 512\n",
    "    dtfy_batch_size: int = 256\n",
    "    dtfy_models: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_original-c1212f89.ckpt\",\n",
    "        \"dtu_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt\",\n",
    "        \"dtm_\": f\"{pretrained_dir}unitaryai/detoxify/multilingual_debiased-0b549669.ckpt\"\n",
    "    }\n",
    "    dtfy_configs: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}bert-base-uncased\",\n",
    "        \"dtu_\": f\"{pretrained_dir}roberta-base\",\n",
    "        \"dtm_\": f\"{pretrained_dir}xlm-roberta-base\"\n",
    "    }\n",
    "    tweeteval_model_max_length: int = 512\n",
    "    tweeteval_batch_size: int = 64\n",
    "    tweeteval_models: Dict[str, str] = {\n",
    "        \"te_roberta_off\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-offensive\",\n",
    "        \"te_roberta_emo_anger\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        \"te_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        \"te_roberta_iro\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-irony\",\n",
    "        \"te_xlm_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    }\n",
    "    tweeteval_label_index: Dict[str, int] = {\n",
    "        \"te_roberta_off\": 1,\n",
    "        \"te_roberta_emo_anger\": 0,\n",
    "        \"te_roberta_snt_neg\": 0,\n",
    "        \"te_roberta_iro\": 1,\n",
    "        \"te_xlm_roberta_snt_neg\": 0,\n",
    "    }\n",
    "    hatebert_model_max_length: int = 512\n",
    "    hatebert_batch_size: int = 128\n",
    "    hatebert_models: Dict[str, str] = {\n",
    "        \"hb_bert_off\": f\"{pretrained_dir}hatebert/bert-offenseval\",\n",
    "        \"hb_bert_abu\" : f\"{pretrained_dir}hatebert/bert-abuseval\",\n",
    "        \"hb_hatebert_off\": f\"{pretrained_dir}hatebert/hatebert-offenseval\",\n",
    "        \"hb_hatebert_abu\" : f\"{pretrained_dir}hatebert/hatebert-abuseval\",\n",
    "    }\n",
    "    em_max_seq_length: int = 128\n",
    "    em_batch_size: int = 1000\n",
    "    em_models: Dict[str, str] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "    }\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_map: Dict[str, float] = {}\n",
    "df = pd.read_csv(\"input/ruddit/Ruddit.csv\", engine=\"c\", low_memory=False)\n",
    "for t in df.itertuples():\n",
    "    k = getattr(t, \"post_id\") + \"_\" + getattr(t, \"comment_id\")\n",
    "    score_map[k] = getattr(t, \"offensiveness_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860fc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   bws     5710 non-null   float32\n",
      " 1   text    5710 non-null   object \n",
      "dtypes: float32(1), object(1)\n",
      "memory usage: 67.0+ KB\n",
      "Wall time: 51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"input/ruddit/ruddit_with_text.csv\", engine=\"c\", low_memory=False)\n",
    "blacklist = {\"[deleted]\", \"[removed]\"}\n",
    "rows = []\n",
    "for t in df.itertuples():\n",
    "    text = getattr(t, \"txt\")\n",
    "    s = text.strip().lower()\n",
    "    if len(s)==0 or s in blacklist:\n",
    "        continue\n",
    "    k = getattr(t, \"post_id\") + \"_\" + getattr(t, \"comment_id\")\n",
    "    rows.append({\"bws\": score_map[k], \"text\": text})\n",
    "df = pd.DataFrame.from_records(rows)\n",
    "df[\"bws\"] = df[\"bws\"].astype(np.float32) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4f3683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bws</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total  Percent     Type\n",
       "bws       0      0.0  float32\n",
       "text      0      0.0   object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scml.find_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a7d8e",
   "metadata": {},
   "source": [
    "# Severity rating label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c05937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force unique ranks\n",
    "col = \"label\"\n",
    "df[col] = rankdata(df[\"bws\"], method='ordinal')\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4796d0d",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27321fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:02<00:00, 2429.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(row) -> str:\n",
    "    return mylib.preprocess(row[\"text\"])\n",
    "\n",
    "\n",
    "col = \"text\"\n",
    "df[col] = df.progress_apply(preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2490070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bws</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>-0.562</td>\n",
       "      <td>This is so sexy! Love it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>-0.542</td>\n",
       "      <td>Cross referencing and forming your own ideologies is easily one of the greatest things I learned in school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>-0.511</td>\n",
       "      <td>Amazing dude! I salute to u! I do not feel like playing much honestly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>-0.438</td>\n",
       "      <td>Who actually cares it is just a building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>-0.417</td>\n",
       "      <td>I think it is safe to say he did not get away with it twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>-0.333</td>\n",
       "      <td>I am European we generally start drinking about 14.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>-0.271</td>\n",
       "      <td>Anybody want some pepperoni flavored vaccines?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.250</td>\n",
       "      <td>Everyone should be tax exempt. The people did not consent to have their money taken, so it is immoral for the government to take any of it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>-0.229</td>\n",
       "      <td>I would hire one very specific artist and kickstart my 6-years-in-making comic book series, and advertise the living hell out of it. And if it was a success, I would make two animated adaptations - one mostly family friendly, and one more explicit than Berserk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>I am getting vaxes for polio and I have autism already xD nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>Thanks for the tidbit of information regarding LotR. Not a fan of it myself (though I did not hate it). I agree with both Socrates and Glaucon, but maybe more towards Glaucon. Give a man invisibility, or hell, when a man thinks he is not being watched, we would be very surprised by what he would do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>The two next major elections are pretty pro-EU. Merkels biggest rival is more pro-EU than her (but the CDU currently still has a slight lead over the SPD) and the current projections of the French election have Macron winning, who is more pro-EU than Hollande.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>-0.167</td>\n",
       "      <td>The exact reason she should never get it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>-0.146</td>\n",
       "      <td>Would they rather support me with public assistance or let me get a job? There do not seem to be any men clambering to support me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>-0.146</td>\n",
       "      <td>Just to give a different view. From a modding perspective, the redesign finally adds, or is in the process of adding, a lot of native tools that help make moderation a lot easier for new mods. You do not have to be a CSS wizard now to set up a good looking subreddit. There are native removal reasons that will hopefully end up in mobile apps instead of being a computer only feature from toolbox. Flair filtering is finally happening. Posting requirements will work properly instead of having Automod remove posts and comments. Yes, there are a lot of complaints from mods about the redesign, but the improvements made by admins over the past few months have been incredible and show that they are listening to feedback. Just check /r/redesign weekly and you will see.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>-0.125</td>\n",
       "      <td>Why the hell are people downvoting your comment? This karma system is for the birds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.125</td>\n",
       "      <td>You make a good point as far as the misinformation goes. And I do not doubt that lone individuals would be able to search out the information anyway. But it could reduce the \"benefit\" of fame that perpetrating a mass shooting has. I am not sure if the misinformation aspect would outweigh the possible benefits, but it is certainly something to think about.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>&gt; she is not a politician lying through her teeth. Funny, that is exactly why we like her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>Anyone want to point out that cutting off everyone who calls him insecure, he is proving them right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>did not know we put people in jail for having other religions or speaking ill of the country.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>that is the thing though. The corporate candidates (the ones we are used to) are laughably bad, generic and fake when compared to someone who genuinely wants to turn things around for the country. The problem is that usually we have to choose between 2 corporate/establishment approved candidates so the contrast is not obvious.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>When you create a new fat cell, your body keeps it for life. Therefore, it makes it even easier to gain weight after losing the weight from before (childhood in my case). So for people like me, who do work hard even just to maintain my weight after losing some, the question is... was it a choice for me as a kid to create all those new fat cells. Because I am stuck with them now... they just lay there waiting to be inflated by any calorie I eat and do not burn. It sucks man it is a lot harder than people think.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.000</td>\n",
       "      <td>you would have one hell of a time proving beyond a reasonable doubt that the lack of vaccination lead directly and causally to the death of the child, seeing as people get illnesses despite vaccination on a non-zero-chance basis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.021</td>\n",
       "      <td>alright first we need to define what kind of god you are referring to, if its the omnipotent omniscient god type then there is a very simple reason why it does not exist. we are unable to properly verify omnipotence, thus we are not capable of acknowledging a being as being such. thus god does not exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.043</td>\n",
       "      <td>Mate, if you think kneeling has had zero effect on viewership, you are naive. The NFL **clearly** thinks kneeling is having an effect on viewership, **or they would not be doing what they are doing.**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>0.083</td>\n",
       "      <td>it is just an observation on my part, though I think it can be attributed to sexual selection. Until very recently a wealthy, powerful, socially dominant provider type would have boosted the probability of a woman's genes surviving. Would be neat to see some data on this, there is always interesting stuff to be seen in studies of human sexual selection. In 'primitive' warring cultures like the Yanomami in the Amazon there is a huge disparity in reproductive success between men who have killed and those who have not.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0.104</td>\n",
       "      <td>I could not go out with a girl who did not enjoy a good amount of the foods I do. Sounds petty, but I did not continue things with a girl who did not like sushi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>0.128</td>\n",
       "      <td>it is going to be like an Always Sunny opening. \"there are hundreds of us, he cannot kill off an entire town!\" *The Mexican druglord kills an entire town*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.128</td>\n",
       "      <td>&gt;It would not be too hard for a terrorist organization to recruit a muslim without a social media presence that makes their religion obvious, and have them pay for the flight with a credit card registered under a white-sounding name. For those kind of flights you would need more than just a credit card. The background checking would exhaust most possibilities.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>0.167</td>\n",
       "      <td>why doesnt trump just threaten china woth nukes? does china have nukes? no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.167</td>\n",
       "      <td>Lot's of money to be made taking bullets out of school shooting victims I hear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.250</td>\n",
       "      <td>So I can get an understanding of your view a little further: What kind of incestuous relationships are you okay with? Just brother/sister? Father/daughter? Mother/son?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>0.250</td>\n",
       "      <td>There is a shit tone of professional research on the issues surrounding masculinity and masculine ideals. There are a bunch of books available on the subject too. It is not mainstream because men have no movement equivalent to feminism and some feminist writers see being male as a solely positive experience. If you want to learn about that stuff a book to start with is Masculinities by R. W. Connell. They are considered the top authority on masculinity in the world. If you want me to share more info reply and I will grab more book names and authors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>0.271</td>\n",
       "      <td>Kid(s) plural is a HARD NO for me. I notice I can maybe manage a woman with 1 kid, who is not on shit terms with the kid's dad. A woman who has a bachelors, masters, makes more than me, just 1 kid, great job, attractive, and has a family support network and a reliable ex is okay for me. I have been \"Seeing\" someone like that recently.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>0.426</td>\n",
       "      <td>What the hell are you talking about? Not the issues, because you cannot win that argument, obviously.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>0.447</td>\n",
       "      <td>To me it looks fucking great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>0.458</td>\n",
       "      <td>So much fucking yes. I listened to it 20 years ago and still do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.562</td>\n",
       "      <td>I do not, but then again I am in my late 30's. It seems to be a common complaint that frequency is down and prior excitement is down. I wish my wife were complaining the other way around. I would tear her ass up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.667</td>\n",
       "      <td>..... Left handed discrimination. I have heard literally everything now. Holy fucking shit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.812</td>\n",
       "      <td>I do not know, porn would solve the problem of having everyone have to fuck each other all the time to get off, leading to less unwanted children.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bws  \\\n",
       "5144 -0.562   \n",
       "5694 -0.542   \n",
       "3560 -0.511   \n",
       "5226 -0.438   \n",
       "4280 -0.417   \n",
       "1078 -0.333   \n",
       "4454 -0.271   \n",
       "396  -0.250   \n",
       "2310 -0.229   \n",
       "4388 -0.188   \n",
       "863  -0.188   \n",
       "2814 -0.188   \n",
       "5297 -0.167   \n",
       "3915 -0.146   \n",
       "641  -0.146   \n",
       "5595 -0.125   \n",
       "505  -0.125   \n",
       "5511 -0.083   \n",
       "5243 -0.062   \n",
       "2012 -0.042   \n",
       "2865 -0.042   \n",
       "1236 -0.021   \n",
       "428   0.000   \n",
       "58    0.021   \n",
       "587   0.043   \n",
       "3901  0.083   \n",
       "1828  0.104   \n",
       "4762  0.128   \n",
       "132   0.128   \n",
       "5427  0.167   \n",
       "4897  0.167   \n",
       "229   0.250   \n",
       "1491  0.250   \n",
       "1832  0.271   \n",
       "5495  0.426   \n",
       "4566  0.447   \n",
       "1542  0.458   \n",
       "997   0.562   \n",
       "557   0.667   \n",
       "2083  0.812   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text  \n",
       "5144                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This is so sexy! Love it!  \n",
       "5694                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Cross referencing and forming your own ideologies is easily one of the greatest things I learned in school.  \n",
       "3560                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Amazing dude! I salute to u! I do not feel like playing much honestly.  \n",
       "5226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Who actually cares it is just a building  \n",
       "4280                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I think it is safe to say he did not get away with it twice  \n",
       "1078                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I am European we generally start drinking about 14.  \n",
       "4454                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Anybody want some pepperoni flavored vaccines?  \n",
       "396                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Everyone should be tax exempt. The people did not consent to have their money taken, so it is immoral for the government to take any of it.  \n",
       "2310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I would hire one very specific artist and kickstart my 6-years-in-making comic book series, and advertise the living hell out of it. And if it was a success, I would make two animated adaptations - one mostly family friendly, and one more explicit than Berserk.  \n",
       "4388                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    I am getting vaxes for polio and I have autism already xD nice.  \n",
       "863                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Thanks for the tidbit of information regarding LotR. Not a fan of it myself (though I did not hate it). I agree with both Socrates and Glaucon, but maybe more towards Glaucon. Give a man invisibility, or hell, when a man thinks he is not being watched, we would be very surprised by what he would do.  \n",
       "2814                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The two next major elections are pretty pro-EU. Merkels biggest rival is more pro-EU than her (but the CDU currently still has a slight lead over the SPD) and the current projections of the French election have Macron winning, who is more pro-EU than Hollande.  \n",
       "5297                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The exact reason she should never get it.  \n",
       "3915                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Would they rather support me with public assistance or let me get a job? There do not seem to be any men clambering to support me...  \n",
       "641   Just to give a different view. From a modding perspective, the redesign finally adds, or is in the process of adding, a lot of native tools that help make moderation a lot easier for new mods. You do not have to be a CSS wizard now to set up a good looking subreddit. There are native removal reasons that will hopefully end up in mobile apps instead of being a computer only feature from toolbox. Flair filtering is finally happening. Posting requirements will work properly instead of having Automod remove posts and comments. Yes, there are a lot of complaints from mods about the redesign, but the improvements made by admins over the past few months have been incredible and show that they are listening to feedback. Just check /r/redesign weekly and you will see.  \n",
       "5595                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Why the hell are people downvoting your comment? This karma system is for the birds.  \n",
       "505                                                                                                                                                                                                                                                                                                                                                                                                                               You make a good point as far as the misinformation goes. And I do not doubt that lone individuals would be able to search out the information anyway. But it could reduce the \"benefit\" of fame that perpetrating a mass shooting has. I am not sure if the misinformation aspect would outweigh the possible benefits, but it is certainly something to think about.  \n",
       "5511                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          > she is not a politician lying through her teeth. Funny, that is exactly why we like her  \n",
       "5243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Anyone want to point out that cutting off everyone who calls him insecure, he is proving them right?  \n",
       "2012                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      did not know we put people in jail for having other religions or speaking ill of the country.  \n",
       "2865                                                                                                                                                                                                                                                                                                                                                                                                                                                           that is the thing though. The corporate candidates (the ones we are used to) are laughably bad, generic and fake when compared to someone who genuinely wants to turn things around for the country. The problem is that usually we have to choose between 2 corporate/establishment approved candidates so the contrast is not obvious.  \n",
       "1236                                                                                                                                                                                                                                                                When you create a new fat cell, your body keeps it for life. Therefore, it makes it even easier to gain weight after losing the weight from before (childhood in my case). So for people like me, who do work hard even just to maintain my weight after losing some, the question is... was it a choice for me as a kid to create all those new fat cells. Because I am stuck with them now... they just lay there waiting to be inflated by any calorie I eat and do not burn. It sucks man it is a lot harder than people think.  \n",
       "428                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               you would have one hell of a time proving beyond a reasonable doubt that the lack of vaccination lead directly and causally to the death of the child, seeing as people get illnesses despite vaccination on a non-zero-chance basis.  \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     alright first we need to define what kind of god you are referring to, if its the omnipotent omniscient god type then there is a very simple reason why it does not exist. we are unable to properly verify omnipotence, thus we are not capable of acknowledging a being as being such. thus god does not exist  \n",
       "587                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Mate, if you think kneeling has had zero effect on viewership, you are naive. The NFL **clearly** thinks kneeling is having an effect on viewership, **or they would not be doing what they are doing.**  \n",
       "3901                                                                                                                                                                                                                                                          it is just an observation on my part, though I think it can be attributed to sexual selection. Until very recently a wealthy, powerful, socially dominant provider type would have boosted the probability of a woman's genes surviving. Would be neat to see some data on this, there is always interesting stuff to be seen in studies of human sexual selection. In 'primitive' warring cultures like the Yanomami in the Amazon there is a huge disparity in reproductive success between men who have killed and those who have not.  \n",
       "1828                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I could not go out with a girl who did not enjoy a good amount of the foods I do. Sounds petty, but I did not continue things with a girl who did not like sushi.  \n",
       "4762                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         it is going to be like an Always Sunny opening. \"there are hundreds of us, he cannot kill off an entire town!\" *The Mexican druglord kills an entire town*  \n",
       "132                                                                                                                                                                                                                                                                                                                                                                                                                          >It would not be too hard for a terrorist organization to recruit a muslim without a social media presence that makes their religion obvious, and have them pay for the flight with a credit card registered under a white-sounding name. For those kind of flights you would need more than just a credit card. The background checking would exhaust most possibilities.  \n",
       "5427                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        why doesnt trump just threaten china woth nukes? does china have nukes? no.  \n",
       "4897                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Lot's of money to be made taking bullets out of school shooting victims I hear.  \n",
       "229                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             So I can get an understanding of your view a little further: What kind of incestuous relationships are you okay with? Just brother/sister? Father/daughter? Mother/son?  \n",
       "1491                                                                                                                                                                                                                        There is a shit tone of professional research on the issues surrounding masculinity and masculine ideals. There are a bunch of books available on the subject too. It is not mainstream because men have no movement equivalent to feminism and some feminist writers see being male as a solely positive experience. If you want to learn about that stuff a book to start with is Masculinities by R. W. Connell. They are considered the top authority on masculinity in the world. If you want me to share more info reply and I will grab more book names and authors.  \n",
       "1832                                                                                                                                                                                                                                                                                                                                                                                                                                                   Kid(s) plural is a HARD NO for me. I notice I can maybe manage a woman with 1 kid, who is not on shit terms with the kid's dad. A woman who has a bachelors, masters, makes more than me, just 1 kid, great job, attractive, and has a family support network and a reliable ex is okay for me. I have been \"Seeing\" someone like that recently.  \n",
       "5495                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              What the hell are you talking about? Not the issues, because you cannot win that argument, obviously.  \n",
       "4566                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       To me it looks fucking great  \n",
       "1542                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   So much fucking yes. I listened to it 20 years ago and still do.  \n",
       "997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I do not, but then again I am in my late 30's. It seems to be a common complaint that frequency is down and prior excitement is down. I wish my wife were complaining the other way around. I would tear her ass up.  \n",
       "557                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ..... Left handed discrimination. I have heard literally everything now. Holy fucking shit.  \n",
       "2083                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 I do not know, porn would solve the problem of having everyone have to fuck each other all the time to get off, leading to less unwanted children.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"bws\", \"text\"]\n",
    "df[cols].sample(40).sort_values(\"bws\").head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752d7ac",
   "metadata": {},
   "source": [
    "# Character level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71d6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col = \"length\"\n",
    "df[col] = df[\"text\"].str.len()\n",
    "df[col] = df[col].astype(np.int16)\n",
    "char_fs = [col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74a87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39565.57it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"digit_frac\"\n",
    "df[col] = df.progress_apply(digit_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddc24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 42491.71it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"letter_frac\"\n",
    "df[col] = df.progress_apply(letter_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ca5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 38431.50it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"space_frac\"\n",
    "df[col] = df.progress_apply(space_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5701ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 35912.34it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"punc_frac\"\n",
    "df[col] = df.progress_apply(punc_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a860959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39391.82it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"upper_frac\"\n",
    "df[col] = df.progress_apply(upper_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c7b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length', 'digit_frac', 'letter_frac', 'space_frac', 'punc_frac', 'upper_frac']\n"
     ]
    }
   ],
   "source": [
    "print(char_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d4202",
   "metadata": {},
   "source": [
    "# Textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def syllables_per_word(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"lexicon_count\"] + 1)\n",
    "\n",
    "\n",
    "def syllables_per_sent(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def words_per_sent(row) -> float:\n",
    "    return row[\"lexicon_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[\"text\"])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[\"text\"])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[\"text\"])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[\"text\"])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[\"text\"])\n",
    "\n",
    "\n",
    "textstat_fns: Dict[str, Callable] = {\n",
    "    \"syllables_per_word\": syllables_per_word,\n",
    "    \"syllables_per_sent\": syllables_per_sent,\n",
    "    \"words_per_sent\": words_per_sent,\n",
    "    \"flesch_reading_ease\": flesch_reading_ease,\n",
    "    \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
    "    \"gunning_fog\": gunning_fog,\n",
    "    \"smog_index\": smog_index,\n",
    "    \"automated_readability_index\": automated_readability_index,\n",
    "    \"coleman_liau_index\": coleman_liau_index,\n",
    "    \"linsear_write_formula\": linsear_write_formula,\n",
    "    \"dale_chall_readability_score\": dale_chall_readability_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d91172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 7947.37it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"syllable_count\"\n",
    "df[col] = df.progress_apply(syllable_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc45e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 70704.15it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"lexicon_count\"\n",
    "df[col] = df.progress_apply(lexicon_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 41159.00it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"sentence_count\"\n",
    "df[col] = df.progress_apply(sentence_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c32df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 89185.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 91165.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 89108.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_reading_ease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12418.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_kincaid_grade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 13197.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunning_fog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10696.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smog_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 16519.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automated_readability_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 30095.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coleman_liau_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 24671.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linsear_write_formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12275.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dale_chall_readability_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10536.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in textstat_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285247d",
   "metadata": {},
   "source": [
    "# TweetEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "167d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:11<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9025, 0.0975],\n",
      "        [0.5804, 0.4196],\n",
      "        [0.6679, 0.3321],\n",
      "        [0.8045, 0.1955],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.7749, 0.2251],\n",
      "        [0.8272, 0.1728],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.7598, 0.2402],\n",
      "        [0.9035, 0.0965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:10<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_emo_anger torch.Size([5710, 4])\n",
      "logits[:10]=tensor([[0.0376, 0.0565, 0.8628, 0.0431],\n",
      "        [0.1369, 0.1012, 0.2558, 0.5061],\n",
      "        [0.8166, 0.0105, 0.0391, 0.1338],\n",
      "        [0.9419, 0.0041, 0.0231, 0.0308],\n",
      "        [0.6140, 0.0225, 0.1561, 0.2074],\n",
      "        [0.8744, 0.0085, 0.0585, 0.0586],\n",
      "        [0.8556, 0.0071, 0.0948, 0.0425],\n",
      "        [0.8475, 0.0155, 0.0260, 0.1111],\n",
      "        [0.8054, 0.0086, 0.0704, 0.1156],\n",
      "        [0.1417, 0.3192, 0.3703, 0.1687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:10<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.0407, 0.7561, 0.2032],\n",
      "        [0.4268, 0.5488, 0.0244],\n",
      "        [0.7662, 0.2259, 0.0080],\n",
      "        [0.6066, 0.3729, 0.0206],\n",
      "        [0.5169, 0.4232, 0.0599],\n",
      "        [0.5795, 0.3848, 0.0357],\n",
      "        [0.3226, 0.6394, 0.0380],\n",
      "        [0.7787, 0.2147, 0.0066],\n",
      "        [0.7998, 0.1863, 0.0139],\n",
      "        [0.1055, 0.6091, 0.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:07<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_iro torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.7999, 0.2001],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.3392, 0.6608],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.8869, 0.1131],\n",
      "        [0.4666, 0.5334],\n",
      "        [0.7453, 0.2547],\n",
      "        [0.0874, 0.9126],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.6555, 0.3445]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:07<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_xlm_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.1049, 0.7652, 0.1299],\n",
      "        [0.1865, 0.7562, 0.0573],\n",
      "        [0.4178, 0.4738, 0.1084],\n",
      "        [0.7074, 0.2630, 0.0296],\n",
      "        [0.8242, 0.1541, 0.0217],\n",
      "        [0.5170, 0.4337, 0.0493],\n",
      "        [0.5321, 0.4271, 0.0408],\n",
      "        [0.5248, 0.4357, 0.0396],\n",
      "        [0.9013, 0.0858, 0.0129],\n",
      "        [0.3988, 0.4830, 0.1182]])\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df[\"text\"])\n",
    "for col, model_dir in conf.tweeteval_models.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir, \n",
    "        model_max_length=conf.tweeteval_model_max_length\n",
    "    )\n",
    "    #print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")\n",
    "    x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "    batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.tweeteval_batch_size, shuffle=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,conf.tweeteval_label_index[col]]\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "    del tokenizer, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e694b",
   "metadata": {},
   "source": [
    "# HateBert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d49676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/hatebert/hatebert-offenseval', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# all Hatebert models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.hatebert_models[\"hb_hatebert_off\"], \n",
    "    model_max_length=conf.hatebert_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12e71aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baba8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9598, 0.0402],\n",
      "        [0.7718, 0.2282],\n",
      "        [0.7567, 0.2433],\n",
      "        [0.9064, 0.0936],\n",
      "        [0.8356, 0.1644],\n",
      "        [0.7731, 0.2269],\n",
      "        [0.5952, 0.4048],\n",
      "        [0.8502, 0.1498],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9258, 0.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9910, 0.0090],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9631, 0.0369],\n",
      "        [0.9727, 0.0273],\n",
      "        [0.8744, 0.1256],\n",
      "        [0.9001, 0.0999],\n",
      "        [0.8544, 0.1456],\n",
      "        [0.8708, 0.1292],\n",
      "        [0.9881, 0.0119]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9377, 0.0623],\n",
      "        [0.5526, 0.4474],\n",
      "        [0.7553, 0.2447],\n",
      "        [0.7828, 0.2172],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9279, 0.0721],\n",
      "        [0.8304, 0.1696],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8965, 0.1035]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9846, 0.0154],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9699, 0.0301],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.9775, 0.0225],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9733, 0.0267],\n",
      "        [0.9407, 0.0593],\n",
      "        [0.9795, 0.0205]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.hatebert_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.hatebert_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,1]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f069f2",
   "metadata": {},
   "source": [
    "# Detoxify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a45a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 3/3 [04:02<00:00, 80.79s/it]\n"
     ]
    }
   ],
   "source": [
    "dtfy_fs = []\n",
    "for prefix, checkpoint in tqdm(conf.dtfy_models.items()):\n",
    "    res = mylib.detoxify_labels(\n",
    "        sentences,\n",
    "        checkpoint=checkpoint,\n",
    "        config_dir=conf.dtfy_configs[prefix],\n",
    "        model_max_length=conf.dtfy_model_max_length,\n",
    "        device=conf.device,\n",
    "        batch_size=conf.dtfy_batch_size\n",
    "    )\n",
    "    for k, v in res.items():\n",
    "        col = prefix + k\n",
    "        df[col] = v\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        dtfy_fs.append(col)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6312beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dto_toxicity', 'dto_severe_toxicity', 'dto_obscene', 'dto_threat', 'dto_insult', 'dto_identity_attack', 'dtu_toxicity', 'dtu_severe_toxicity', 'dtu_obscene', 'dtu_identity_attack', 'dtu_insult', 'dtu_threat', 'dtu_sexual_explicit', 'dtm_toxicity', 'dtm_severe_toxicity', 'dtm_obscene', 'dtm_identity_attack', 'dtm_insult', 'dtm_threat', 'dtm_sexual_explicit']\n"
     ]
    }
   ],
   "source": [
    "print(dtfy_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e5b5d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d1f90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480361ed11c24ee2ae00515a09887035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(5710, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(conf.em_models[\"paraphrase-MiniLM-L6-v2\"], device=conf.device)\n",
    "model.max_seq_length = conf.em_max_seq_length\n",
    "em = model.encode(sentences=sentences, batch_size=conf.em_batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bdd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "em_size = em.shape[1]\n",
    "em_cols = [f\"zz{i:04d}\" for i in range(em_size)]\n",
    "df[em_cols] = em\n",
    "df[em_cols] = df[em_cols].astype(np.float32)\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335287",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15b1d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bws</th>\n",
       "      <th>worker</th>\n",
       "      <th>length</th>\n",
       "      <th>digit_frac</th>\n",
       "      <th>letter_frac</th>\n",
       "      <th>space_frac</th>\n",
       "      <th>punc_frac</th>\n",
       "      <th>upper_frac</th>\n",
       "      <th>dto_toxicity</th>\n",
       "      <th>dto_severe_toxicity</th>\n",
       "      <th>dto_obscene</th>\n",
       "      <th>dto_threat</th>\n",
       "      <th>dto_insult</th>\n",
       "      <th>dto_identity_attack</th>\n",
       "      <th>dtu_toxicity</th>\n",
       "      <th>dtu_severe_toxicity</th>\n",
       "      <th>dtu_obscene</th>\n",
       "      <th>dtu_identity_attack</th>\n",
       "      <th>dtu_insult</th>\n",
       "      <th>dtu_threat</th>\n",
       "      <th>dtu_sexual_explicit</th>\n",
       "      <th>dtm_toxicity</th>\n",
       "      <th>dtm_severe_toxicity</th>\n",
       "      <th>dtm_obscene</th>\n",
       "      <th>dtm_identity_attack</th>\n",
       "      <th>dtm_insult</th>\n",
       "      <th>dtm_threat</th>\n",
       "      <th>dtm_sexual_explicit</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>syllables_per_sent</th>\n",
       "      <th>words_per_sent</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>hb_bert_off</th>\n",
       "      <th>hb_bert_abu</th>\n",
       "      <th>hb_hatebert_off</th>\n",
       "      <th>hb_hatebert_abu</th>\n",
       "      <th>te_roberta_off</th>\n",
       "      <th>te_roberta_emo_anger</th>\n",
       "      <th>te_roberta_snt_neg</th>\n",
       "      <th>te_roberta_iro</th>\n",
       "      <th>te_xlm_roberta_snt_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5.710000e+03</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.564098</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.788830</td>\n",
       "      <td>0.177722</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>0.177856</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.113673</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.059683</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.195873</td>\n",
       "      <td>4.698273e-03</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>0.203075</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.105158</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.083563</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.044618</td>\n",
       "      <td>1.294621</td>\n",
       "      <td>13.780085</td>\n",
       "      <td>10.045985</td>\n",
       "      <td>75.253105</td>\n",
       "      <td>6.685254</td>\n",
       "      <td>8.998004</td>\n",
       "      <td>3.062995</td>\n",
       "      <td>7.482505</td>\n",
       "      <td>6.631683</td>\n",
       "      <td>8.562484</td>\n",
       "      <td>8.299163</td>\n",
       "      <td>0.332577</td>\n",
       "      <td>0.166173</td>\n",
       "      <td>0.329977</td>\n",
       "      <td>0.144314</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.507189</td>\n",
       "      <td>0.508503</td>\n",
       "      <td>0.313383</td>\n",
       "      <td>0.576552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1648.47935</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.016744</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>0.326334</td>\n",
       "      <td>0.052992</td>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.056317</td>\n",
       "      <td>0.175381</td>\n",
       "      <td>0.064708</td>\n",
       "      <td>0.341383</td>\n",
       "      <td>2.272458e-02</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.074354</td>\n",
       "      <td>0.207780</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>0.149433</td>\n",
       "      <td>0.345334</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.272925</td>\n",
       "      <td>0.075226</td>\n",
       "      <td>0.214901</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.155314</td>\n",
       "      <td>0.195702</td>\n",
       "      <td>8.242771</td>\n",
       "      <td>5.752335</td>\n",
       "      <td>19.903004</td>\n",
       "      <td>4.430519</td>\n",
       "      <td>4.645890</td>\n",
       "      <td>4.695458</td>\n",
       "      <td>5.593331</td>\n",
       "      <td>3.883116</td>\n",
       "      <td>5.906460</td>\n",
       "      <td>2.270676</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.278667</td>\n",
       "      <td>0.284761</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.357695</td>\n",
       "      <td>0.319341</td>\n",
       "      <td>0.276529</td>\n",
       "      <td>0.302263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.529070e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-48.980000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.700000</td>\n",
       "      <td>-10.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.007973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>58.09000</td>\n",
       "      <td>-0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672759</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1.087282e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>19.430301</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.003700</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.018760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>286.45000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1.200621e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.869999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.074244</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>0.051341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>571.90000</td>\n",
       "      <td>-0.426000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.271093e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>50.669998</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>2.741667</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.049953</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.039984</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.046494</td>\n",
       "      <td>0.107111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1142.80000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.161966</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>1.407266e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.139535</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>59.980000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.698000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.124509</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.146359</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.239498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>1713.70000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>1.645227e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.194919</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>66.739998</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.364000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>0.113060</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.161852</td>\n",
       "      <td>0.175718</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.102903</td>\n",
       "      <td>0.384754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>2284.60000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>2.303226e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1.247088</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>72.144003</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.157839</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>0.208463</td>\n",
       "      <td>0.321477</td>\n",
       "      <td>0.416262</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>0.514975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792852</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>4.173747e-06</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1.288299</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>76.220001</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>0.171648</td>\n",
       "      <td>0.027659</td>\n",
       "      <td>0.218091</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>0.265905</td>\n",
       "      <td>0.526801</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.200985</td>\n",
       "      <td>0.644350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>3426.40000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798788</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>1.015833e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>80.919998</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>7.484000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>0.282971</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.310787</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.342768</td>\n",
       "      <td>0.714927</td>\n",
       "      <td>0.652210</td>\n",
       "      <td>0.291033</td>\n",
       "      <td>0.753180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3997.30000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.188464</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.056457</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>3.191344e-05</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.091781</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.382353</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>85.690002</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>10.853000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>8.460000</td>\n",
       "      <td>10.676667</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>0.460070</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.439863</td>\n",
       "      <td>0.106683</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>0.837082</td>\n",
       "      <td>0.758375</td>\n",
       "      <td>0.414743</td>\n",
       "      <td>0.831708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4568.20000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>0.194306</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.318193</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.430039</td>\n",
       "      <td>1.706842e-04</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.487258</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>91.110001</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>12.134000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>9.520000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.615488</td>\n",
       "      <td>0.189939</td>\n",
       "      <td>0.589677</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.584716</td>\n",
       "      <td>0.885163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5139.10000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.670921</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.168232</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.930690</td>\n",
       "      <td>4.385715e-03</td>\n",
       "      <td>0.736380</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.295351</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.042829</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.658297</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.306216</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.079094</td>\n",
       "      <td>1.533957</td>\n",
       "      <td>24.755000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>99.570000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>14.501000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>11.140000</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.928643</td>\n",
       "      <td>0.710093</td>\n",
       "      <td>0.824093</td>\n",
       "      <td>0.460149</td>\n",
       "      <td>0.784665</td>\n",
       "      <td>0.955451</td>\n",
       "      <td>0.921829</td>\n",
       "      <td>0.786549</td>\n",
       "      <td>0.922117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5424.55000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577.550000</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.985316</td>\n",
       "      <td>0.086339</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.480264</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>0.979522</td>\n",
       "      <td>2.221569e-02</td>\n",
       "      <td>0.934339</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.283533</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.911508</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.689002</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>1.622222</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>105.660004</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>11.830000</td>\n",
       "      <td>0.960833</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.737487</td>\n",
       "      <td>0.858253</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.953920</td>\n",
       "      <td>0.886064</td>\n",
       "      <td>0.938671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5652.91000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.910000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.119969</td>\n",
       "      <td>0.159718</td>\n",
       "      <td>0.997169</td>\n",
       "      <td>0.282513</td>\n",
       "      <td>0.984720</td>\n",
       "      <td>0.317607</td>\n",
       "      <td>0.887015</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.994499</td>\n",
       "      <td>1.104791e-01</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.457570</td>\n",
       "      <td>0.947763</td>\n",
       "      <td>0.401428</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.994160</td>\n",
       "      <td>0.127040</td>\n",
       "      <td>0.977652</td>\n",
       "      <td>0.404110</td>\n",
       "      <td>0.969594</td>\n",
       "      <td>0.472689</td>\n",
       "      <td>0.890709</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>116.150002</td>\n",
       "      <td>20.373000</td>\n",
       "      <td>23.709999</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>16.534699</td>\n",
       "      <td>29.455000</td>\n",
       "      <td>14.561900</td>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.967271</td>\n",
       "      <td>0.957988</td>\n",
       "      <td>0.945889</td>\n",
       "      <td>0.913508</td>\n",
       "      <td>0.979008</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.960554</td>\n",
       "      <td>0.955537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.764529</td>\n",
       "      <td>0.994431</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>4.605981e-01</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>118.680000</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>55.520000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>29.150000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.985018</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.966720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label          bws  worker       length   digit_frac  letter_frac  \\\n",
       "count  5710.00000  5710.000000  5710.0  5710.000000  5710.000000  5710.000000   \n",
       "mean   2855.50000    -0.027706     0.0   197.564098     0.003542     0.788830   \n",
       "std    1648.47935     0.334195     0.0   172.016744     0.012983     0.034318   \n",
       "min       1.00000    -0.889000     0.0    15.000000     0.000000     0.400000   \n",
       "1%       58.09000    -0.667000     0.0    24.000000     0.000000     0.672759   \n",
       "5%      286.45000    -0.521000     0.0    33.000000     0.000000     0.733333   \n",
       "10%     571.90000    -0.426000     0.0    42.000000     0.000000     0.750000   \n",
       "20%    1142.80000    -0.312000     0.0    60.000000     0.000000     0.769841   \n",
       "30%    1713.70000    -0.213000     0.0    82.000000     0.000000     0.779661   \n",
       "40%    2284.60000    -0.146000     0.0   106.000000     0.000000     0.786537   \n",
       "50%    2855.50000    -0.062000     0.0   137.000000     0.000000     0.792852   \n",
       "60%    3426.40000     0.021000     0.0   177.000000     0.000000     0.798788   \n",
       "70%    3997.30000     0.104000     0.0   233.000000     0.000000     0.805556   \n",
       "80%    4568.20000     0.229000     0.0   317.000000     0.000000     0.812900   \n",
       "90%    5139.10000     0.458000     0.0   458.000000     0.009662     0.822917   \n",
       "95%    5424.55000     0.625000     0.0   577.550000     0.022415     0.831579   \n",
       "99%    5652.91000     0.833000     0.0   749.910000     0.060606     0.857143   \n",
       "max    5710.00000     0.979000     0.0   917.000000     0.235294     0.897436   \n",
       "\n",
       "        space_frac    punc_frac   upper_frac  dto_toxicity  \\\n",
       "count  5710.000000  5710.000000  5710.000000   5710.000000   \n",
       "mean      0.177722     0.029905     0.030517      0.177856   \n",
       "std       0.021473     0.024070     0.049035      0.326334   \n",
       "min       0.040541     0.000000     0.000000      0.000506   \n",
       "1%        0.117647     0.000000     0.000000      0.000556   \n",
       "5%        0.141414     0.000000     0.005062      0.000614   \n",
       "10%       0.151515     0.010417     0.008333      0.000668   \n",
       "20%       0.161966     0.015385     0.011758      0.000797   \n",
       "30%       0.168627     0.018692     0.014599      0.001006   \n",
       "40%       0.173913     0.021652     0.017857      0.001533   \n",
       "50%       0.178947     0.025000     0.021277      0.004124   \n",
       "60%       0.183486     0.028571     0.025502      0.015243   \n",
       "70%       0.188464     0.032787     0.030928      0.056457   \n",
       "80%       0.194306     0.040000     0.038981      0.318193   \n",
       "90%       0.202703     0.054054     0.054560      0.887332   \n",
       "95%       0.210526     0.069767     0.074074      0.985316   \n",
       "99%       0.227273     0.119969     0.159718      0.997169   \n",
       "max       0.272727     0.402174     0.857143      0.999072   \n",
       "\n",
       "       dto_severe_toxicity  dto_obscene   dto_threat   dto_insult  \\\n",
       "count          5710.000000  5710.000000  5710.000000  5710.000000   \n",
       "mean              0.013080     0.113673     0.008411     0.059683   \n",
       "std               0.052992     0.282462     0.056317     0.175381   \n",
       "min               0.000080     0.000141     0.000086     0.000164   \n",
       "1%                0.000087     0.000158     0.000096     0.000171   \n",
       "5%                0.000093     0.000165     0.000103     0.000175   \n",
       "10%               0.000097     0.000170     0.000108     0.000177   \n",
       "20%               0.000103     0.000176     0.000115     0.000181   \n",
       "30%               0.000108     0.000183     0.000121     0.000188   \n",
       "40%               0.000114     0.000196     0.000127     0.000207   \n",
       "50%               0.000121     0.000280     0.000138     0.000298   \n",
       "60%               0.000132     0.000578     0.000209     0.000679   \n",
       "70%               0.000225     0.001707     0.000431     0.002063   \n",
       "80%               0.001118     0.018481     0.001115     0.014511   \n",
       "90%               0.016841     0.670921     0.003118     0.168232   \n",
       "95%               0.086339     0.948901     0.009527     0.480264   \n",
       "99%               0.282513     0.984720     0.317607     0.887015   \n",
       "max               0.764529     0.994431     0.823060     0.980776   \n",
       "\n",
       "       dto_identity_attack  dtu_toxicity  dtu_severe_toxicity  dtu_obscene  \\\n",
       "count          5710.000000   5710.000000         5.710000e+03  5710.000000   \n",
       "mean              0.011454      0.195873         4.698273e-03     0.113027   \n",
       "std               0.064708      0.341383         2.272458e-02     0.285412   \n",
       "min               0.000121      0.000286         9.529070e-07     0.000017   \n",
       "1%                0.000134      0.000360         1.087282e-06     0.000021   \n",
       "5%                0.000138      0.000410         1.200621e-06     0.000024   \n",
       "10%               0.000140      0.000454         1.271093e-06     0.000026   \n",
       "20%               0.000145      0.000572         1.407266e-06     0.000031   \n",
       "30%               0.000151      0.000850         1.645227e-06     0.000041   \n",
       "40%               0.000165      0.001636         2.303226e-06     0.000067   \n",
       "50%               0.000211      0.003793         4.173747e-06     0.000131   \n",
       "60%               0.000361      0.014255         1.015833e-05     0.000302   \n",
       "70%               0.000867      0.078342         3.191344e-05     0.000959   \n",
       "80%               0.002603      0.430039         1.706842e-04     0.006408   \n",
       "90%               0.009993      0.930690         4.385715e-03     0.736380   \n",
       "95%               0.032305      0.979522         2.221569e-02     0.934339   \n",
       "99%               0.263866      0.994499         1.104791e-01     0.975236   \n",
       "max               0.894015      0.998344         4.605981e-01     0.987875   \n",
       "\n",
       "       dtu_identity_attack   dtu_insult   dtu_threat  dtu_sexual_explicit  \\\n",
       "count          5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean              0.015234     0.081492     0.011010             0.040167   \n",
       "std               0.074354     0.207780     0.069685             0.149433   \n",
       "min               0.000052     0.000061     0.000012             0.000009   \n",
       "1%                0.000063     0.000092     0.000015             0.000011   \n",
       "5%                0.000070     0.000103     0.000017             0.000012   \n",
       "10%               0.000076     0.000111     0.000019             0.000013   \n",
       "20%               0.000089     0.000133     0.000023             0.000016   \n",
       "30%               0.000113     0.000177     0.000030             0.000021   \n",
       "40%               0.000175     0.000311     0.000048             0.000033   \n",
       "50%               0.000366     0.000660     0.000089             0.000069   \n",
       "60%               0.000847     0.001623     0.000180             0.000176   \n",
       "70%               0.002036     0.005559     0.000397             0.000531   \n",
       "80%               0.004938     0.042105     0.000974             0.003249   \n",
       "90%               0.015910     0.295351     0.002905             0.042829   \n",
       "95%               0.042194     0.656381     0.014624             0.283533   \n",
       "99%               0.457570     0.947763     0.401428             0.863210   \n",
       "max               0.984674     0.993023     0.925068             0.974648   \n",
       "\n",
       "       dtm_toxicity  dtm_severe_toxicity  dtm_obscene  dtm_identity_attack  \\\n",
       "count   5710.000000          5710.000000  5710.000000          5710.000000   \n",
       "mean       0.203075             0.005742     0.105158             0.013474   \n",
       "std        0.345334             0.027226     0.272925             0.075226   \n",
       "min        0.000178             0.000009     0.000063             0.000045   \n",
       "1%         0.000281             0.000013     0.000095             0.000066   \n",
       "5%         0.000357             0.000016     0.000115             0.000078   \n",
       "10%        0.000417             0.000019     0.000129             0.000086   \n",
       "20%        0.000578             0.000023     0.000159             0.000099   \n",
       "30%        0.000857             0.000027     0.000201             0.000118   \n",
       "40%        0.001655             0.000033     0.000272             0.000152   \n",
       "50%        0.004238             0.000046     0.000438             0.000244   \n",
       "60%        0.015952             0.000085     0.000760             0.000504   \n",
       "70%        0.091781             0.000210     0.001610             0.001241   \n",
       "80%        0.487258             0.000817     0.005910             0.003259   \n",
       "90%        0.927200             0.007909     0.658297             0.010893   \n",
       "95%        0.976718             0.029604     0.911508             0.032165   \n",
       "99%        0.994160             0.127040     0.977652             0.404110   \n",
       "max        0.999047             0.672039     0.993243             0.965869   \n",
       "\n",
       "        dtm_insult   dtm_threat  dtm_sexual_explicit  syllables_per_word  \\\n",
       "count  5710.000000  5710.000000          5710.000000         5710.000000   \n",
       "mean      0.083563     0.014735             0.044618            1.294621   \n",
       "std       0.214901     0.078828             0.155314            0.195702   \n",
       "min       0.000095     0.000014             0.000012            0.800000   \n",
       "1%        0.000149     0.000021             0.000017            0.857143   \n",
       "5%        0.000177     0.000027             0.000020            1.000000   \n",
       "10%       0.000200     0.000031             0.000022            1.052632   \n",
       "20%       0.000247     0.000037             0.000026            1.139535   \n",
       "30%       0.000327     0.000046             0.000032            1.194919   \n",
       "40%       0.000511     0.000065             0.000045            1.247088   \n",
       "50%       0.001043     0.000123             0.000090            1.288299   \n",
       "60%       0.002455     0.000310             0.000239            1.333333   \n",
       "70%       0.007981     0.000952             0.000792            1.382353   \n",
       "80%       0.041335     0.002956             0.004605            1.444444   \n",
       "90%       0.306216     0.010762             0.079094            1.533957   \n",
       "95%       0.689002     0.036829             0.330517            1.622222   \n",
       "99%       0.969594     0.472689             0.890709            1.833333   \n",
       "max       0.994790     0.962406             0.982923            2.500000   \n",
       "\n",
       "       syllables_per_sent  words_per_sent  flesch_reading_ease  \\\n",
       "count         5710.000000     5710.000000          5710.000000   \n",
       "mean            13.780085       10.045985            75.253105   \n",
       "std              8.242771        5.752335            19.903004   \n",
       "min              1.500000        1.000000           -48.980000   \n",
       "1%               3.000000        2.500000            19.430301   \n",
       "5%               4.000000        3.000000            41.869999   \n",
       "10%              5.000000        3.666667            50.669998   \n",
       "20%              6.500000        5.000000            59.980000   \n",
       "30%              8.500000        6.333333            66.739998   \n",
       "40%             10.000000        7.500000            72.144003   \n",
       "50%             12.250000        9.000000            76.220001   \n",
       "60%             14.500000       10.500000            80.919998   \n",
       "70%             16.799999       12.250000            85.690002   \n",
       "80%             20.000000       14.500000            91.110001   \n",
       "90%             24.755000       17.600000            99.570000   \n",
       "95%             29.000000       20.500000           105.660004   \n",
       "99%             39.000000       27.000000           116.150002   \n",
       "max             96.000000       65.000000           118.680000   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog   smog_index  \\\n",
       "count           5710.000000  5710.000000  5710.000000   \n",
       "mean               6.685254     8.998004     3.062995   \n",
       "std                4.430519     4.645890     4.695458   \n",
       "min               -2.500000     0.800000     0.000000   \n",
       "1%                -1.500000     2.000000     0.000000   \n",
       "5%                 0.500000     2.400000     0.000000   \n",
       "10%                1.700000     3.200000     0.000000   \n",
       "20%                3.100000     4.870000     0.000000   \n",
       "30%                4.400000     6.364000     0.000000   \n",
       "40%                5.300000     8.000000     0.000000   \n",
       "50%                6.400000     8.510000     0.000000   \n",
       "60%                7.200000     9.600000     0.000000   \n",
       "70%                8.400000    10.853000     6.000000   \n",
       "80%                9.900000    12.134000     8.800000   \n",
       "90%               12.100000    14.501000    10.700000   \n",
       "95%               14.200000    16.930000    12.000000   \n",
       "99%               20.373000    23.709999    14.300000   \n",
       "max               51.599998    55.520000    18.900000   \n",
       "\n",
       "       automated_readability_index  coleman_liau_index  linsear_write_formula  \\\n",
       "count                  5710.000000         5710.000000            5710.000000   \n",
       "mean                      7.482505            6.631683               8.562484   \n",
       "std                       5.593331            3.883116               5.906460   \n",
       "min                      -8.700000          -10.160000               0.000000   \n",
       "1%                       -3.000000           -3.003700               1.500000   \n",
       "5%                       -0.200000            0.320000               2.000000   \n",
       "10%                       1.290000            1.820000               2.741667   \n",
       "20%                       3.200000            3.698000               4.000000   \n",
       "30%                       4.600000            4.930000               5.000000   \n",
       "40%                       5.800000            5.900000               6.000000   \n",
       "50%                       7.000000            6.680000               7.000000   \n",
       "60%                       8.200000            7.484000               8.250000   \n",
       "70%                       9.400000            8.460000              10.676667   \n",
       "80%                      11.200000            9.520000              12.500000   \n",
       "90%                      13.800000           11.140000              15.666667   \n",
       "95%                      16.600000           12.620000              19.250000   \n",
       "99%                      24.799999           16.534699              29.455000   \n",
       "max                      64.900002           40.599998              66.000000   \n",
       "\n",
       "       dale_chall_readability_score  hb_bert_off  hb_bert_abu  \\\n",
       "count                   5710.000000  5710.000000  5710.000000   \n",
       "mean                       8.299163     0.332577     0.166173   \n",
       "std                        2.270676     0.332031     0.278667   \n",
       "min                        0.200000     0.008860     0.002739   \n",
       "1%                         0.350000     0.013618     0.003827   \n",
       "5%                         5.620000     0.021350     0.005177   \n",
       "10%                        6.240000     0.029108     0.006430   \n",
       "20%                        6.930000     0.045445     0.009145   \n",
       "30%                        7.380000     0.071743     0.012743   \n",
       "40%                        7.820000     0.108833     0.018178   \n",
       "50%                        8.210000     0.171648     0.027659   \n",
       "60%                        8.590000     0.282971     0.048089   \n",
       "70%                        9.120000     0.460070     0.097038   \n",
       "80%                        9.760000     0.719423     0.248265   \n",
       "90%                       10.750000     0.928643     0.710093   \n",
       "95%                       11.830000     0.960833     0.914900   \n",
       "99%                       14.561900     0.972503     0.967271   \n",
       "max                       29.150000     0.978723     0.977543   \n",
       "\n",
       "       hb_hatebert_off  hb_hatebert_abu  te_roberta_off  te_roberta_emo_anger  \\\n",
       "count      5710.000000      5710.000000     5710.000000           5710.000000   \n",
       "mean          0.329977         0.144314        0.350061              0.507189   \n",
       "std           0.284761         0.221301        0.251317              0.357695   \n",
       "min           0.007778         0.007624        0.021641              0.004902   \n",
       "1%            0.021895         0.010283        0.049634              0.010852   \n",
       "5%            0.036465         0.013695        0.074244              0.024071   \n",
       "10%           0.049953         0.016057        0.091896              0.039984   \n",
       "20%           0.078526         0.020993        0.124509              0.089963   \n",
       "30%           0.113060         0.027239        0.161852              0.175718   \n",
       "40%           0.157839         0.035502        0.208463              0.321477   \n",
       "50%           0.218091         0.047703        0.265905              0.526801   \n",
       "60%           0.310787         0.067547        0.342768              0.714927   \n",
       "70%           0.439863         0.106683        0.449289              0.837082   \n",
       "80%           0.615488         0.189939        0.589677              0.911141   \n",
       "90%           0.824093         0.460149        0.784665              0.955451   \n",
       "95%           0.908639         0.737487        0.858253              0.968262   \n",
       "99%           0.957988         0.945889        0.913508              0.979008   \n",
       "max           0.979833         0.977078        0.950407              0.985018   \n",
       "\n",
       "       te_roberta_snt_neg  te_roberta_iro  te_xlm_roberta_snt_neg  \n",
       "count         5710.000000     5710.000000             5710.000000  \n",
       "mean             0.508503        0.313383                0.576552  \n",
       "std              0.319341        0.276529                0.302263  \n",
       "min              0.000799        0.014366                0.007973  \n",
       "1%               0.001768        0.022520                0.018760  \n",
       "5%               0.008642        0.034839                0.051341  \n",
       "10%              0.032663        0.046494                0.107111  \n",
       "20%              0.146359        0.072034                0.239498  \n",
       "30%              0.295210        0.102903                0.384754  \n",
       "40%              0.416262        0.145013                0.514975  \n",
       "50%              0.535722        0.200985                0.644350  \n",
       "60%              0.652210        0.291033                0.753180  \n",
       "70%              0.758375        0.414743                0.831708  \n",
       "80%              0.846273        0.584716                0.885163  \n",
       "90%              0.921829        0.786549                0.922117  \n",
       "95%              0.953920        0.886064                0.938671  \n",
       "99%              0.973875        0.960554                0.955537  \n",
       "max              0.982809        0.990079                0.966720  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"worker\"\n",
    "df[col] = 0\n",
    "df[col] = df[col].astype(np.int8)\n",
    "cols = [\"label\", \"bws\", \"worker\"]\n",
    "cols += char_fs + dtfy_fs\n",
    "cols += list(textstat_fns.keys())\n",
    "cols += list(conf.hatebert_models.keys()) \n",
    "cols += list(conf.tweeteval_models.keys()) \n",
    "df[cols].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bddf8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 433 columns):\n",
      " #    Column                        Non-Null Count  Dtype  \n",
      "---   ------                        --------------  -----  \n",
      " 0    label                         5710 non-null   int32  \n",
      " 1    bws                           5710 non-null   float32\n",
      " 2    worker                        5710 non-null   int8   \n",
      " 3    length                        5710 non-null   int16  \n",
      " 4    digit_frac                    5710 non-null   float32\n",
      " 5    letter_frac                   5710 non-null   float32\n",
      " 6    space_frac                    5710 non-null   float32\n",
      " 7    punc_frac                     5710 non-null   float32\n",
      " 8    upper_frac                    5710 non-null   float32\n",
      " 9    dto_toxicity                  5710 non-null   float32\n",
      " 10   dto_severe_toxicity           5710 non-null   float32\n",
      " 11   dto_obscene                   5710 non-null   float32\n",
      " 12   dto_threat                    5710 non-null   float32\n",
      " 13   dto_insult                    5710 non-null   float32\n",
      " 14   dto_identity_attack           5710 non-null   float32\n",
      " 15   dtu_toxicity                  5710 non-null   float32\n",
      " 16   dtu_severe_toxicity           5710 non-null   float32\n",
      " 17   dtu_obscene                   5710 non-null   float32\n",
      " 18   dtu_identity_attack           5710 non-null   float32\n",
      " 19   dtu_insult                    5710 non-null   float32\n",
      " 20   dtu_threat                    5710 non-null   float32\n",
      " 21   dtu_sexual_explicit           5710 non-null   float32\n",
      " 22   dtm_toxicity                  5710 non-null   float32\n",
      " 23   dtm_severe_toxicity           5710 non-null   float32\n",
      " 24   dtm_obscene                   5710 non-null   float32\n",
      " 25   dtm_identity_attack           5710 non-null   float32\n",
      " 26   dtm_insult                    5710 non-null   float32\n",
      " 27   dtm_threat                    5710 non-null   float32\n",
      " 28   dtm_sexual_explicit           5710 non-null   float32\n",
      " 29   syllables_per_word            5710 non-null   float32\n",
      " 30   syllables_per_sent            5710 non-null   float32\n",
      " 31   words_per_sent                5710 non-null   float32\n",
      " 32   flesch_reading_ease           5710 non-null   float32\n",
      " 33   flesch_kincaid_grade          5710 non-null   float32\n",
      " 34   gunning_fog                   5710 non-null   float32\n",
      " 35   smog_index                    5710 non-null   float32\n",
      " 36   automated_readability_index   5710 non-null   float32\n",
      " 37   coleman_liau_index            5710 non-null   float32\n",
      " 38   linsear_write_formula         5710 non-null   float32\n",
      " 39   dale_chall_readability_score  5710 non-null   float32\n",
      " 40   hb_bert_off                   5710 non-null   float32\n",
      " 41   hb_bert_abu                   5710 non-null   float32\n",
      " 42   hb_hatebert_off               5710 non-null   float32\n",
      " 43   hb_hatebert_abu               5710 non-null   float32\n",
      " 44   te_roberta_off                5710 non-null   float32\n",
      " 45   te_roberta_emo_anger          5710 non-null   float32\n",
      " 46   te_roberta_snt_neg            5710 non-null   float32\n",
      " 47   te_roberta_iro                5710 non-null   float32\n",
      " 48   te_xlm_roberta_snt_neg        5710 non-null   float32\n",
      " 49   zz0000                        5710 non-null   float32\n",
      " 50   zz0001                        5710 non-null   float32\n",
      " 51   zz0002                        5710 non-null   float32\n",
      " 52   zz0003                        5710 non-null   float32\n",
      " 53   zz0004                        5710 non-null   float32\n",
      " 54   zz0005                        5710 non-null   float32\n",
      " 55   zz0006                        5710 non-null   float32\n",
      " 56   zz0007                        5710 non-null   float32\n",
      " 57   zz0008                        5710 non-null   float32\n",
      " 58   zz0009                        5710 non-null   float32\n",
      " 59   zz0010                        5710 non-null   float32\n",
      " 60   zz0011                        5710 non-null   float32\n",
      " 61   zz0012                        5710 non-null   float32\n",
      " 62   zz0013                        5710 non-null   float32\n",
      " 63   zz0014                        5710 non-null   float32\n",
      " 64   zz0015                        5710 non-null   float32\n",
      " 65   zz0016                        5710 non-null   float32\n",
      " 66   zz0017                        5710 non-null   float32\n",
      " 67   zz0018                        5710 non-null   float32\n",
      " 68   zz0019                        5710 non-null   float32\n",
      " 69   zz0020                        5710 non-null   float32\n",
      " 70   zz0021                        5710 non-null   float32\n",
      " 71   zz0022                        5710 non-null   float32\n",
      " 72   zz0023                        5710 non-null   float32\n",
      " 73   zz0024                        5710 non-null   float32\n",
      " 74   zz0025                        5710 non-null   float32\n",
      " 75   zz0026                        5710 non-null   float32\n",
      " 76   zz0027                        5710 non-null   float32\n",
      " 77   zz0028                        5710 non-null   float32\n",
      " 78   zz0029                        5710 non-null   float32\n",
      " 79   zz0030                        5710 non-null   float32\n",
      " 80   zz0031                        5710 non-null   float32\n",
      " 81   zz0032                        5710 non-null   float32\n",
      " 82   zz0033                        5710 non-null   float32\n",
      " 83   zz0034                        5710 non-null   float32\n",
      " 84   zz0035                        5710 non-null   float32\n",
      " 85   zz0036                        5710 non-null   float32\n",
      " 86   zz0037                        5710 non-null   float32\n",
      " 87   zz0038                        5710 non-null   float32\n",
      " 88   zz0039                        5710 non-null   float32\n",
      " 89   zz0040                        5710 non-null   float32\n",
      " 90   zz0041                        5710 non-null   float32\n",
      " 91   zz0042                        5710 non-null   float32\n",
      " 92   zz0043                        5710 non-null   float32\n",
      " 93   zz0044                        5710 non-null   float32\n",
      " 94   zz0045                        5710 non-null   float32\n",
      " 95   zz0046                        5710 non-null   float32\n",
      " 96   zz0047                        5710 non-null   float32\n",
      " 97   zz0048                        5710 non-null   float32\n",
      " 98   zz0049                        5710 non-null   float32\n",
      " 99   zz0050                        5710 non-null   float32\n",
      " 100  zz0051                        5710 non-null   float32\n",
      " 101  zz0052                        5710 non-null   float32\n",
      " 102  zz0053                        5710 non-null   float32\n",
      " 103  zz0054                        5710 non-null   float32\n",
      " 104  zz0055                        5710 non-null   float32\n",
      " 105  zz0056                        5710 non-null   float32\n",
      " 106  zz0057                        5710 non-null   float32\n",
      " 107  zz0058                        5710 non-null   float32\n",
      " 108  zz0059                        5710 non-null   float32\n",
      " 109  zz0060                        5710 non-null   float32\n",
      " 110  zz0061                        5710 non-null   float32\n",
      " 111  zz0062                        5710 non-null   float32\n",
      " 112  zz0063                        5710 non-null   float32\n",
      " 113  zz0064                        5710 non-null   float32\n",
      " 114  zz0065                        5710 non-null   float32\n",
      " 115  zz0066                        5710 non-null   float32\n",
      " 116  zz0067                        5710 non-null   float32\n",
      " 117  zz0068                        5710 non-null   float32\n",
      " 118  zz0069                        5710 non-null   float32\n",
      " 119  zz0070                        5710 non-null   float32\n",
      " 120  zz0071                        5710 non-null   float32\n",
      " 121  zz0072                        5710 non-null   float32\n",
      " 122  zz0073                        5710 non-null   float32\n",
      " 123  zz0074                        5710 non-null   float32\n",
      " 124  zz0075                        5710 non-null   float32\n",
      " 125  zz0076                        5710 non-null   float32\n",
      " 126  zz0077                        5710 non-null   float32\n",
      " 127  zz0078                        5710 non-null   float32\n",
      " 128  zz0079                        5710 non-null   float32\n",
      " 129  zz0080                        5710 non-null   float32\n",
      " 130  zz0081                        5710 non-null   float32\n",
      " 131  zz0082                        5710 non-null   float32\n",
      " 132  zz0083                        5710 non-null   float32\n",
      " 133  zz0084                        5710 non-null   float32\n",
      " 134  zz0085                        5710 non-null   float32\n",
      " 135  zz0086                        5710 non-null   float32\n",
      " 136  zz0087                        5710 non-null   float32\n",
      " 137  zz0088                        5710 non-null   float32\n",
      " 138  zz0089                        5710 non-null   float32\n",
      " 139  zz0090                        5710 non-null   float32\n",
      " 140  zz0091                        5710 non-null   float32\n",
      " 141  zz0092                        5710 non-null   float32\n",
      " 142  zz0093                        5710 non-null   float32\n",
      " 143  zz0094                        5710 non-null   float32\n",
      " 144  zz0095                        5710 non-null   float32\n",
      " 145  zz0096                        5710 non-null   float32\n",
      " 146  zz0097                        5710 non-null   float32\n",
      " 147  zz0098                        5710 non-null   float32\n",
      " 148  zz0099                        5710 non-null   float32\n",
      " 149  zz0100                        5710 non-null   float32\n",
      " 150  zz0101                        5710 non-null   float32\n",
      " 151  zz0102                        5710 non-null   float32\n",
      " 152  zz0103                        5710 non-null   float32\n",
      " 153  zz0104                        5710 non-null   float32\n",
      " 154  zz0105                        5710 non-null   float32\n",
      " 155  zz0106                        5710 non-null   float32\n",
      " 156  zz0107                        5710 non-null   float32\n",
      " 157  zz0108                        5710 non-null   float32\n",
      " 158  zz0109                        5710 non-null   float32\n",
      " 159  zz0110                        5710 non-null   float32\n",
      " 160  zz0111                        5710 non-null   float32\n",
      " 161  zz0112                        5710 non-null   float32\n",
      " 162  zz0113                        5710 non-null   float32\n",
      " 163  zz0114                        5710 non-null   float32\n",
      " 164  zz0115                        5710 non-null   float32\n",
      " 165  zz0116                        5710 non-null   float32\n",
      " 166  zz0117                        5710 non-null   float32\n",
      " 167  zz0118                        5710 non-null   float32\n",
      " 168  zz0119                        5710 non-null   float32\n",
      " 169  zz0120                        5710 non-null   float32\n",
      " 170  zz0121                        5710 non-null   float32\n",
      " 171  zz0122                        5710 non-null   float32\n",
      " 172  zz0123                        5710 non-null   float32\n",
      " 173  zz0124                        5710 non-null   float32\n",
      " 174  zz0125                        5710 non-null   float32\n",
      " 175  zz0126                        5710 non-null   float32\n",
      " 176  zz0127                        5710 non-null   float32\n",
      " 177  zz0128                        5710 non-null   float32\n",
      " 178  zz0129                        5710 non-null   float32\n",
      " 179  zz0130                        5710 non-null   float32\n",
      " 180  zz0131                        5710 non-null   float32\n",
      " 181  zz0132                        5710 non-null   float32\n",
      " 182  zz0133                        5710 non-null   float32\n",
      " 183  zz0134                        5710 non-null   float32\n",
      " 184  zz0135                        5710 non-null   float32\n",
      " 185  zz0136                        5710 non-null   float32\n",
      " 186  zz0137                        5710 non-null   float32\n",
      " 187  zz0138                        5710 non-null   float32\n",
      " 188  zz0139                        5710 non-null   float32\n",
      " 189  zz0140                        5710 non-null   float32\n",
      " 190  zz0141                        5710 non-null   float32\n",
      " 191  zz0142                        5710 non-null   float32\n",
      " 192  zz0143                        5710 non-null   float32\n",
      " 193  zz0144                        5710 non-null   float32\n",
      " 194  zz0145                        5710 non-null   float32\n",
      " 195  zz0146                        5710 non-null   float32\n",
      " 196  zz0147                        5710 non-null   float32\n",
      " 197  zz0148                        5710 non-null   float32\n",
      " 198  zz0149                        5710 non-null   float32\n",
      " 199  zz0150                        5710 non-null   float32\n",
      " 200  zz0151                        5710 non-null   float32\n",
      " 201  zz0152                        5710 non-null   float32\n",
      " 202  zz0153                        5710 non-null   float32\n",
      " 203  zz0154                        5710 non-null   float32\n",
      " 204  zz0155                        5710 non-null   float32\n",
      " 205  zz0156                        5710 non-null   float32\n",
      " 206  zz0157                        5710 non-null   float32\n",
      " 207  zz0158                        5710 non-null   float32\n",
      " 208  zz0159                        5710 non-null   float32\n",
      " 209  zz0160                        5710 non-null   float32\n",
      " 210  zz0161                        5710 non-null   float32\n",
      " 211  zz0162                        5710 non-null   float32\n",
      " 212  zz0163                        5710 non-null   float32\n",
      " 213  zz0164                        5710 non-null   float32\n",
      " 214  zz0165                        5710 non-null   float32\n",
      " 215  zz0166                        5710 non-null   float32\n",
      " 216  zz0167                        5710 non-null   float32\n",
      " 217  zz0168                        5710 non-null   float32\n",
      " 218  zz0169                        5710 non-null   float32\n",
      " 219  zz0170                        5710 non-null   float32\n",
      " 220  zz0171                        5710 non-null   float32\n",
      " 221  zz0172                        5710 non-null   float32\n",
      " 222  zz0173                        5710 non-null   float32\n",
      " 223  zz0174                        5710 non-null   float32\n",
      " 224  zz0175                        5710 non-null   float32\n",
      " 225  zz0176                        5710 non-null   float32\n",
      " 226  zz0177                        5710 non-null   float32\n",
      " 227  zz0178                        5710 non-null   float32\n",
      " 228  zz0179                        5710 non-null   float32\n",
      " 229  zz0180                        5710 non-null   float32\n",
      " 230  zz0181                        5710 non-null   float32\n",
      " 231  zz0182                        5710 non-null   float32\n",
      " 232  zz0183                        5710 non-null   float32\n",
      " 233  zz0184                        5710 non-null   float32\n",
      " 234  zz0185                        5710 non-null   float32\n",
      " 235  zz0186                        5710 non-null   float32\n",
      " 236  zz0187                        5710 non-null   float32\n",
      " 237  zz0188                        5710 non-null   float32\n",
      " 238  zz0189                        5710 non-null   float32\n",
      " 239  zz0190                        5710 non-null   float32\n",
      " 240  zz0191                        5710 non-null   float32\n",
      " 241  zz0192                        5710 non-null   float32\n",
      " 242  zz0193                        5710 non-null   float32\n",
      " 243  zz0194                        5710 non-null   float32\n",
      " 244  zz0195                        5710 non-null   float32\n",
      " 245  zz0196                        5710 non-null   float32\n",
      " 246  zz0197                        5710 non-null   float32\n",
      " 247  zz0198                        5710 non-null   float32\n",
      " 248  zz0199                        5710 non-null   float32\n",
      " 249  zz0200                        5710 non-null   float32\n",
      " 250  zz0201                        5710 non-null   float32\n",
      " 251  zz0202                        5710 non-null   float32\n",
      " 252  zz0203                        5710 non-null   float32\n",
      " 253  zz0204                        5710 non-null   float32\n",
      " 254  zz0205                        5710 non-null   float32\n",
      " 255  zz0206                        5710 non-null   float32\n",
      " 256  zz0207                        5710 non-null   float32\n",
      " 257  zz0208                        5710 non-null   float32\n",
      " 258  zz0209                        5710 non-null   float32\n",
      " 259  zz0210                        5710 non-null   float32\n",
      " 260  zz0211                        5710 non-null   float32\n",
      " 261  zz0212                        5710 non-null   float32\n",
      " 262  zz0213                        5710 non-null   float32\n",
      " 263  zz0214                        5710 non-null   float32\n",
      " 264  zz0215                        5710 non-null   float32\n",
      " 265  zz0216                        5710 non-null   float32\n",
      " 266  zz0217                        5710 non-null   float32\n",
      " 267  zz0218                        5710 non-null   float32\n",
      " 268  zz0219                        5710 non-null   float32\n",
      " 269  zz0220                        5710 non-null   float32\n",
      " 270  zz0221                        5710 non-null   float32\n",
      " 271  zz0222                        5710 non-null   float32\n",
      " 272  zz0223                        5710 non-null   float32\n",
      " 273  zz0224                        5710 non-null   float32\n",
      " 274  zz0225                        5710 non-null   float32\n",
      " 275  zz0226                        5710 non-null   float32\n",
      " 276  zz0227                        5710 non-null   float32\n",
      " 277  zz0228                        5710 non-null   float32\n",
      " 278  zz0229                        5710 non-null   float32\n",
      " 279  zz0230                        5710 non-null   float32\n",
      " 280  zz0231                        5710 non-null   float32\n",
      " 281  zz0232                        5710 non-null   float32\n",
      " 282  zz0233                        5710 non-null   float32\n",
      " 283  zz0234                        5710 non-null   float32\n",
      " 284  zz0235                        5710 non-null   float32\n",
      " 285  zz0236                        5710 non-null   float32\n",
      " 286  zz0237                        5710 non-null   float32\n",
      " 287  zz0238                        5710 non-null   float32\n",
      " 288  zz0239                        5710 non-null   float32\n",
      " 289  zz0240                        5710 non-null   float32\n",
      " 290  zz0241                        5710 non-null   float32\n",
      " 291  zz0242                        5710 non-null   float32\n",
      " 292  zz0243                        5710 non-null   float32\n",
      " 293  zz0244                        5710 non-null   float32\n",
      " 294  zz0245                        5710 non-null   float32\n",
      " 295  zz0246                        5710 non-null   float32\n",
      " 296  zz0247                        5710 non-null   float32\n",
      " 297  zz0248                        5710 non-null   float32\n",
      " 298  zz0249                        5710 non-null   float32\n",
      " 299  zz0250                        5710 non-null   float32\n",
      " 300  zz0251                        5710 non-null   float32\n",
      " 301  zz0252                        5710 non-null   float32\n",
      " 302  zz0253                        5710 non-null   float32\n",
      " 303  zz0254                        5710 non-null   float32\n",
      " 304  zz0255                        5710 non-null   float32\n",
      " 305  zz0256                        5710 non-null   float32\n",
      " 306  zz0257                        5710 non-null   float32\n",
      " 307  zz0258                        5710 non-null   float32\n",
      " 308  zz0259                        5710 non-null   float32\n",
      " 309  zz0260                        5710 non-null   float32\n",
      " 310  zz0261                        5710 non-null   float32\n",
      " 311  zz0262                        5710 non-null   float32\n",
      " 312  zz0263                        5710 non-null   float32\n",
      " 313  zz0264                        5710 non-null   float32\n",
      " 314  zz0265                        5710 non-null   float32\n",
      " 315  zz0266                        5710 non-null   float32\n",
      " 316  zz0267                        5710 non-null   float32\n",
      " 317  zz0268                        5710 non-null   float32\n",
      " 318  zz0269                        5710 non-null   float32\n",
      " 319  zz0270                        5710 non-null   float32\n",
      " 320  zz0271                        5710 non-null   float32\n",
      " 321  zz0272                        5710 non-null   float32\n",
      " 322  zz0273                        5710 non-null   float32\n",
      " 323  zz0274                        5710 non-null   float32\n",
      " 324  zz0275                        5710 non-null   float32\n",
      " 325  zz0276                        5710 non-null   float32\n",
      " 326  zz0277                        5710 non-null   float32\n",
      " 327  zz0278                        5710 non-null   float32\n",
      " 328  zz0279                        5710 non-null   float32\n",
      " 329  zz0280                        5710 non-null   float32\n",
      " 330  zz0281                        5710 non-null   float32\n",
      " 331  zz0282                        5710 non-null   float32\n",
      " 332  zz0283                        5710 non-null   float32\n",
      " 333  zz0284                        5710 non-null   float32\n",
      " 334  zz0285                        5710 non-null   float32\n",
      " 335  zz0286                        5710 non-null   float32\n",
      " 336  zz0287                        5710 non-null   float32\n",
      " 337  zz0288                        5710 non-null   float32\n",
      " 338  zz0289                        5710 non-null   float32\n",
      " 339  zz0290                        5710 non-null   float32\n",
      " 340  zz0291                        5710 non-null   float32\n",
      " 341  zz0292                        5710 non-null   float32\n",
      " 342  zz0293                        5710 non-null   float32\n",
      " 343  zz0294                        5710 non-null   float32\n",
      " 344  zz0295                        5710 non-null   float32\n",
      " 345  zz0296                        5710 non-null   float32\n",
      " 346  zz0297                        5710 non-null   float32\n",
      " 347  zz0298                        5710 non-null   float32\n",
      " 348  zz0299                        5710 non-null   float32\n",
      " 349  zz0300                        5710 non-null   float32\n",
      " 350  zz0301                        5710 non-null   float32\n",
      " 351  zz0302                        5710 non-null   float32\n",
      " 352  zz0303                        5710 non-null   float32\n",
      " 353  zz0304                        5710 non-null   float32\n",
      " 354  zz0305                        5710 non-null   float32\n",
      " 355  zz0306                        5710 non-null   float32\n",
      " 356  zz0307                        5710 non-null   float32\n",
      " 357  zz0308                        5710 non-null   float32\n",
      " 358  zz0309                        5710 non-null   float32\n",
      " 359  zz0310                        5710 non-null   float32\n",
      " 360  zz0311                        5710 non-null   float32\n",
      " 361  zz0312                        5710 non-null   float32\n",
      " 362  zz0313                        5710 non-null   float32\n",
      " 363  zz0314                        5710 non-null   float32\n",
      " 364  zz0315                        5710 non-null   float32\n",
      " 365  zz0316                        5710 non-null   float32\n",
      " 366  zz0317                        5710 non-null   float32\n",
      " 367  zz0318                        5710 non-null   float32\n",
      " 368  zz0319                        5710 non-null   float32\n",
      " 369  zz0320                        5710 non-null   float32\n",
      " 370  zz0321                        5710 non-null   float32\n",
      " 371  zz0322                        5710 non-null   float32\n",
      " 372  zz0323                        5710 non-null   float32\n",
      " 373  zz0324                        5710 non-null   float32\n",
      " 374  zz0325                        5710 non-null   float32\n",
      " 375  zz0326                        5710 non-null   float32\n",
      " 376  zz0327                        5710 non-null   float32\n",
      " 377  zz0328                        5710 non-null   float32\n",
      " 378  zz0329                        5710 non-null   float32\n",
      " 379  zz0330                        5710 non-null   float32\n",
      " 380  zz0331                        5710 non-null   float32\n",
      " 381  zz0332                        5710 non-null   float32\n",
      " 382  zz0333                        5710 non-null   float32\n",
      " 383  zz0334                        5710 non-null   float32\n",
      " 384  zz0335                        5710 non-null   float32\n",
      " 385  zz0336                        5710 non-null   float32\n",
      " 386  zz0337                        5710 non-null   float32\n",
      " 387  zz0338                        5710 non-null   float32\n",
      " 388  zz0339                        5710 non-null   float32\n",
      " 389  zz0340                        5710 non-null   float32\n",
      " 390  zz0341                        5710 non-null   float32\n",
      " 391  zz0342                        5710 non-null   float32\n",
      " 392  zz0343                        5710 non-null   float32\n",
      " 393  zz0344                        5710 non-null   float32\n",
      " 394  zz0345                        5710 non-null   float32\n",
      " 395  zz0346                        5710 non-null   float32\n",
      " 396  zz0347                        5710 non-null   float32\n",
      " 397  zz0348                        5710 non-null   float32\n",
      " 398  zz0349                        5710 non-null   float32\n",
      " 399  zz0350                        5710 non-null   float32\n",
      " 400  zz0351                        5710 non-null   float32\n",
      " 401  zz0352                        5710 non-null   float32\n",
      " 402  zz0353                        5710 non-null   float32\n",
      " 403  zz0354                        5710 non-null   float32\n",
      " 404  zz0355                        5710 non-null   float32\n",
      " 405  zz0356                        5710 non-null   float32\n",
      " 406  zz0357                        5710 non-null   float32\n",
      " 407  zz0358                        5710 non-null   float32\n",
      " 408  zz0359                        5710 non-null   float32\n",
      " 409  zz0360                        5710 non-null   float32\n",
      " 410  zz0361                        5710 non-null   float32\n",
      " 411  zz0362                        5710 non-null   float32\n",
      " 412  zz0363                        5710 non-null   float32\n",
      " 413  zz0364                        5710 non-null   float32\n",
      " 414  zz0365                        5710 non-null   float32\n",
      " 415  zz0366                        5710 non-null   float32\n",
      " 416  zz0367                        5710 non-null   float32\n",
      " 417  zz0368                        5710 non-null   float32\n",
      " 418  zz0369                        5710 non-null   float32\n",
      " 419  zz0370                        5710 non-null   float32\n",
      " 420  zz0371                        5710 non-null   float32\n",
      " 421  zz0372                        5710 non-null   float32\n",
      " 422  zz0373                        5710 non-null   float32\n",
      " 423  zz0374                        5710 non-null   float32\n",
      " 424  zz0375                        5710 non-null   float32\n",
      " 425  zz0376                        5710 non-null   float32\n",
      " 426  zz0377                        5710 non-null   float32\n",
      " 427  zz0378                        5710 non-null   float32\n",
      " 428  zz0379                        5710 non-null   float32\n",
      " 429  zz0380                        5710 non-null   float32\n",
      " 430  zz0381                        5710 non-null   float32\n",
      " 431  zz0382                        5710 non-null   float32\n",
      " 432  zz0383                        5710 non-null   float32\n",
      "dtypes: float32(430), int16(1), int32(1), int8(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "cols += em_cols\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b13fb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 333 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[cols].to_parquet(\"output/tra.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
