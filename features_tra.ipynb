{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b888a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import rankdata\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import textstat\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8f39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', dtfy_model_max_length=512, dtfy_batch_size=256, dtfy_models={'dto_': 'pretrained/unitaryai/detoxify/toxic_original-c1212f89.ckpt', 'dtu_': 'pretrained/unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt', 'dtm_': 'pretrained/unitaryai/detoxify/multilingual_debiased-0b549669.ckpt'}, dtfy_configs={'dto_': 'pretrained/bert-base-uncased', 'dtu_': 'pretrained/roberta-base', 'dtm_': 'pretrained/xlm-roberta-base'}, tweeteval_model_max_length=512, tweeteval_batch_size=128, tweeteval_models={'te_roberta_off': 'pretrained/cardiffnlp/twitter-roberta-base-offensive', 'te_roberta_emo_anger': 'pretrained/cardiffnlp/twitter-roberta-base-emotion', 'te_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-roberta-base-sentiment', 'te_roberta_iro': 'pretrained/cardiffnlp/twitter-roberta-base-irony'}, tweeteval_label_index={'te_roberta_off': 1, 'te_roberta_emo_anger': 0, 'te_roberta_snt_neg': 0, 'te_roberta_iro': 1}, hatebert_model_max_length=512, hatebert_batch_size=128, hatebert_models={'hb_bert_off': 'pretrained/hatebert/bert-offenseval', 'hb_bert_abu': 'pretrained/hatebert/bert-abuseval', 'hb_hatebert_off': 'pretrained/hatebert/hatebert-offenseval', 'hb_hatebert_abu': 'pretrained/hatebert/hatebert-abuseval'}, em_max_seq_length=128, em_batch_size=1000, em_models={'paraphrase-MiniLM-L6-v2': 'pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2'})\n",
      "NVIDIA GeForce GTX 1060 6GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    dtfy_model_max_length: int = 512\n",
    "    dtfy_batch_size: int = 256\n",
    "    dtfy_models: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_original-c1212f89.ckpt\",\n",
    "        \"dtu_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt\",\n",
    "        \"dtm_\": f\"{pretrained_dir}unitaryai/detoxify/multilingual_debiased-0b549669.ckpt\"\n",
    "    }\n",
    "    dtfy_configs: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}bert-base-uncased\",\n",
    "        \"dtu_\": f\"{pretrained_dir}roberta-base\",\n",
    "        \"dtm_\": f\"{pretrained_dir}xlm-roberta-base\"\n",
    "    }\n",
    "    tweeteval_model_max_length: int = 512\n",
    "    tweeteval_batch_size: int = 128\n",
    "    tweeteval_models: Dict[str, str] = {\n",
    "        \"te_roberta_off\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-offensive\",\n",
    "        \"te_roberta_emo_anger\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        \"te_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        \"te_roberta_iro\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-irony\",\n",
    "    }\n",
    "    tweeteval_label_index: Dict[str, int] = {\n",
    "        \"te_roberta_off\": 1,\n",
    "        \"te_roberta_emo_anger\": 0,\n",
    "        \"te_roberta_snt_neg\": 0,\n",
    "        \"te_roberta_iro\": 1,\n",
    "    }\n",
    "    hatebert_model_max_length: int = 512\n",
    "    hatebert_batch_size: int = 128\n",
    "    hatebert_models: Dict[str, str] = {\n",
    "        \"hb_bert_off\": f\"{pretrained_dir}hatebert/bert-offenseval\",\n",
    "        \"hb_bert_abu\" : f\"{pretrained_dir}hatebert/bert-abuseval\",\n",
    "        \"hb_hatebert_off\": f\"{pretrained_dir}hatebert/hatebert-offenseval\",\n",
    "        \"hb_hatebert_abu\" : f\"{pretrained_dir}hatebert/hatebert-abuseval\",\n",
    "    }\n",
    "    em_max_seq_length: int = 128\n",
    "    em_batch_size: int = 1000\n",
    "    em_models: Dict[str, str] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "    }\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_map: Dict[str, float] = {}\n",
    "df = pd.read_csv(\"input/ruddit/Ruddit.csv\", engine=\"c\", low_memory=False)\n",
    "for t in df.itertuples():\n",
    "    k = getattr(t, \"post_id\") + \"_\" + getattr(t, \"comment_id\")\n",
    "    score_map[k] = getattr(t, \"offensiveness_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860fc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   bws     5710 non-null   float32\n",
      " 1   text    5710 non-null   object \n",
      "dtypes: float32(1), object(1)\n",
      "memory usage: 67.0+ KB\n",
      "Wall time: 51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"input/ruddit/ruddit_with_text.csv\", engine=\"c\", low_memory=False)\n",
    "blacklist = {\"[deleted]\", \"[removed]\"}\n",
    "rows = []\n",
    "for t in df.itertuples():\n",
    "    text = getattr(t, \"txt\")\n",
    "    s = text.strip().lower()\n",
    "    if len(s)==0 or s in blacklist:\n",
    "        continue\n",
    "    k = getattr(t, \"post_id\") + \"_\" + getattr(t, \"comment_id\")\n",
    "    rows.append({\"bws\": score_map[k], \"text\": text})\n",
    "df = pd.DataFrame.from_records(rows)\n",
    "df[\"bws\"] = df[\"bws\"].astype(np.float32) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4f3683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bws</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total  Percent     Type\n",
       "bws       0      0.0  float32\n",
       "text      0      0.0   object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scml.find_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a7d8e",
   "metadata": {},
   "source": [
    "# Severity rating label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c05937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force unique ranks\n",
    "col = \"label\"\n",
    "df[col] = rankdata(df[\"bws\"], method='ordinal')\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4796d0d",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27321fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:02<00:00, 2425.37it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(row) -> str:\n",
    "    return mylib.preprocess(row[\"text\"])\n",
    "\n",
    "\n",
    "col = \"text\"\n",
    "df[col] = df.progress_apply(preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2490070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bws</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>-0.667</td>\n",
       "      <td>All New Materials and Buttersnips too - man that first album had some great songs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>-0.479</td>\n",
       "      <td>probably conventional RPGs are not your cup of tea then? have you tried other genres like Assassin's Creed or Mass effect or Skyrim which has RPG elements but not conventional RPG?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>-0.457</td>\n",
       "      <td>Exposing the number of bots would crash their stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>-0.438</td>\n",
       "      <td>None of my friends throw a New Year's eve party. you are lucky!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>It looks like a high ranking dark wraith perhaps if you steal enough humanity you get an upgrade to the dark sign? Looks cool AF. Either a mini boss or a normal enemy of the city... ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>-0.312</td>\n",
       "      <td>Not really. California came at a point when it was clear Bernie had lost, so it is not surprising that Clinton won.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>-0.312</td>\n",
       "      <td>I started lifting and taking care of myself late. The way women treat me changed 180. Even guys are doing me favours now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>-0.298</td>\n",
       "      <td>Short guys usually cannot guy things off the rack, either. Clothes are not made for short, thin men.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-0.229</td>\n",
       "      <td>Considering how closely prisoners are monitored, I suspect the reporting rate is much higher there than in the general population.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>she wont do any time, she will be fined and move on.she HOPEFULLY will be smarter in the future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>Psilocybin mushrooms reset this pattern of thinking and behavior. Safely, unlike the toxic compounds people are ingesting by the truckload, as prescribed by their doctors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>-0.146</td>\n",
       "      <td>So proud of her! Teens fighting the good fight and not putting up with their parents bullshit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>-0.106</td>\n",
       "      <td>Hey I got into a situation a while back in high school.My plan was to go to the military,but I got a case and I had to put it on hold.I finally got it situated and came out with a deferred prosecution. No probation or fees the judge said not to get into anymore trouble for 6 months. My lawyer said I would not even have to show up if I sent the volunteer work to him. I want to talk to a recruiter, but I do not want to make it seem like I am wasting time due to the bs earlier this year. Can I talk to a recruiter with a deferred prosecution ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>-0.104</td>\n",
       "      <td>It likely depends on what action the org takes. The player will be penalozed for trying to breach their contract, and if the org knowingly is they would be as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>Ideally i wont marry/end up with a girl of the same ethnicity as myself. I enjoy the idea of mixing my lineage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>A mainly financial and business oriented newspaper is not popular with teens. Big suprise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>You said vaccination is a poor choice by accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.043</td>\n",
       "      <td>I defined what I meant by God in the original post. If you are claiming that an argument against something is the existence of alternative definitions then I would be interested if you would be willing to actually defend that assertion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>She is a homebody that is not interested in going out. This is a long term problem that gotten worse. She does not place a great emphasis on my physical needs. Something she has admitted. She \"forgets\" despite 5-6 serious conversations about over the past 3 years. I do not want to cheat. I am not a cheater and would never hurt my children by doing so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>0.021</td>\n",
       "      <td>My school counselor told me she can not counsel me anymore because she started to get \"issues at home\" after talking with me and that I will inevitably find myself in an abusive relationship anyways. So please. DO tell me what you do to help these children?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0.021</td>\n",
       "      <td>I am taking a human sexuality college course this summer and I just read the other day that pharmacists are allowed to decline to fill for moral or religious reasons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>0.021</td>\n",
       "      <td>Someone please tell her that hen tie is perfectly safe and nothing to worry about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>0.021</td>\n",
       "      <td>My fiancee is religious. She is a leftist and not someone who evangelizes. it is a personal faith. I am an atheist. it is not like every atheist would very compatible with every religious person but it can work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.021</td>\n",
       "      <td>I mean does it really have to have anything to do with gender to provide urinals? If you have the right kit (or are brave enough) I do not see anything wrong with providing facilities for a quick #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>0.062</td>\n",
       "      <td>Go on Facebook and ask the flat earthers if NASA is also faking this, too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>0.067</td>\n",
       "      <td>Well, that would be because 'pro-life' is about controlling women's bodies, not defending innocent life, and all of the arguments used in defense of their stance are fabricated.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>0.104</td>\n",
       "      <td>Usually you do not kill your bargaining chip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.106</td>\n",
       "      <td>Me : never had a flu vaccine , me: never had the flu . I do not believe in vaccines , the human race has survived thousands of years without them. And after reading countless stories about children getting vaccininated and dieing a few hours or a couple days later is heartbreaking. I expect this comment to be deleted like the last .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.170</td>\n",
       "      <td>I am assuming that the straw man you are referring to is where I talk about witch hunts. While I do not think that that is a straw man, you clearly do so let us ignore that for now and just address the first question: is it alright to punish people for the faults of their ancestors? To be more specific, is it right to deem certain actions and behaviors, such as wearing a native American headdress, acceptable or unacceptable based on the faults of your ancestors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>0.271</td>\n",
       "      <td>that line low-key broke my faith that Americans had any semblance of shame. For God's sake he is advocating collective punishment and the wholesale slaughter of women and children whose only crime is they are RELATED TO BAD GUYS. The Yemen raid made me want to cry, we killed an eight year old girl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.292</td>\n",
       "      <td>By your logic, should homosexuals still be classified as mentally ill because our sexuality is a minority?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.292</td>\n",
       "      <td>But gay men and lesbians can currently do those things in their respective bathrooms, so would not it make more sense to have laws against loitering in bathrooms and doing those sorts of things rather than sex based segregation. Like, your entire argument seems predicated on the assumption that only heterosexual people exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>0.312</td>\n",
       "      <td>I saw this posted yesterday and many of the comments were saying that \"oh okay, the girls were planning on robbing him and offered themselves\" as if that is somehow an excuse. These should be two separate things. The man solicited underaged girls, that is a crime no matter how you look at it. it is irrelevant if the girls are soliciting themselves or put up to it by someone else - as an adult, the 67 year old is the one committing the crime and he should be punished for it. And the girls pimping eachother out for money and planning to rob him? That should be tried as a separate crime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.312</td>\n",
       "      <td>Could this be because... prisons are full of actual rapists?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>0.333</td>\n",
       "      <td>Exactly. Birth control is only good for deciding your future, sexual freedom, and bodily autonomy. And none of that helps punish sinners for having sex, so that is obviously no good. /s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0.438</td>\n",
       "      <td>i thought girl scouts was a thing? what is the point? seems to be some sjw appeasing crap but really who cares what sex people are in any given situation that does not involve sex/romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>0.458</td>\n",
       "      <td>Cancer bats. Hail destroyer. Im in the middle of learning this and the intro is really fun. Plus the band is sick as fuccccck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>0.542</td>\n",
       "      <td>Muslim man teaches children how to shoot AK-47s should have hospitals and schools Democrats nothing white guy kills people with gun change gun laws!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>0.667</td>\n",
       "      <td>My mother developed PTSD and various addictions after she was molested by a priest. Fuck the church. This is the exact opposite of what their God would have wanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>0.792</td>\n",
       "      <td>Fuck, I should really quit smoking. It makes me feel like an idiot for doing it when I see shit like this.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bws  \\\n",
       "3470 -0.667   \n",
       "3264 -0.479   \n",
       "4842 -0.457   \n",
       "1568 -0.438   \n",
       "2727 -0.375   \n",
       "2851 -0.312   \n",
       "1820 -0.312   \n",
       "1659 -0.298   \n",
       "605  -0.229   \n",
       "3828 -0.188   \n",
       "1118 -0.188   \n",
       "4703 -0.146   \n",
       "3105 -0.106   \n",
       "2477 -0.104   \n",
       "1573 -0.083   \n",
       "2799 -0.062   \n",
       "4589 -0.062   \n",
       "70   -0.043   \n",
       "994  -0.042   \n",
       "2344  0.021   \n",
       "3944  0.021   \n",
       "4733  0.021   \n",
       "1575  0.021   \n",
       "1147  0.021   \n",
       "3693  0.062   \n",
       "4242  0.067   \n",
       "4768  0.104   \n",
       "434   0.106   \n",
       "466   0.170   \n",
       "2850  0.271   \n",
       "1296  0.292   \n",
       "1286  0.292   \n",
       "4132  0.312   \n",
       "612   0.312   \n",
       "3975  0.333   \n",
       "1671  0.438   \n",
       "3474  0.458   \n",
       "5465  0.542   \n",
       "4069  0.667   \n",
       "3027  0.792   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \n",
       "3470                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               All New Materials and Buttersnips too - man that first album had some great songs.  \n",
       "3264                                                                                                                                                                                                                                                                                                                                                                                                                             probably conventional RPGs are not your cup of tea then? have you tried other genres like Assassin's Creed or Mass effect or Skyrim which has RPG elements but not conventional RPG?  \n",
       "4842                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Exposing the number of bots would crash their stock  \n",
       "1568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                None of my friends throw a New Year's eve party. you are lucky!!!  \n",
       "2727                                                                                                                                                                                                                                                                                                                                                                                                                         It looks like a high ranking dark wraith perhaps if you steal enough humanity you get an upgrade to the dark sign? Looks cool AF. Either a mini boss or a normal enemy of the city... ;D  \n",
       "2851                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Not really. California came at a point when it was clear Bernie had lost, so it is not surprising that Clinton won.  \n",
       "1820                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I started lifting and taking care of myself late. The way women treat me changed 180. Even guys are doing me favours now.  \n",
       "1659                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Short guys usually cannot guy things off the rack, either. Clothes are not made for short, thin men.  \n",
       "605                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Considering how closely prisoners are monitored, I suspect the reporting rate is much higher there than in the general population.  \n",
       "3828                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  she wont do any time, she will be fined and move on.she HOPEFULLY will be smarter in the future  \n",
       "1118                                                                                                                                                                                                                                                                                                                                                                                                                                      Psilocybin mushrooms reset this pattern of thinking and behavior. Safely, unlike the toxic compounds people are ingesting by the truckload, as prescribed by their doctors.  \n",
       "4703                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    So proud of her! Teens fighting the good fight and not putting up with their parents bullshit  \n",
       "3105                                                Hey I got into a situation a while back in high school.My plan was to go to the military,but I got a case and I had to put it on hold.I finally got it situated and came out with a deferred prosecution. No probation or fees the judge said not to get into anymore trouble for 6 months. My lawyer said I would not even have to show up if I sent the volunteer work to him. I want to talk to a recruiter, but I do not want to make it seem like I am wasting time due to the bs earlier this year. Can I talk to a recruiter with a deferred prosecution ?  \n",
       "2477                                                                                                                                                                                                                                                                                                                                                                                                                                             It likely depends on what action the org takes. The player will be penalozed for trying to breach their contract, and if the org knowingly is they would be as well.  \n",
       "1573                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Ideally i wont marry/end up with a girl of the same ethnicity as myself. I enjoy the idea of mixing my lineage.  \n",
       "2799                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A mainly financial and business oriented newspaper is not popular with teens. Big suprise.  \n",
       "4589                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You said vaccination is a poor choice by accident.  \n",
       "70                                                                                                                                                                                                                                                                                                                                                                       I defined what I meant by God in the original post. If you are claiming that an argument against something is the existence of alternative definitions then I would be interested if you would be willing to actually defend that assertion.  \n",
       "994                                                                                                                                                                                                                                                 She is a homebody that is not interested in going out. This is a long term problem that gotten worse. She does not place a great emphasis on my physical needs. Something she has admitted. She \"forgets\" despite 5-6 serious conversations about over the past 3 years. I do not want to cheat. I am not a cheater and would never hurt my children by doing so.  \n",
       "2344                                                                                                                                                                                                                                                                                                                                                My school counselor told me she can not counsel me anymore because she started to get \"issues at home\" after talking with me and that I will inevitably find myself in an abusive relationship anyways. So please. DO tell me what you do to help these children?  \n",
       "3944                                                                                                                                                                                                                                                                                                                                                                                                                                           I am taking a human sexuality college course this summer and I just read the other day that pharmacists are allowed to decline to fill for moral or religious reasons.  \n",
       "4733                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Someone please tell her that hen tie is perfectly safe and nothing to worry about  \n",
       "1575                                                                                                                                                                                                                                                                                                                                                                                               My fiancee is religious. She is a leftist and not someone who evangelizes. it is a personal faith. I am an atheist. it is not like every atheist would very compatible with every religious person but it can work  \n",
       "1147                                                                                                                                                                                                                                                                                                                                                                                                           I mean does it really have to have anything to do with gender to provide urinals? If you have the right kit (or are brave enough) I do not see anything wrong with providing facilities for a quick #1  \n",
       "3693                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Go on Facebook and ask the flat earthers if NASA is also faking this, too.  \n",
       "4242                                                                                                                                                                                                                                                                                                                                                                                                                                Well, that would be because 'pro-life' is about controlling women's bodies, not defending innocent life, and all of the arguments used in defense of their stance are fabricated.  \n",
       "4768                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Usually you do not kill your bargaining chip.  \n",
       "434                                                                                                                                                                                                                                                                    Me : never had a flu vaccine , me: never had the flu . I do not believe in vaccines , the human race has survived thousands of years without them. And after reading countless stories about children getting vaccininated and dieing a few hours or a couple days later is heartbreaking. I expect this comment to be deleted like the last .  \n",
       "466                                                                                                                                I am assuming that the straw man you are referring to is where I talk about witch hunts. While I do not think that that is a straw man, you clearly do so let us ignore that for now and just address the first question: is it alright to punish people for the faults of their ancestors? To be more specific, is it right to deem certain actions and behaviors, such as wearing a native American headdress, acceptable or unacceptable based on the faults of your ancestors?  \n",
       "2850                                                                                                                                                                                                                                                                                                      that line low-key broke my faith that Americans had any semblance of shame. For God's sake he is advocating collective punishment and the wholesale slaughter of women and children whose only crime is they are RELATED TO BAD GUYS. The Yemen raid made me want to cry, we killed an eight year old girl.  \n",
       "1296                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       By your logic, should homosexuals still be classified as mentally ill because our sexuality is a minority?  \n",
       "1286                                                                                                                                                                                                                                                                          But gay men and lesbians can currently do those things in their respective bathrooms, so would not it make more sense to have laws against loitering in bathrooms and doing those sorts of things rather than sex based segregation. Like, your entire argument seems predicated on the assumption that only heterosexual people exist.  \n",
       "4132  I saw this posted yesterday and many of the comments were saying that \"oh okay, the girls were planning on robbing him and offered themselves\" as if that is somehow an excuse. These should be two separate things. The man solicited underaged girls, that is a crime no matter how you look at it. it is irrelevant if the girls are soliciting themselves or put up to it by someone else - as an adult, the 67 year old is the one committing the crime and he should be punished for it. And the girls pimping eachother out for money and planning to rob him? That should be tried as a separate crime.  \n",
       "612                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Could this be because... prisons are full of actual rapists?  \n",
       "3975                                                                                                                                                                                                                                                                                                                                                                                                                        Exactly. Birth control is only good for deciding your future, sexual freedom, and bodily autonomy. And none of that helps punish sinners for having sex, so that is obviously no good. /s  \n",
       "1671                                                                                                                                                                                                                                                                                                                                                                                                                      i thought girl scouts was a thing? what is the point? seems to be some sjw appeasing crap but really who cares what sex people are in any given situation that does not involve sex/romance  \n",
       "3474                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Cancer bats. Hail destroyer. Im in the middle of learning this and the intro is really fun. Plus the band is sick as fuccccck  \n",
       "5465                                                                                                                                                                                                                                                                                                                                                                                                                                                             Muslim man teaches children how to shoot AK-47s should have hospitals and schools Democrats nothing white guy kills people with gun change gun laws!  \n",
       "4069                                                                                                                                                                                                                                                                                                                                                                                                                                              My mother developed PTSD and various addictions after she was molested by a priest. Fuck the church. This is the exact opposite of what their God would have wanted  \n",
       "3027                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Fuck, I should really quit smoking. It makes me feel like an idiot for doing it when I see shit like this.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"bws\", \"text\"]\n",
    "df[cols].sample(40).sort_values(\"bws\").head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752d7ac",
   "metadata": {},
   "source": [
    "# Character level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71d6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col = \"length\"\n",
    "df[col] = df[\"text\"].str.len()\n",
    "df[col] = df[col].astype(np.int16)\n",
    "char_fs = [col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74a87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[\"text\"])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39889.67it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"digit_frac\"\n",
    "df[col] = df.progress_apply(digit_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddc24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39082.62it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"letter_frac\"\n",
    "df[col] = df.progress_apply(letter_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ca5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39753.14it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"space_frac\"\n",
    "df[col] = df.progress_apply(space_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5701ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 35680.52it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"punc_frac\"\n",
    "df[col] = df.progress_apply(punc_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a860959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 40204.06it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"upper_frac\"\n",
    "df[col] = df.progress_apply(upper_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c7b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length', 'digit_frac', 'letter_frac', 'space_frac', 'punc_frac', 'upper_frac']\n"
     ]
    }
   ],
   "source": [
    "print(char_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d4202",
   "metadata": {},
   "source": [
    "# Textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[\"text\"])\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[\"text\"])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[\"text\"])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[\"text\"])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[\"text\"])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[\"text\"])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c32df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 6213.75it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"flesch_reading_ease\"\n",
    "df[col] = df.progress_apply(flesch_reading_ease, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs = []\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aad1c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12816.05it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"flesch_kincaid_grade\"\n",
    "df[col] = df.progress_apply(flesch_kincaid_grade, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d91172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 19755.79it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"syllable_count\"\n",
    "df[col] = df.progress_apply(syllable_count, axis=1)\n",
    "df[col] = df[col].astype(np.int16)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc45e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 67155.34it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"lexicon_count\"\n",
    "df[col] = df.progress_apply(lexicon_count, axis=1)\n",
    "df[col] = df[col].astype(np.int16)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "245bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 40784.23it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"sentence_count\"\n",
    "df[col] = df.progress_apply(sentence_count, axis=1)\n",
    "df[col] = df[col].astype(np.int16)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a900647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10415.25it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"gunning_fog\"\n",
    "df[col] = df.progress_apply(gunning_fog, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a0bc915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 16205.41it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"smog_index\"\n",
    "df[col] = df.progress_apply(smog_index, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea50888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 27844.86it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"automated_readability_index\"\n",
    "df[col] = df.progress_apply(automated_readability_index, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809093ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 23738.04it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"coleman_liau_index\"\n",
    "df[col] = df.progress_apply(coleman_liau_index, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2340310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 11700.77it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"linsear_write_formula\"\n",
    "df[col] = df.progress_apply(linsear_write_formula, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d8fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10215.70it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"dale_chall_readability_score\"\n",
    "df[col] = df.progress_apply(dale_chall_readability_score, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "textstat_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9530cb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flesch_reading_ease', 'flesch_kincaid_grade', 'syllable_count', 'lexicon_count', 'sentence_count', 'gunning_fog', 'smog_index', 'automated_readability_index', 'coleman_liau_index', 'linsear_write_formula', 'dale_chall_readability_score']\n"
     ]
    }
   ],
   "source": [
    "print(textstat_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285247d",
   "metadata": {},
   "source": [
    "# TweetEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "380f4e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/cardiffnlp/twitter-roberta-base-offensive', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "model_input_names=['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df[\"text\"])\n",
    "# all TweetEval models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.tweeteval_models[\"te_roberta_off\"], \n",
    "    model_max_length=conf.tweeteval_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0d4320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 983 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "167d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_off=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9025, 0.0975],\n",
      "        [0.5804, 0.4196],\n",
      "        [0.6679, 0.3321],\n",
      "        [0.8045, 0.1955],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.7749, 0.2251],\n",
      "        [0.8272, 0.1728],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.7598, 0.2402],\n",
      "        [0.9035, 0.0965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_emo_anger=torch.Size([5710, 4])\n",
      "logits[:10]=tensor([[0.0376, 0.0565, 0.8628, 0.0431],\n",
      "        [0.1369, 0.1012, 0.2558, 0.5061],\n",
      "        [0.8166, 0.0105, 0.0391, 0.1338],\n",
      "        [0.9419, 0.0041, 0.0231, 0.0308],\n",
      "        [0.6140, 0.0225, 0.1561, 0.2074],\n",
      "        [0.8744, 0.0085, 0.0585, 0.0586],\n",
      "        [0.8556, 0.0071, 0.0948, 0.0425],\n",
      "        [0.8475, 0.0155, 0.0260, 0.1111],\n",
      "        [0.8054, 0.0086, 0.0704, 0.1156],\n",
      "        [0.1417, 0.3192, 0.3703, 0.1687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_snt_neg=torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.0407, 0.7561, 0.2032],\n",
      "        [0.4268, 0.5488, 0.0244],\n",
      "        [0.7662, 0.2259, 0.0080],\n",
      "        [0.6066, 0.3729, 0.0206],\n",
      "        [0.5169, 0.4232, 0.0599],\n",
      "        [0.5795, 0.3848, 0.0357],\n",
      "        [0.3226, 0.6394, 0.0380],\n",
      "        [0.7787, 0.2147, 0.0066],\n",
      "        [0.7998, 0.1863, 0.0139],\n",
      "        [0.1055, 0.6091, 0.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_iro=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.7999, 0.2001],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.3392, 0.6608],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.8869, 0.1131],\n",
      "        [0.4666, 0.5334],\n",
      "        [0.7453, 0.2547],\n",
      "        [0.0874, 0.9126],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.6555, 0.3445]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.tweeteval_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.tweeteval_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,conf.tweeteval_label_index[col]]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e694b",
   "metadata": {},
   "source": [
    "# HateBert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d49676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/hatebert/hatebert-offenseval', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# all Hatebert models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.hatebert_models[\"hb_hatebert_off\"], \n",
    "    model_max_length=conf.hatebert_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12e71aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baba8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_off=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9598, 0.0402],\n",
      "        [0.7718, 0.2282],\n",
      "        [0.7567, 0.2433],\n",
      "        [0.9064, 0.0936],\n",
      "        [0.8356, 0.1644],\n",
      "        [0.7731, 0.2269],\n",
      "        [0.5952, 0.4048],\n",
      "        [0.8502, 0.1498],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9258, 0.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:13<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_abu=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9910, 0.0090],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9631, 0.0369],\n",
      "        [0.9727, 0.0273],\n",
      "        [0.8744, 0.1256],\n",
      "        [0.9001, 0.0999],\n",
      "        [0.8544, 0.1456],\n",
      "        [0.8708, 0.1292],\n",
      "        [0.9881, 0.0119]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:15<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_off=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9377, 0.0623],\n",
      "        [0.5526, 0.4474],\n",
      "        [0.7553, 0.2447],\n",
      "        [0.7828, 0.2172],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9279, 0.0721],\n",
      "        [0.8304, 0.1696],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8965, 0.1035]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:12<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_abu=torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9846, 0.0154],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9699, 0.0301],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.9775, 0.0225],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9733, 0.0267],\n",
      "        [0.9407, 0.0593],\n",
      "        [0.9795, 0.0205]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.hatebert_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.hatebert_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,1]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f069f2",
   "metadata": {},
   "source": [
    "# Detoxify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a45a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 3/3 [03:58<00:00, 79.63s/it]\n"
     ]
    }
   ],
   "source": [
    "dtfy_fs = []\n",
    "for prefix, checkpoint in tqdm(conf.dtfy_models.items()):\n",
    "    res = mylib.detoxify_labels(\n",
    "        sentences,\n",
    "        checkpoint=checkpoint,\n",
    "        config_dir=conf.dtfy_configs[prefix],\n",
    "        model_max_length=conf.dtfy_model_max_length,\n",
    "        device=conf.device,\n",
    "        batch_size=conf.dtfy_batch_size\n",
    "    )\n",
    "    for k, v in res.items():\n",
    "        col = prefix + k\n",
    "        df[col] = v\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        dtfy_fs.append(col)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6312beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dto_toxicity', 'dto_severe_toxicity', 'dto_obscene', 'dto_threat', 'dto_insult', 'dto_identity_attack', 'dtu_toxicity', 'dtu_severe_toxicity', 'dtu_obscene', 'dtu_identity_attack', 'dtu_insult', 'dtu_threat', 'dtu_sexual_explicit', 'dtm_toxicity', 'dtm_severe_toxicity', 'dtm_obscene', 'dtm_identity_attack', 'dtm_insult', 'dtm_threat', 'dtm_sexual_explicit']\n"
     ]
    }
   ],
   "source": [
    "print(dtfy_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e5b5d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11d1f90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff1203a1b50497a83d399ff7a0cc0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(5710, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(conf.em_models[\"paraphrase-MiniLM-L6-v2\"], device=conf.device)\n",
    "model.max_seq_length = conf.em_max_seq_length\n",
    "em = model.encode(sentences=sentences, batch_size=conf.em_batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73bdd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "em_size = em.shape[1]\n",
    "em_cols = [f\"zz{i:04d}\" for i in range(em_size)]\n",
    "df[em_cols] = em\n",
    "df[em_cols] = df[em_cols].astype(np.float32)\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335287",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15b1d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bws</th>\n",
       "      <th>worker</th>\n",
       "      <th>length</th>\n",
       "      <th>digit_frac</th>\n",
       "      <th>letter_frac</th>\n",
       "      <th>space_frac</th>\n",
       "      <th>punc_frac</th>\n",
       "      <th>upper_frac</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>lexicon_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>dto_toxicity</th>\n",
       "      <th>dto_severe_toxicity</th>\n",
       "      <th>dto_obscene</th>\n",
       "      <th>dto_threat</th>\n",
       "      <th>dto_insult</th>\n",
       "      <th>dto_identity_attack</th>\n",
       "      <th>dtu_toxicity</th>\n",
       "      <th>dtu_severe_toxicity</th>\n",
       "      <th>dtu_obscene</th>\n",
       "      <th>dtu_identity_attack</th>\n",
       "      <th>dtu_insult</th>\n",
       "      <th>dtu_threat</th>\n",
       "      <th>dtu_sexual_explicit</th>\n",
       "      <th>dtm_toxicity</th>\n",
       "      <th>dtm_severe_toxicity</th>\n",
       "      <th>dtm_obscene</th>\n",
       "      <th>dtm_identity_attack</th>\n",
       "      <th>dtm_insult</th>\n",
       "      <th>dtm_threat</th>\n",
       "      <th>dtm_sexual_explicit</th>\n",
       "      <th>hb_bert_off</th>\n",
       "      <th>hb_bert_abu</th>\n",
       "      <th>hb_hatebert_off</th>\n",
       "      <th>hb_hatebert_abu</th>\n",
       "      <th>te_roberta_off</th>\n",
       "      <th>te_roberta_emo_anger</th>\n",
       "      <th>te_roberta_snt_neg</th>\n",
       "      <th>te_roberta_iro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5.710000e+03</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.564098</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.788830</td>\n",
       "      <td>0.177722</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>75.253105</td>\n",
       "      <td>6.685254</td>\n",
       "      <td>50.067426</td>\n",
       "      <td>36.371278</td>\n",
       "      <td>2.319790</td>\n",
       "      <td>8.998004</td>\n",
       "      <td>3.062995</td>\n",
       "      <td>7.482505</td>\n",
       "      <td>6.631683</td>\n",
       "      <td>8.562484</td>\n",
       "      <td>8.299163</td>\n",
       "      <td>0.177856</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.113673</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.059683</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.195873</td>\n",
       "      <td>4.698273e-03</td>\n",
       "      <td>0.113027</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>0.203075</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.105158</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.083563</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.044618</td>\n",
       "      <td>0.332577</td>\n",
       "      <td>0.166173</td>\n",
       "      <td>0.329977</td>\n",
       "      <td>0.144314</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.507189</td>\n",
       "      <td>0.508503</td>\n",
       "      <td>0.313383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1648.47935</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.016744</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>19.903004</td>\n",
       "      <td>4.430519</td>\n",
       "      <td>44.035705</td>\n",
       "      <td>31.194250</td>\n",
       "      <td>1.722369</td>\n",
       "      <td>4.645890</td>\n",
       "      <td>4.695458</td>\n",
       "      <td>5.593331</td>\n",
       "      <td>3.883116</td>\n",
       "      <td>5.906460</td>\n",
       "      <td>2.270676</td>\n",
       "      <td>0.326334</td>\n",
       "      <td>0.052992</td>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.056317</td>\n",
       "      <td>0.175381</td>\n",
       "      <td>0.064708</td>\n",
       "      <td>0.341383</td>\n",
       "      <td>2.272458e-02</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.074354</td>\n",
       "      <td>0.207780</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>0.149433</td>\n",
       "      <td>0.345334</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.272925</td>\n",
       "      <td>0.075226</td>\n",
       "      <td>0.214901</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.155314</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.278667</td>\n",
       "      <td>0.284761</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.357695</td>\n",
       "      <td>0.319341</td>\n",
       "      <td>0.276529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-48.980000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.700000</td>\n",
       "      <td>-10.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.529070e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.014366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>58.09000</td>\n",
       "      <td>-0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672759</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.430301</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.003700</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1.087282e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.022520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>286.45000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>41.869999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1.200621e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.074244</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.034839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>571.90000</td>\n",
       "      <td>-0.426000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>50.669998</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>2.741667</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.271093e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.049953</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.039984</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.046494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1142.80000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.161966</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>59.980000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.698000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>1.407266e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.124509</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.146359</td>\n",
       "      <td>0.072034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>1713.70000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>66.739998</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.364000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>1.645227e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>0.113060</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.161852</td>\n",
       "      <td>0.175718</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.102903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>2284.60000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>72.144003</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>2.303226e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.157839</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>0.208463</td>\n",
       "      <td>0.321477</td>\n",
       "      <td>0.416262</td>\n",
       "      <td>0.145013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792852</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>76.220001</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>4.173747e-06</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.171648</td>\n",
       "      <td>0.027659</td>\n",
       "      <td>0.218091</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>0.265905</td>\n",
       "      <td>0.526801</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.200985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>3426.40000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798788</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>80.919998</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>7.484000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>1.015833e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.282971</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.310787</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.342768</td>\n",
       "      <td>0.714927</td>\n",
       "      <td>0.652210</td>\n",
       "      <td>0.291033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3997.30000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.188464</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>85.690002</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.853000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>8.460000</td>\n",
       "      <td>10.676667</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>0.056457</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>3.191344e-05</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.091781</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.460070</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.439863</td>\n",
       "      <td>0.106683</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>0.837082</td>\n",
       "      <td>0.758375</td>\n",
       "      <td>0.414743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4568.20000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>0.194306</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>91.110001</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.134000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>9.520000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>0.318193</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.430039</td>\n",
       "      <td>1.706842e-04</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.487258</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.615488</td>\n",
       "      <td>0.189939</td>\n",
       "      <td>0.589677</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.584716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5139.10000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>99.570000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.501000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>11.140000</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.670921</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.168232</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.930690</td>\n",
       "      <td>4.385715e-03</td>\n",
       "      <td>0.736380</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.295351</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.042829</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.658297</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.306216</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.079094</td>\n",
       "      <td>0.928643</td>\n",
       "      <td>0.710093</td>\n",
       "      <td>0.824093</td>\n",
       "      <td>0.460149</td>\n",
       "      <td>0.784665</td>\n",
       "      <td>0.955451</td>\n",
       "      <td>0.921829</td>\n",
       "      <td>0.786549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5424.55000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577.550000</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>105.660004</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>12.620000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>11.830000</td>\n",
       "      <td>0.985316</td>\n",
       "      <td>0.086339</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.480264</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>0.979522</td>\n",
       "      <td>2.221569e-02</td>\n",
       "      <td>0.934339</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.283533</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.911508</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.689002</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>0.960833</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.737487</td>\n",
       "      <td>0.858253</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.953920</td>\n",
       "      <td>0.886064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5652.91000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.910000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.119969</td>\n",
       "      <td>0.159718</td>\n",
       "      <td>116.150002</td>\n",
       "      <td>20.373000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23.709999</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>16.534699</td>\n",
       "      <td>29.455000</td>\n",
       "      <td>14.561900</td>\n",
       "      <td>0.997169</td>\n",
       "      <td>0.282513</td>\n",
       "      <td>0.984720</td>\n",
       "      <td>0.317607</td>\n",
       "      <td>0.887015</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.994499</td>\n",
       "      <td>1.104791e-01</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.457570</td>\n",
       "      <td>0.947763</td>\n",
       "      <td>0.401428</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.994160</td>\n",
       "      <td>0.127040</td>\n",
       "      <td>0.977652</td>\n",
       "      <td>0.404110</td>\n",
       "      <td>0.969594</td>\n",
       "      <td>0.472689</td>\n",
       "      <td>0.890709</td>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.967271</td>\n",
       "      <td>0.957988</td>\n",
       "      <td>0.945889</td>\n",
       "      <td>0.913508</td>\n",
       "      <td>0.979008</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.960554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>118.680000</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>55.520000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>29.150000</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.764529</td>\n",
       "      <td>0.994431</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>4.605981e-01</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.985018</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.990079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label          bws  worker       length   digit_frac  letter_frac  \\\n",
       "count  5710.00000  5710.000000  5710.0  5710.000000  5710.000000  5710.000000   \n",
       "mean   2855.50000    -0.027706     0.0   197.564098     0.003542     0.788830   \n",
       "std    1648.47935     0.334195     0.0   172.016744     0.012983     0.034318   \n",
       "min       1.00000    -0.889000     0.0    15.000000     0.000000     0.400000   \n",
       "1%       58.09000    -0.667000     0.0    24.000000     0.000000     0.672759   \n",
       "5%      286.45000    -0.521000     0.0    33.000000     0.000000     0.733333   \n",
       "10%     571.90000    -0.426000     0.0    42.000000     0.000000     0.750000   \n",
       "20%    1142.80000    -0.312000     0.0    60.000000     0.000000     0.769841   \n",
       "30%    1713.70000    -0.213000     0.0    82.000000     0.000000     0.779661   \n",
       "40%    2284.60000    -0.146000     0.0   106.000000     0.000000     0.786537   \n",
       "50%    2855.50000    -0.062000     0.0   137.000000     0.000000     0.792852   \n",
       "60%    3426.40000     0.021000     0.0   177.000000     0.000000     0.798788   \n",
       "70%    3997.30000     0.104000     0.0   233.000000     0.000000     0.805556   \n",
       "80%    4568.20000     0.229000     0.0   317.000000     0.000000     0.812900   \n",
       "90%    5139.10000     0.458000     0.0   458.000000     0.009662     0.822917   \n",
       "95%    5424.55000     0.625000     0.0   577.550000     0.022415     0.831579   \n",
       "99%    5652.91000     0.833000     0.0   749.910000     0.060606     0.857143   \n",
       "max    5710.00000     0.979000     0.0   917.000000     0.235294     0.897436   \n",
       "\n",
       "        space_frac    punc_frac   upper_frac  flesch_reading_ease  \\\n",
       "count  5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean      0.177722     0.029905     0.030517            75.253105   \n",
       "std       0.021473     0.024070     0.049035            19.903004   \n",
       "min       0.040541     0.000000     0.000000           -48.980000   \n",
       "1%        0.117647     0.000000     0.000000            19.430301   \n",
       "5%        0.141414     0.000000     0.005062            41.869999   \n",
       "10%       0.151515     0.010417     0.008333            50.669998   \n",
       "20%       0.161966     0.015385     0.011758            59.980000   \n",
       "30%       0.168627     0.018692     0.014599            66.739998   \n",
       "40%       0.173913     0.021652     0.017857            72.144003   \n",
       "50%       0.178947     0.025000     0.021277            76.220001   \n",
       "60%       0.183486     0.028571     0.025502            80.919998   \n",
       "70%       0.188464     0.032787     0.030928            85.690002   \n",
       "80%       0.194306     0.040000     0.038981            91.110001   \n",
       "90%       0.202703     0.054054     0.054560            99.570000   \n",
       "95%       0.210526     0.069767     0.074074           105.660004   \n",
       "99%       0.227273     0.119969     0.159718           116.150002   \n",
       "max       0.272727     0.402174     0.857143           118.680000   \n",
       "\n",
       "       flesch_kincaid_grade  syllable_count  lexicon_count  sentence_count  \\\n",
       "count           5710.000000     5710.000000    5710.000000     5710.000000   \n",
       "mean               6.685254       50.067426      36.371278        2.319790   \n",
       "std                4.430519       44.035705      31.194250        1.722369   \n",
       "min               -2.500000        3.000000       2.000000        1.000000   \n",
       "1%                -1.500000        6.000000       5.000000        1.000000   \n",
       "5%                 0.500000        8.000000       6.000000        1.000000   \n",
       "10%                1.700000       10.000000       8.000000        1.000000   \n",
       "20%                3.100000       15.000000      11.000000        1.000000   \n",
       "30%                4.400000       20.000000      15.000000        1.000000   \n",
       "40%                5.300000       27.000000      20.000000        1.000000   \n",
       "50%                6.400000       34.000000      25.000000        2.000000   \n",
       "60%                7.200000       44.000000      33.000000        2.000000   \n",
       "70%                8.400000       59.000000      43.000000        3.000000   \n",
       "80%                9.900000       81.000000      59.000000        3.000000   \n",
       "90%               12.100000      117.000000      83.000000        5.000000   \n",
       "95%               14.200000      148.000000     105.000000        6.000000   \n",
       "99%               20.373000      191.000000     136.000000        8.000000   \n",
       "max               51.599998      243.000000     150.000000       19.000000   \n",
       "\n",
       "       gunning_fog   smog_index  automated_readability_index  \\\n",
       "count  5710.000000  5710.000000                  5710.000000   \n",
       "mean      8.998004     3.062995                     7.482505   \n",
       "std       4.645890     4.695458                     5.593331   \n",
       "min       0.800000     0.000000                    -8.700000   \n",
       "1%        2.000000     0.000000                    -3.000000   \n",
       "5%        2.400000     0.000000                    -0.200000   \n",
       "10%       3.200000     0.000000                     1.290000   \n",
       "20%       4.870000     0.000000                     3.200000   \n",
       "30%       6.364000     0.000000                     4.600000   \n",
       "40%       8.000000     0.000000                     5.800000   \n",
       "50%       8.510000     0.000000                     7.000000   \n",
       "60%       9.600000     0.000000                     8.200000   \n",
       "70%      10.853000     6.000000                     9.400000   \n",
       "80%      12.134000     8.800000                    11.200000   \n",
       "90%      14.501000    10.700000                    13.800000   \n",
       "95%      16.930000    12.000000                    16.600000   \n",
       "99%      23.709999    14.300000                    24.799999   \n",
       "max      55.520000    18.900000                    64.900002   \n",
       "\n",
       "       coleman_liau_index  linsear_write_formula  \\\n",
       "count         5710.000000            5710.000000   \n",
       "mean             6.631683               8.562484   \n",
       "std              3.883116               5.906460   \n",
       "min            -10.160000               0.000000   \n",
       "1%              -3.003700               1.500000   \n",
       "5%               0.320000               2.000000   \n",
       "10%              1.820000               2.741667   \n",
       "20%              3.698000               4.000000   \n",
       "30%              4.930000               5.000000   \n",
       "40%              5.900000               6.000000   \n",
       "50%              6.680000               7.000000   \n",
       "60%              7.484000               8.250000   \n",
       "70%              8.460000              10.676667   \n",
       "80%              9.520000              12.500000   \n",
       "90%             11.140000              15.666667   \n",
       "95%             12.620000              19.250000   \n",
       "99%             16.534699              29.455000   \n",
       "max             40.599998              66.000000   \n",
       "\n",
       "       dale_chall_readability_score  dto_toxicity  dto_severe_toxicity  \\\n",
       "count                   5710.000000   5710.000000          5710.000000   \n",
       "mean                       8.299163      0.177856             0.013080   \n",
       "std                        2.270676      0.326334             0.052992   \n",
       "min                        0.200000      0.000506             0.000080   \n",
       "1%                         0.350000      0.000556             0.000087   \n",
       "5%                         5.620000      0.000614             0.000093   \n",
       "10%                        6.240000      0.000668             0.000097   \n",
       "20%                        6.930000      0.000797             0.000103   \n",
       "30%                        7.380000      0.001006             0.000108   \n",
       "40%                        7.820000      0.001533             0.000114   \n",
       "50%                        8.210000      0.004124             0.000121   \n",
       "60%                        8.590000      0.015243             0.000132   \n",
       "70%                        9.120000      0.056457             0.000225   \n",
       "80%                        9.760000      0.318193             0.001118   \n",
       "90%                       10.750000      0.887332             0.016841   \n",
       "95%                       11.830000      0.985316             0.086339   \n",
       "99%                       14.561900      0.997169             0.282513   \n",
       "max                       29.150000      0.999072             0.764529   \n",
       "\n",
       "       dto_obscene   dto_threat   dto_insult  dto_identity_attack  \\\n",
       "count  5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean      0.113673     0.008411     0.059683             0.011454   \n",
       "std       0.282462     0.056317     0.175381             0.064708   \n",
       "min       0.000141     0.000086     0.000164             0.000121   \n",
       "1%        0.000158     0.000096     0.000171             0.000134   \n",
       "5%        0.000165     0.000103     0.000175             0.000138   \n",
       "10%       0.000170     0.000108     0.000177             0.000140   \n",
       "20%       0.000176     0.000115     0.000181             0.000145   \n",
       "30%       0.000183     0.000121     0.000188             0.000151   \n",
       "40%       0.000196     0.000127     0.000207             0.000165   \n",
       "50%       0.000280     0.000138     0.000298             0.000211   \n",
       "60%       0.000578     0.000209     0.000679             0.000361   \n",
       "70%       0.001707     0.000431     0.002063             0.000867   \n",
       "80%       0.018481     0.001115     0.014511             0.002603   \n",
       "90%       0.670921     0.003118     0.168232             0.009993   \n",
       "95%       0.948901     0.009527     0.480264             0.032305   \n",
       "99%       0.984720     0.317607     0.887015             0.263866   \n",
       "max       0.994431     0.823060     0.980776             0.894015   \n",
       "\n",
       "       dtu_toxicity  dtu_severe_toxicity  dtu_obscene  dtu_identity_attack  \\\n",
       "count   5710.000000         5.710000e+03  5710.000000          5710.000000   \n",
       "mean       0.195873         4.698273e-03     0.113027             0.015234   \n",
       "std        0.341383         2.272458e-02     0.285412             0.074354   \n",
       "min        0.000286         9.529070e-07     0.000017             0.000052   \n",
       "1%         0.000360         1.087282e-06     0.000021             0.000063   \n",
       "5%         0.000410         1.200621e-06     0.000024             0.000070   \n",
       "10%        0.000454         1.271093e-06     0.000026             0.000076   \n",
       "20%        0.000572         1.407266e-06     0.000031             0.000089   \n",
       "30%        0.000850         1.645227e-06     0.000041             0.000113   \n",
       "40%        0.001636         2.303226e-06     0.000067             0.000175   \n",
       "50%        0.003793         4.173747e-06     0.000131             0.000366   \n",
       "60%        0.014255         1.015833e-05     0.000302             0.000847   \n",
       "70%        0.078342         3.191344e-05     0.000959             0.002036   \n",
       "80%        0.430039         1.706842e-04     0.006408             0.004938   \n",
       "90%        0.930690         4.385715e-03     0.736380             0.015910   \n",
       "95%        0.979522         2.221569e-02     0.934339             0.042194   \n",
       "99%        0.994499         1.104791e-01     0.975236             0.457570   \n",
       "max        0.998344         4.605981e-01     0.987875             0.984674   \n",
       "\n",
       "        dtu_insult   dtu_threat  dtu_sexual_explicit  dtm_toxicity  \\\n",
       "count  5710.000000  5710.000000          5710.000000   5710.000000   \n",
       "mean      0.081492     0.011010             0.040167      0.203075   \n",
       "std       0.207780     0.069685             0.149433      0.345334   \n",
       "min       0.000061     0.000012             0.000009      0.000178   \n",
       "1%        0.000092     0.000015             0.000011      0.000281   \n",
       "5%        0.000103     0.000017             0.000012      0.000357   \n",
       "10%       0.000111     0.000019             0.000013      0.000417   \n",
       "20%       0.000133     0.000023             0.000016      0.000578   \n",
       "30%       0.000177     0.000030             0.000021      0.000857   \n",
       "40%       0.000311     0.000048             0.000033      0.001655   \n",
       "50%       0.000660     0.000089             0.000069      0.004238   \n",
       "60%       0.001623     0.000180             0.000176      0.015952   \n",
       "70%       0.005559     0.000397             0.000531      0.091781   \n",
       "80%       0.042105     0.000974             0.003249      0.487258   \n",
       "90%       0.295351     0.002905             0.042829      0.927200   \n",
       "95%       0.656381     0.014624             0.283533      0.976718   \n",
       "99%       0.947763     0.401428             0.863210      0.994160   \n",
       "max       0.993023     0.925068             0.974648      0.999047   \n",
       "\n",
       "       dtm_severe_toxicity  dtm_obscene  dtm_identity_attack   dtm_insult  \\\n",
       "count          5710.000000  5710.000000          5710.000000  5710.000000   \n",
       "mean              0.005742     0.105158             0.013474     0.083563   \n",
       "std               0.027226     0.272925             0.075226     0.214901   \n",
       "min               0.000009     0.000063             0.000045     0.000095   \n",
       "1%                0.000013     0.000095             0.000066     0.000149   \n",
       "5%                0.000016     0.000115             0.000078     0.000177   \n",
       "10%               0.000019     0.000129             0.000086     0.000200   \n",
       "20%               0.000023     0.000159             0.000099     0.000247   \n",
       "30%               0.000027     0.000201             0.000118     0.000327   \n",
       "40%               0.000033     0.000272             0.000152     0.000511   \n",
       "50%               0.000046     0.000438             0.000244     0.001043   \n",
       "60%               0.000085     0.000760             0.000504     0.002455   \n",
       "70%               0.000210     0.001610             0.001241     0.007981   \n",
       "80%               0.000817     0.005910             0.003259     0.041335   \n",
       "90%               0.007909     0.658297             0.010893     0.306216   \n",
       "95%               0.029604     0.911508             0.032165     0.689002   \n",
       "99%               0.127040     0.977652             0.404110     0.969594   \n",
       "max               0.672039     0.993243             0.965869     0.994790   \n",
       "\n",
       "        dtm_threat  dtm_sexual_explicit  hb_bert_off  hb_bert_abu  \\\n",
       "count  5710.000000          5710.000000  5710.000000  5710.000000   \n",
       "mean      0.014735             0.044618     0.332577     0.166173   \n",
       "std       0.078828             0.155314     0.332031     0.278667   \n",
       "min       0.000014             0.000012     0.008860     0.002739   \n",
       "1%        0.000021             0.000017     0.013618     0.003827   \n",
       "5%        0.000027             0.000020     0.021350     0.005177   \n",
       "10%       0.000031             0.000022     0.029108     0.006430   \n",
       "20%       0.000037             0.000026     0.045445     0.009145   \n",
       "30%       0.000046             0.000032     0.071743     0.012743   \n",
       "40%       0.000065             0.000045     0.108833     0.018178   \n",
       "50%       0.000123             0.000090     0.171648     0.027659   \n",
       "60%       0.000310             0.000239     0.282971     0.048089   \n",
       "70%       0.000952             0.000792     0.460070     0.097038   \n",
       "80%       0.002956             0.004605     0.719423     0.248265   \n",
       "90%       0.010762             0.079094     0.928643     0.710093   \n",
       "95%       0.036829             0.330517     0.960833     0.914900   \n",
       "99%       0.472689             0.890709     0.972503     0.967271   \n",
       "max       0.962406             0.982923     0.978723     0.977543   \n",
       "\n",
       "       hb_hatebert_off  hb_hatebert_abu  te_roberta_off  te_roberta_emo_anger  \\\n",
       "count      5710.000000      5710.000000     5710.000000           5710.000000   \n",
       "mean          0.329977         0.144314        0.350061              0.507189   \n",
       "std           0.284761         0.221301        0.251317              0.357695   \n",
       "min           0.007778         0.007624        0.021641              0.004902   \n",
       "1%            0.021895         0.010283        0.049634              0.010852   \n",
       "5%            0.036465         0.013695        0.074244              0.024071   \n",
       "10%           0.049953         0.016057        0.091896              0.039984   \n",
       "20%           0.078526         0.020993        0.124509              0.089963   \n",
       "30%           0.113060         0.027239        0.161852              0.175718   \n",
       "40%           0.157839         0.035502        0.208463              0.321477   \n",
       "50%           0.218091         0.047703        0.265905              0.526801   \n",
       "60%           0.310787         0.067547        0.342768              0.714927   \n",
       "70%           0.439863         0.106683        0.449289              0.837082   \n",
       "80%           0.615488         0.189939        0.589677              0.911141   \n",
       "90%           0.824093         0.460149        0.784665              0.955451   \n",
       "95%           0.908639         0.737487        0.858253              0.968262   \n",
       "99%           0.957988         0.945889        0.913508              0.979008   \n",
       "max           0.979833         0.977078        0.950407              0.985018   \n",
       "\n",
       "       te_roberta_snt_neg  te_roberta_iro  \n",
       "count         5710.000000     5710.000000  \n",
       "mean             0.508503        0.313383  \n",
       "std              0.319341        0.276529  \n",
       "min              0.000799        0.014366  \n",
       "1%               0.001768        0.022520  \n",
       "5%               0.008642        0.034839  \n",
       "10%              0.032663        0.046494  \n",
       "20%              0.146359        0.072034  \n",
       "30%              0.295210        0.102903  \n",
       "40%              0.416262        0.145013  \n",
       "50%              0.535722        0.200985  \n",
       "60%              0.652210        0.291033  \n",
       "70%              0.758375        0.414743  \n",
       "80%              0.846273        0.584716  \n",
       "90%              0.921829        0.786549  \n",
       "95%              0.953920        0.886064  \n",
       "99%              0.973875        0.960554  \n",
       "max              0.982809        0.990079  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"worker\"\n",
    "df[col] = 0\n",
    "df[col] = df[col].astype(np.int8)\n",
    "cols = [\"label\", \"bws\", \"worker\"]\n",
    "cols += char_fs + textstat_fs + dtfy_fs \n",
    "cols += list(conf.hatebert_models.keys()) \n",
    "cols += list(conf.tweeteval_models.keys()) \n",
    "df[cols].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bddf8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 432 columns):\n",
      " #    Column                        Non-Null Count  Dtype  \n",
      "---   ------                        --------------  -----  \n",
      " 0    label                         5710 non-null   int32  \n",
      " 1    bws                           5710 non-null   float32\n",
      " 2    worker                        5710 non-null   int8   \n",
      " 3    length                        5710 non-null   int16  \n",
      " 4    digit_frac                    5710 non-null   float32\n",
      " 5    letter_frac                   5710 non-null   float32\n",
      " 6    space_frac                    5710 non-null   float32\n",
      " 7    punc_frac                     5710 non-null   float32\n",
      " 8    upper_frac                    5710 non-null   float32\n",
      " 9    flesch_reading_ease           5710 non-null   float32\n",
      " 10   flesch_kincaid_grade          5710 non-null   float32\n",
      " 11   syllable_count                5710 non-null   int16  \n",
      " 12   lexicon_count                 5710 non-null   int16  \n",
      " 13   sentence_count                5710 non-null   int16  \n",
      " 14   gunning_fog                   5710 non-null   float32\n",
      " 15   smog_index                    5710 non-null   float32\n",
      " 16   automated_readability_index   5710 non-null   float32\n",
      " 17   coleman_liau_index            5710 non-null   float32\n",
      " 18   linsear_write_formula         5710 non-null   float32\n",
      " 19   dale_chall_readability_score  5710 non-null   float32\n",
      " 20   dto_toxicity                  5710 non-null   float32\n",
      " 21   dto_severe_toxicity           5710 non-null   float32\n",
      " 22   dto_obscene                   5710 non-null   float32\n",
      " 23   dto_threat                    5710 non-null   float32\n",
      " 24   dto_insult                    5710 non-null   float32\n",
      " 25   dto_identity_attack           5710 non-null   float32\n",
      " 26   dtu_toxicity                  5710 non-null   float32\n",
      " 27   dtu_severe_toxicity           5710 non-null   float32\n",
      " 28   dtu_obscene                   5710 non-null   float32\n",
      " 29   dtu_identity_attack           5710 non-null   float32\n",
      " 30   dtu_insult                    5710 non-null   float32\n",
      " 31   dtu_threat                    5710 non-null   float32\n",
      " 32   dtu_sexual_explicit           5710 non-null   float32\n",
      " 33   dtm_toxicity                  5710 non-null   float32\n",
      " 34   dtm_severe_toxicity           5710 non-null   float32\n",
      " 35   dtm_obscene                   5710 non-null   float32\n",
      " 36   dtm_identity_attack           5710 non-null   float32\n",
      " 37   dtm_insult                    5710 non-null   float32\n",
      " 38   dtm_threat                    5710 non-null   float32\n",
      " 39   dtm_sexual_explicit           5710 non-null   float32\n",
      " 40   hb_bert_off                   5710 non-null   float32\n",
      " 41   hb_bert_abu                   5710 non-null   float32\n",
      " 42   hb_hatebert_off               5710 non-null   float32\n",
      " 43   hb_hatebert_abu               5710 non-null   float32\n",
      " 44   te_roberta_off                5710 non-null   float32\n",
      " 45   te_roberta_emo_anger          5710 non-null   float32\n",
      " 46   te_roberta_snt_neg            5710 non-null   float32\n",
      " 47   te_roberta_iro                5710 non-null   float32\n",
      " 48   zz0000                        5710 non-null   float32\n",
      " 49   zz0001                        5710 non-null   float32\n",
      " 50   zz0002                        5710 non-null   float32\n",
      " 51   zz0003                        5710 non-null   float32\n",
      " 52   zz0004                        5710 non-null   float32\n",
      " 53   zz0005                        5710 non-null   float32\n",
      " 54   zz0006                        5710 non-null   float32\n",
      " 55   zz0007                        5710 non-null   float32\n",
      " 56   zz0008                        5710 non-null   float32\n",
      " 57   zz0009                        5710 non-null   float32\n",
      " 58   zz0010                        5710 non-null   float32\n",
      " 59   zz0011                        5710 non-null   float32\n",
      " 60   zz0012                        5710 non-null   float32\n",
      " 61   zz0013                        5710 non-null   float32\n",
      " 62   zz0014                        5710 non-null   float32\n",
      " 63   zz0015                        5710 non-null   float32\n",
      " 64   zz0016                        5710 non-null   float32\n",
      " 65   zz0017                        5710 non-null   float32\n",
      " 66   zz0018                        5710 non-null   float32\n",
      " 67   zz0019                        5710 non-null   float32\n",
      " 68   zz0020                        5710 non-null   float32\n",
      " 69   zz0021                        5710 non-null   float32\n",
      " 70   zz0022                        5710 non-null   float32\n",
      " 71   zz0023                        5710 non-null   float32\n",
      " 72   zz0024                        5710 non-null   float32\n",
      " 73   zz0025                        5710 non-null   float32\n",
      " 74   zz0026                        5710 non-null   float32\n",
      " 75   zz0027                        5710 non-null   float32\n",
      " 76   zz0028                        5710 non-null   float32\n",
      " 77   zz0029                        5710 non-null   float32\n",
      " 78   zz0030                        5710 non-null   float32\n",
      " 79   zz0031                        5710 non-null   float32\n",
      " 80   zz0032                        5710 non-null   float32\n",
      " 81   zz0033                        5710 non-null   float32\n",
      " 82   zz0034                        5710 non-null   float32\n",
      " 83   zz0035                        5710 non-null   float32\n",
      " 84   zz0036                        5710 non-null   float32\n",
      " 85   zz0037                        5710 non-null   float32\n",
      " 86   zz0038                        5710 non-null   float32\n",
      " 87   zz0039                        5710 non-null   float32\n",
      " 88   zz0040                        5710 non-null   float32\n",
      " 89   zz0041                        5710 non-null   float32\n",
      " 90   zz0042                        5710 non-null   float32\n",
      " 91   zz0043                        5710 non-null   float32\n",
      " 92   zz0044                        5710 non-null   float32\n",
      " 93   zz0045                        5710 non-null   float32\n",
      " 94   zz0046                        5710 non-null   float32\n",
      " 95   zz0047                        5710 non-null   float32\n",
      " 96   zz0048                        5710 non-null   float32\n",
      " 97   zz0049                        5710 non-null   float32\n",
      " 98   zz0050                        5710 non-null   float32\n",
      " 99   zz0051                        5710 non-null   float32\n",
      " 100  zz0052                        5710 non-null   float32\n",
      " 101  zz0053                        5710 non-null   float32\n",
      " 102  zz0054                        5710 non-null   float32\n",
      " 103  zz0055                        5710 non-null   float32\n",
      " 104  zz0056                        5710 non-null   float32\n",
      " 105  zz0057                        5710 non-null   float32\n",
      " 106  zz0058                        5710 non-null   float32\n",
      " 107  zz0059                        5710 non-null   float32\n",
      " 108  zz0060                        5710 non-null   float32\n",
      " 109  zz0061                        5710 non-null   float32\n",
      " 110  zz0062                        5710 non-null   float32\n",
      " 111  zz0063                        5710 non-null   float32\n",
      " 112  zz0064                        5710 non-null   float32\n",
      " 113  zz0065                        5710 non-null   float32\n",
      " 114  zz0066                        5710 non-null   float32\n",
      " 115  zz0067                        5710 non-null   float32\n",
      " 116  zz0068                        5710 non-null   float32\n",
      " 117  zz0069                        5710 non-null   float32\n",
      " 118  zz0070                        5710 non-null   float32\n",
      " 119  zz0071                        5710 non-null   float32\n",
      " 120  zz0072                        5710 non-null   float32\n",
      " 121  zz0073                        5710 non-null   float32\n",
      " 122  zz0074                        5710 non-null   float32\n",
      " 123  zz0075                        5710 non-null   float32\n",
      " 124  zz0076                        5710 non-null   float32\n",
      " 125  zz0077                        5710 non-null   float32\n",
      " 126  zz0078                        5710 non-null   float32\n",
      " 127  zz0079                        5710 non-null   float32\n",
      " 128  zz0080                        5710 non-null   float32\n",
      " 129  zz0081                        5710 non-null   float32\n",
      " 130  zz0082                        5710 non-null   float32\n",
      " 131  zz0083                        5710 non-null   float32\n",
      " 132  zz0084                        5710 non-null   float32\n",
      " 133  zz0085                        5710 non-null   float32\n",
      " 134  zz0086                        5710 non-null   float32\n",
      " 135  zz0087                        5710 non-null   float32\n",
      " 136  zz0088                        5710 non-null   float32\n",
      " 137  zz0089                        5710 non-null   float32\n",
      " 138  zz0090                        5710 non-null   float32\n",
      " 139  zz0091                        5710 non-null   float32\n",
      " 140  zz0092                        5710 non-null   float32\n",
      " 141  zz0093                        5710 non-null   float32\n",
      " 142  zz0094                        5710 non-null   float32\n",
      " 143  zz0095                        5710 non-null   float32\n",
      " 144  zz0096                        5710 non-null   float32\n",
      " 145  zz0097                        5710 non-null   float32\n",
      " 146  zz0098                        5710 non-null   float32\n",
      " 147  zz0099                        5710 non-null   float32\n",
      " 148  zz0100                        5710 non-null   float32\n",
      " 149  zz0101                        5710 non-null   float32\n",
      " 150  zz0102                        5710 non-null   float32\n",
      " 151  zz0103                        5710 non-null   float32\n",
      " 152  zz0104                        5710 non-null   float32\n",
      " 153  zz0105                        5710 non-null   float32\n",
      " 154  zz0106                        5710 non-null   float32\n",
      " 155  zz0107                        5710 non-null   float32\n",
      " 156  zz0108                        5710 non-null   float32\n",
      " 157  zz0109                        5710 non-null   float32\n",
      " 158  zz0110                        5710 non-null   float32\n",
      " 159  zz0111                        5710 non-null   float32\n",
      " 160  zz0112                        5710 non-null   float32\n",
      " 161  zz0113                        5710 non-null   float32\n",
      " 162  zz0114                        5710 non-null   float32\n",
      " 163  zz0115                        5710 non-null   float32\n",
      " 164  zz0116                        5710 non-null   float32\n",
      " 165  zz0117                        5710 non-null   float32\n",
      " 166  zz0118                        5710 non-null   float32\n",
      " 167  zz0119                        5710 non-null   float32\n",
      " 168  zz0120                        5710 non-null   float32\n",
      " 169  zz0121                        5710 non-null   float32\n",
      " 170  zz0122                        5710 non-null   float32\n",
      " 171  zz0123                        5710 non-null   float32\n",
      " 172  zz0124                        5710 non-null   float32\n",
      " 173  zz0125                        5710 non-null   float32\n",
      " 174  zz0126                        5710 non-null   float32\n",
      " 175  zz0127                        5710 non-null   float32\n",
      " 176  zz0128                        5710 non-null   float32\n",
      " 177  zz0129                        5710 non-null   float32\n",
      " 178  zz0130                        5710 non-null   float32\n",
      " 179  zz0131                        5710 non-null   float32\n",
      " 180  zz0132                        5710 non-null   float32\n",
      " 181  zz0133                        5710 non-null   float32\n",
      " 182  zz0134                        5710 non-null   float32\n",
      " 183  zz0135                        5710 non-null   float32\n",
      " 184  zz0136                        5710 non-null   float32\n",
      " 185  zz0137                        5710 non-null   float32\n",
      " 186  zz0138                        5710 non-null   float32\n",
      " 187  zz0139                        5710 non-null   float32\n",
      " 188  zz0140                        5710 non-null   float32\n",
      " 189  zz0141                        5710 non-null   float32\n",
      " 190  zz0142                        5710 non-null   float32\n",
      " 191  zz0143                        5710 non-null   float32\n",
      " 192  zz0144                        5710 non-null   float32\n",
      " 193  zz0145                        5710 non-null   float32\n",
      " 194  zz0146                        5710 non-null   float32\n",
      " 195  zz0147                        5710 non-null   float32\n",
      " 196  zz0148                        5710 non-null   float32\n",
      " 197  zz0149                        5710 non-null   float32\n",
      " 198  zz0150                        5710 non-null   float32\n",
      " 199  zz0151                        5710 non-null   float32\n",
      " 200  zz0152                        5710 non-null   float32\n",
      " 201  zz0153                        5710 non-null   float32\n",
      " 202  zz0154                        5710 non-null   float32\n",
      " 203  zz0155                        5710 non-null   float32\n",
      " 204  zz0156                        5710 non-null   float32\n",
      " 205  zz0157                        5710 non-null   float32\n",
      " 206  zz0158                        5710 non-null   float32\n",
      " 207  zz0159                        5710 non-null   float32\n",
      " 208  zz0160                        5710 non-null   float32\n",
      " 209  zz0161                        5710 non-null   float32\n",
      " 210  zz0162                        5710 non-null   float32\n",
      " 211  zz0163                        5710 non-null   float32\n",
      " 212  zz0164                        5710 non-null   float32\n",
      " 213  zz0165                        5710 non-null   float32\n",
      " 214  zz0166                        5710 non-null   float32\n",
      " 215  zz0167                        5710 non-null   float32\n",
      " 216  zz0168                        5710 non-null   float32\n",
      " 217  zz0169                        5710 non-null   float32\n",
      " 218  zz0170                        5710 non-null   float32\n",
      " 219  zz0171                        5710 non-null   float32\n",
      " 220  zz0172                        5710 non-null   float32\n",
      " 221  zz0173                        5710 non-null   float32\n",
      " 222  zz0174                        5710 non-null   float32\n",
      " 223  zz0175                        5710 non-null   float32\n",
      " 224  zz0176                        5710 non-null   float32\n",
      " 225  zz0177                        5710 non-null   float32\n",
      " 226  zz0178                        5710 non-null   float32\n",
      " 227  zz0179                        5710 non-null   float32\n",
      " 228  zz0180                        5710 non-null   float32\n",
      " 229  zz0181                        5710 non-null   float32\n",
      " 230  zz0182                        5710 non-null   float32\n",
      " 231  zz0183                        5710 non-null   float32\n",
      " 232  zz0184                        5710 non-null   float32\n",
      " 233  zz0185                        5710 non-null   float32\n",
      " 234  zz0186                        5710 non-null   float32\n",
      " 235  zz0187                        5710 non-null   float32\n",
      " 236  zz0188                        5710 non-null   float32\n",
      " 237  zz0189                        5710 non-null   float32\n",
      " 238  zz0190                        5710 non-null   float32\n",
      " 239  zz0191                        5710 non-null   float32\n",
      " 240  zz0192                        5710 non-null   float32\n",
      " 241  zz0193                        5710 non-null   float32\n",
      " 242  zz0194                        5710 non-null   float32\n",
      " 243  zz0195                        5710 non-null   float32\n",
      " 244  zz0196                        5710 non-null   float32\n",
      " 245  zz0197                        5710 non-null   float32\n",
      " 246  zz0198                        5710 non-null   float32\n",
      " 247  zz0199                        5710 non-null   float32\n",
      " 248  zz0200                        5710 non-null   float32\n",
      " 249  zz0201                        5710 non-null   float32\n",
      " 250  zz0202                        5710 non-null   float32\n",
      " 251  zz0203                        5710 non-null   float32\n",
      " 252  zz0204                        5710 non-null   float32\n",
      " 253  zz0205                        5710 non-null   float32\n",
      " 254  zz0206                        5710 non-null   float32\n",
      " 255  zz0207                        5710 non-null   float32\n",
      " 256  zz0208                        5710 non-null   float32\n",
      " 257  zz0209                        5710 non-null   float32\n",
      " 258  zz0210                        5710 non-null   float32\n",
      " 259  zz0211                        5710 non-null   float32\n",
      " 260  zz0212                        5710 non-null   float32\n",
      " 261  zz0213                        5710 non-null   float32\n",
      " 262  zz0214                        5710 non-null   float32\n",
      " 263  zz0215                        5710 non-null   float32\n",
      " 264  zz0216                        5710 non-null   float32\n",
      " 265  zz0217                        5710 non-null   float32\n",
      " 266  zz0218                        5710 non-null   float32\n",
      " 267  zz0219                        5710 non-null   float32\n",
      " 268  zz0220                        5710 non-null   float32\n",
      " 269  zz0221                        5710 non-null   float32\n",
      " 270  zz0222                        5710 non-null   float32\n",
      " 271  zz0223                        5710 non-null   float32\n",
      " 272  zz0224                        5710 non-null   float32\n",
      " 273  zz0225                        5710 non-null   float32\n",
      " 274  zz0226                        5710 non-null   float32\n",
      " 275  zz0227                        5710 non-null   float32\n",
      " 276  zz0228                        5710 non-null   float32\n",
      " 277  zz0229                        5710 non-null   float32\n",
      " 278  zz0230                        5710 non-null   float32\n",
      " 279  zz0231                        5710 non-null   float32\n",
      " 280  zz0232                        5710 non-null   float32\n",
      " 281  zz0233                        5710 non-null   float32\n",
      " 282  zz0234                        5710 non-null   float32\n",
      " 283  zz0235                        5710 non-null   float32\n",
      " 284  zz0236                        5710 non-null   float32\n",
      " 285  zz0237                        5710 non-null   float32\n",
      " 286  zz0238                        5710 non-null   float32\n",
      " 287  zz0239                        5710 non-null   float32\n",
      " 288  zz0240                        5710 non-null   float32\n",
      " 289  zz0241                        5710 non-null   float32\n",
      " 290  zz0242                        5710 non-null   float32\n",
      " 291  zz0243                        5710 non-null   float32\n",
      " 292  zz0244                        5710 non-null   float32\n",
      " 293  zz0245                        5710 non-null   float32\n",
      " 294  zz0246                        5710 non-null   float32\n",
      " 295  zz0247                        5710 non-null   float32\n",
      " 296  zz0248                        5710 non-null   float32\n",
      " 297  zz0249                        5710 non-null   float32\n",
      " 298  zz0250                        5710 non-null   float32\n",
      " 299  zz0251                        5710 non-null   float32\n",
      " 300  zz0252                        5710 non-null   float32\n",
      " 301  zz0253                        5710 non-null   float32\n",
      " 302  zz0254                        5710 non-null   float32\n",
      " 303  zz0255                        5710 non-null   float32\n",
      " 304  zz0256                        5710 non-null   float32\n",
      " 305  zz0257                        5710 non-null   float32\n",
      " 306  zz0258                        5710 non-null   float32\n",
      " 307  zz0259                        5710 non-null   float32\n",
      " 308  zz0260                        5710 non-null   float32\n",
      " 309  zz0261                        5710 non-null   float32\n",
      " 310  zz0262                        5710 non-null   float32\n",
      " 311  zz0263                        5710 non-null   float32\n",
      " 312  zz0264                        5710 non-null   float32\n",
      " 313  zz0265                        5710 non-null   float32\n",
      " 314  zz0266                        5710 non-null   float32\n",
      " 315  zz0267                        5710 non-null   float32\n",
      " 316  zz0268                        5710 non-null   float32\n",
      " 317  zz0269                        5710 non-null   float32\n",
      " 318  zz0270                        5710 non-null   float32\n",
      " 319  zz0271                        5710 non-null   float32\n",
      " 320  zz0272                        5710 non-null   float32\n",
      " 321  zz0273                        5710 non-null   float32\n",
      " 322  zz0274                        5710 non-null   float32\n",
      " 323  zz0275                        5710 non-null   float32\n",
      " 324  zz0276                        5710 non-null   float32\n",
      " 325  zz0277                        5710 non-null   float32\n",
      " 326  zz0278                        5710 non-null   float32\n",
      " 327  zz0279                        5710 non-null   float32\n",
      " 328  zz0280                        5710 non-null   float32\n",
      " 329  zz0281                        5710 non-null   float32\n",
      " 330  zz0282                        5710 non-null   float32\n",
      " 331  zz0283                        5710 non-null   float32\n",
      " 332  zz0284                        5710 non-null   float32\n",
      " 333  zz0285                        5710 non-null   float32\n",
      " 334  zz0286                        5710 non-null   float32\n",
      " 335  zz0287                        5710 non-null   float32\n",
      " 336  zz0288                        5710 non-null   float32\n",
      " 337  zz0289                        5710 non-null   float32\n",
      " 338  zz0290                        5710 non-null   float32\n",
      " 339  zz0291                        5710 non-null   float32\n",
      " 340  zz0292                        5710 non-null   float32\n",
      " 341  zz0293                        5710 non-null   float32\n",
      " 342  zz0294                        5710 non-null   float32\n",
      " 343  zz0295                        5710 non-null   float32\n",
      " 344  zz0296                        5710 non-null   float32\n",
      " 345  zz0297                        5710 non-null   float32\n",
      " 346  zz0298                        5710 non-null   float32\n",
      " 347  zz0299                        5710 non-null   float32\n",
      " 348  zz0300                        5710 non-null   float32\n",
      " 349  zz0301                        5710 non-null   float32\n",
      " 350  zz0302                        5710 non-null   float32\n",
      " 351  zz0303                        5710 non-null   float32\n",
      " 352  zz0304                        5710 non-null   float32\n",
      " 353  zz0305                        5710 non-null   float32\n",
      " 354  zz0306                        5710 non-null   float32\n",
      " 355  zz0307                        5710 non-null   float32\n",
      " 356  zz0308                        5710 non-null   float32\n",
      " 357  zz0309                        5710 non-null   float32\n",
      " 358  zz0310                        5710 non-null   float32\n",
      " 359  zz0311                        5710 non-null   float32\n",
      " 360  zz0312                        5710 non-null   float32\n",
      " 361  zz0313                        5710 non-null   float32\n",
      " 362  zz0314                        5710 non-null   float32\n",
      " 363  zz0315                        5710 non-null   float32\n",
      " 364  zz0316                        5710 non-null   float32\n",
      " 365  zz0317                        5710 non-null   float32\n",
      " 366  zz0318                        5710 non-null   float32\n",
      " 367  zz0319                        5710 non-null   float32\n",
      " 368  zz0320                        5710 non-null   float32\n",
      " 369  zz0321                        5710 non-null   float32\n",
      " 370  zz0322                        5710 non-null   float32\n",
      " 371  zz0323                        5710 non-null   float32\n",
      " 372  zz0324                        5710 non-null   float32\n",
      " 373  zz0325                        5710 non-null   float32\n",
      " 374  zz0326                        5710 non-null   float32\n",
      " 375  zz0327                        5710 non-null   float32\n",
      " 376  zz0328                        5710 non-null   float32\n",
      " 377  zz0329                        5710 non-null   float32\n",
      " 378  zz0330                        5710 non-null   float32\n",
      " 379  zz0331                        5710 non-null   float32\n",
      " 380  zz0332                        5710 non-null   float32\n",
      " 381  zz0333                        5710 non-null   float32\n",
      " 382  zz0334                        5710 non-null   float32\n",
      " 383  zz0335                        5710 non-null   float32\n",
      " 384  zz0336                        5710 non-null   float32\n",
      " 385  zz0337                        5710 non-null   float32\n",
      " 386  zz0338                        5710 non-null   float32\n",
      " 387  zz0339                        5710 non-null   float32\n",
      " 388  zz0340                        5710 non-null   float32\n",
      " 389  zz0341                        5710 non-null   float32\n",
      " 390  zz0342                        5710 non-null   float32\n",
      " 391  zz0343                        5710 non-null   float32\n",
      " 392  zz0344                        5710 non-null   float32\n",
      " 393  zz0345                        5710 non-null   float32\n",
      " 394  zz0346                        5710 non-null   float32\n",
      " 395  zz0347                        5710 non-null   float32\n",
      " 396  zz0348                        5710 non-null   float32\n",
      " 397  zz0349                        5710 non-null   float32\n",
      " 398  zz0350                        5710 non-null   float32\n",
      " 399  zz0351                        5710 non-null   float32\n",
      " 400  zz0352                        5710 non-null   float32\n",
      " 401  zz0353                        5710 non-null   float32\n",
      " 402  zz0354                        5710 non-null   float32\n",
      " 403  zz0355                        5710 non-null   float32\n",
      " 404  zz0356                        5710 non-null   float32\n",
      " 405  zz0357                        5710 non-null   float32\n",
      " 406  zz0358                        5710 non-null   float32\n",
      " 407  zz0359                        5710 non-null   float32\n",
      " 408  zz0360                        5710 non-null   float32\n",
      " 409  zz0361                        5710 non-null   float32\n",
      " 410  zz0362                        5710 non-null   float32\n",
      " 411  zz0363                        5710 non-null   float32\n",
      " 412  zz0364                        5710 non-null   float32\n",
      " 413  zz0365                        5710 non-null   float32\n",
      " 414  zz0366                        5710 non-null   float32\n",
      " 415  zz0367                        5710 non-null   float32\n",
      " 416  zz0368                        5710 non-null   float32\n",
      " 417  zz0369                        5710 non-null   float32\n",
      " 418  zz0370                        5710 non-null   float32\n",
      " 419  zz0371                        5710 non-null   float32\n",
      " 420  zz0372                        5710 non-null   float32\n",
      " 421  zz0373                        5710 non-null   float32\n",
      " 422  zz0374                        5710 non-null   float32\n",
      " 423  zz0375                        5710 non-null   float32\n",
      " 424  zz0376                        5710 non-null   float32\n",
      " 425  zz0377                        5710 non-null   float32\n",
      " 426  zz0378                        5710 non-null   float32\n",
      " 427  zz0379                        5710 non-null   float32\n",
      " 428  zz0380                        5710 non-null   float32\n",
      " 429  zz0381                        5710 non-null   float32\n",
      " 430  zz0382                        5710 non-null   float32\n",
      " 431  zz0383                        5710 non-null   float32\n",
      "dtypes: float32(426), int16(4), int32(1), int8(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "cols += em_cols\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b13fb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 229 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[cols].to_parquet(\"output/tra.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
