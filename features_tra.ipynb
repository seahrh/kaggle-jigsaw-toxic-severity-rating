{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b888a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import rankdata\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import textstat\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8f39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', dtfy_model_max_length=512, dtfy_batch_size=256, dtfy_models={'dto_': 'pretrained/unitaryai/detoxify/toxic_original-c1212f89.ckpt', 'dtu_': 'pretrained/unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt', 'dtm_': 'pretrained/unitaryai/detoxify/multilingual_debiased-0b549669.ckpt'}, dtfy_configs={'dto_': 'pretrained/bert-base-uncased', 'dtu_': 'pretrained/roberta-base', 'dtm_': 'pretrained/xlm-roberta-base'}, tweeteval_model_max_length=512, tweeteval_batch_size=64, tweeteval_models={'te_roberta_off': 'pretrained/cardiffnlp/twitter-roberta-base-offensive', 'te_roberta_emo_anger': 'pretrained/cardiffnlp/twitter-roberta-base-emotion', 'te_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-roberta-base-sentiment', 'te_roberta_iro': 'pretrained/cardiffnlp/twitter-roberta-base-irony', 'te_xlm_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-xlm-roberta-base-sentiment'}, tweeteval_label_index={'te_roberta_off': 1, 'te_roberta_emo_anger': 0, 'te_roberta_snt_neg': 0, 'te_roberta_iro': 1, 'te_xlm_roberta_snt_neg': 0}, hatebert_model_max_length=512, hatebert_batch_size=128, hatebert_models={'hb_bert_off': 'pretrained/hatebert/bert-offenseval', 'hb_bert_abu': 'pretrained/hatebert/bert-abuseval', 'hb_hatebert_off': 'pretrained/hatebert/hatebert-offenseval', 'hb_hatebert_abu': 'pretrained/hatebert/hatebert-abuseval'}, em_max_seq_length=128, em_batch_size=1000, em_models={'paraphrase-MiniLM-L6-v2': 'pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2'})\n",
      "device=0, NVIDIA GeForce GTX 1060 6GB\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    dtfy_model_max_length: int = 512\n",
    "    dtfy_batch_size: int = 256\n",
    "    dtfy_models: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_original-c1212f89.ckpt\",\n",
    "        \"dtu_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt\",\n",
    "        \"dtm_\": f\"{pretrained_dir}unitaryai/detoxify/multilingual_debiased-0b549669.ckpt\"\n",
    "    }\n",
    "    dtfy_configs: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}bert-base-uncased\",\n",
    "        \"dtu_\": f\"{pretrained_dir}roberta-base\",\n",
    "        \"dtm_\": f\"{pretrained_dir}xlm-roberta-base\"\n",
    "    }\n",
    "    tweeteval_model_max_length: int = 512\n",
    "    tweeteval_batch_size: int = 64\n",
    "    tweeteval_models: Dict[str, str] = {\n",
    "        \"te_roberta_off\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-offensive\",\n",
    "        \"te_roberta_emo_anger\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        \"te_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        \"te_roberta_iro\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-irony\",\n",
    "        \"te_xlm_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    }\n",
    "    tweeteval_label_index: Dict[str, int] = {\n",
    "        \"te_roberta_off\": 1,\n",
    "        \"te_roberta_emo_anger\": 0,\n",
    "        \"te_roberta_snt_neg\": 0,\n",
    "        \"te_roberta_iro\": 1,\n",
    "        \"te_xlm_roberta_snt_neg\": 0,\n",
    "    }\n",
    "    hatebert_model_max_length: int = 512\n",
    "    hatebert_batch_size: int = 128\n",
    "    hatebert_models: Dict[str, str] = {\n",
    "        \"hb_bert_off\": f\"{pretrained_dir}hatebert/bert-offenseval\",\n",
    "        \"hb_bert_abu\" : f\"{pretrained_dir}hatebert/bert-abuseval\",\n",
    "        \"hb_hatebert_off\": f\"{pretrained_dir}hatebert/hatebert-offenseval\",\n",
    "        \"hb_hatebert_abu\" : f\"{pretrained_dir}hatebert/hatebert-abuseval\",\n",
    "    }\n",
    "    em_max_seq_length: int = 128\n",
    "    em_batch_size: int = 1000\n",
    "    em_models: Dict[str, str] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "    }\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   5710 non-null   int32  \n",
      " 1   bws     5710 non-null   float32\n",
      " 2   worker  5710 non-null   int8   \n",
      " 3   text    5710 non-null   object \n",
      " 4   text1   5710 non-null   object \n",
      " 5   text2   5710 non-null   object \n",
      "dtypes: float32(1), int32(1), int8(1), object(3)\n",
      "memory usage: 184.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/pre_ruddit.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752d7ac",
   "metadata": {},
   "source": [
    "# Character level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71d6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col = \"length\"\n",
    "df[col] = df[\"text1\"].str.len()\n",
    "df[col] = df[col].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74a87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "char_fns: Dict[str, Callable] = {\n",
    "    \"digit_frac\": digit_frac,\n",
    "    \"letter_frac\": letter_frac,\n",
    "    \"space_frac\": space_frac,\n",
    "    \"punc_frac\": punc_frac,\n",
    "    \"upper_frac\": upper_frac,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39102.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 37615.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 38556.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punc_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 35456.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39109.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in char_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d4202",
   "metadata": {},
   "source": [
    "# Textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def syllables_per_word(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"lexicon_count\"] + 1)\n",
    "\n",
    "\n",
    "def syllables_per_sent(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def words_per_sent(row) -> float:\n",
    "    return row[\"lexicon_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[\"text1\"])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[\"text1\"])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[\"text1\"])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[\"text1\"])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[\"text1\"])\n",
    "\n",
    "\n",
    "textstat_fns: Dict[str, Callable] = {\n",
    "    \"syllables_per_word\": syllables_per_word,\n",
    "    \"syllables_per_sent\": syllables_per_sent,\n",
    "    \"words_per_sent\": words_per_sent,\n",
    "    \"flesch_reading_ease\": flesch_reading_ease,\n",
    "    \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
    "    \"gunning_fog\": gunning_fog,\n",
    "    \"smog_index\": smog_index,\n",
    "    \"automated_readability_index\": automated_readability_index,\n",
    "    \"coleman_liau_index\": coleman_liau_index,\n",
    "    \"linsear_write_formula\": linsear_write_formula,\n",
    "    \"dale_chall_readability_score\": dale_chall_readability_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d91172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 7886.19it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"syllable_count\"\n",
    "df[col] = df.progress_apply(syllable_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc45e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 65567.04it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"lexicon_count\"\n",
    "df[col] = df.progress_apply(lexicon_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 37439.02it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"sentence_count\"\n",
    "df[col] = df.progress_apply(sentence_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 88439.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 89440.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 86514.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_reading_ease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12159.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_kincaid_grade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12638.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunning_fog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10196.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smog_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 15861.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automated_readability_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 27317.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coleman_liau_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 23891.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linsear_write_formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12021.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dale_chall_readability_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10437.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in textstat_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285247d",
   "metadata": {},
   "source": [
    "# TweetEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:11<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9025, 0.0975],\n",
      "        [0.5804, 0.4196],\n",
      "        [0.6679, 0.3321],\n",
      "        [0.8045, 0.1955],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.8272, 0.1728],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.7598, 0.2402],\n",
      "        [0.9035, 0.0965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:06<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_emo_anger torch.Size([5710, 4])\n",
      "logits[:10]=tensor([[0.0376, 0.0565, 0.8628, 0.0431],\n",
      "        [0.1369, 0.1012, 0.2558, 0.5061],\n",
      "        [0.8166, 0.0105, 0.0391, 0.1338],\n",
      "        [0.9419, 0.0041, 0.0231, 0.0308],\n",
      "        [0.6684, 0.0184, 0.1338, 0.1794],\n",
      "        [0.8703, 0.0090, 0.0602, 0.0605],\n",
      "        [0.8556, 0.0071, 0.0948, 0.0425],\n",
      "        [0.8475, 0.0155, 0.0260, 0.1111],\n",
      "        [0.8054, 0.0086, 0.0704, 0.1156],\n",
      "        [0.1417, 0.3192, 0.3703, 0.1687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.0407, 0.7561, 0.2032],\n",
      "        [0.4268, 0.5488, 0.0244],\n",
      "        [0.7662, 0.2259, 0.0080],\n",
      "        [0.6066, 0.3729, 0.0206],\n",
      "        [0.5111, 0.4282, 0.0607],\n",
      "        [0.5525, 0.4095, 0.0379],\n",
      "        [0.3226, 0.6394, 0.0380],\n",
      "        [0.7787, 0.2147, 0.0066],\n",
      "        [0.7998, 0.1863, 0.0139],\n",
      "        [0.1055, 0.6091, 0.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_iro torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.7999, 0.2001],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.3392, 0.6608],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.8902, 0.1098],\n",
      "        [0.6376, 0.3624],\n",
      "        [0.7453, 0.2547],\n",
      "        [0.0874, 0.9126],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.6555, 0.3445]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:04<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_xlm_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.1049, 0.7652, 0.1299],\n",
      "        [0.1865, 0.7562, 0.0573],\n",
      "        [0.4178, 0.4738, 0.1084],\n",
      "        [0.7074, 0.2630, 0.0296],\n",
      "        [0.7878, 0.1841, 0.0281],\n",
      "        [0.5432, 0.4069, 0.0500],\n",
      "        [0.5321, 0.4271, 0.0408],\n",
      "        [0.5248, 0.4357, 0.0396],\n",
      "        [0.9013, 0.0858, 0.0129],\n",
      "        [0.3988, 0.4830, 0.1182]])\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df[\"text2\"])\n",
    "for col, model_dir in conf.tweeteval_models.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir, \n",
    "        model_max_length=conf.tweeteval_model_max_length\n",
    "    )\n",
    "    #print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")\n",
    "    x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "    batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.tweeteval_batch_size, shuffle=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,conf.tweeteval_label_index[col]]\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "    del tokenizer, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e694b",
   "metadata": {},
   "source": [
    "# HateBert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/hatebert/hatebert-offenseval', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# all Hatebert models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.hatebert_models[\"hb_hatebert_off\"], \n",
    "    model_max_length=conf.hatebert_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e71aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baba8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9598, 0.0402],\n",
      "        [0.7718, 0.2282],\n",
      "        [0.7567, 0.2433],\n",
      "        [0.9064, 0.0936],\n",
      "        [0.8318, 0.1682],\n",
      "        [0.7811, 0.2189],\n",
      "        [0.5952, 0.4048],\n",
      "        [0.8502, 0.1498],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9258, 0.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:10<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9910, 0.0090],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9631, 0.0369],\n",
      "        [0.9714, 0.0286],\n",
      "        [0.8686, 0.1314],\n",
      "        [0.9001, 0.0999],\n",
      "        [0.8544, 0.1456],\n",
      "        [0.8708, 0.1292],\n",
      "        [0.9881, 0.0119]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:11<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9377, 0.0623],\n",
      "        [0.5526, 0.4474],\n",
      "        [0.7553, 0.2447],\n",
      "        [0.7828, 0.2172],\n",
      "        [0.8787, 0.1213],\n",
      "        [0.9267, 0.0733],\n",
      "        [0.8304, 0.1696],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8965, 0.1035]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:09<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9846, 0.0154],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9699, 0.0301],\n",
      "        [0.9698, 0.0302],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9733, 0.0267],\n",
      "        [0.9407, 0.0593],\n",
      "        [0.9795, 0.0205]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.hatebert_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.hatebert_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,1]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f069f2",
   "metadata": {},
   "source": [
    "# Detoxify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a45a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 3/3 [04:01<00:00, 80.48s/it]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "dtfy_fs = []\n",
    "for prefix, checkpoint in tqdm(conf.dtfy_models.items()):\n",
    "    res = mylib.detoxify_labels(\n",
    "        sentences,\n",
    "        checkpoint=checkpoint,\n",
    "        config_dir=conf.dtfy_configs[prefix],\n",
    "        model_max_length=conf.dtfy_model_max_length,\n",
    "        device=conf.device,\n",
    "        batch_size=conf.dtfy_batch_size\n",
    "    )\n",
    "    for k, v in res.items():\n",
    "        col = prefix + k\n",
    "        df[col] = v\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        dtfy_fs.append(col)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6312beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dto_toxicity', 'dto_severe_toxicity', 'dto_obscene', 'dto_threat', 'dto_insult', 'dto_identity_attack', 'dtu_toxicity', 'dtu_severe_toxicity', 'dtu_obscene', 'dtu_identity_attack', 'dtu_insult', 'dtu_threat', 'dtu_sexual_explicit', 'dtm_toxicity', 'dtm_severe_toxicity', 'dtm_obscene', 'dtm_identity_attack', 'dtm_insult', 'dtm_threat', 'dtm_sexual_explicit']\n"
     ]
    }
   ],
   "source": [
    "print(dtfy_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e5b5d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d1f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|SentenceTransformer.py:60] 2022-01-30 11:13:09,835 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-01-30 11:13:09,835 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-01-30 11:13:09,835 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-01-30 11:13:09,835 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6510adf4e110434a8eed6a67c9cdedfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(5710, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(conf.em_models[\"paraphrase-MiniLM-L6-v2\"], device=conf.device)\n",
    "model.max_seq_length = conf.em_max_seq_length\n",
    "em = model.encode(sentences=sentences, batch_size=conf.em_batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73bdd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 245 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "em_size = em.shape[1]\n",
    "em_cols = [f\"zz{i:04d}\" for i in range(em_size)]\n",
    "df[em_cols] = em\n",
    "df[em_cols] = df[em_cols].astype(np.float32)\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335287",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15b1d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bws</th>\n",
       "      <th>worker</th>\n",
       "      <th>length</th>\n",
       "      <th>digit_frac</th>\n",
       "      <th>letter_frac</th>\n",
       "      <th>space_frac</th>\n",
       "      <th>punc_frac</th>\n",
       "      <th>upper_frac</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>syllables_per_sent</th>\n",
       "      <th>words_per_sent</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>dto_toxicity</th>\n",
       "      <th>dto_severe_toxicity</th>\n",
       "      <th>dto_obscene</th>\n",
       "      <th>dto_threat</th>\n",
       "      <th>dto_insult</th>\n",
       "      <th>dto_identity_attack</th>\n",
       "      <th>dtu_toxicity</th>\n",
       "      <th>dtu_severe_toxicity</th>\n",
       "      <th>dtu_obscene</th>\n",
       "      <th>dtu_identity_attack</th>\n",
       "      <th>dtu_insult</th>\n",
       "      <th>dtu_threat</th>\n",
       "      <th>dtu_sexual_explicit</th>\n",
       "      <th>dtm_toxicity</th>\n",
       "      <th>dtm_severe_toxicity</th>\n",
       "      <th>dtm_obscene</th>\n",
       "      <th>dtm_identity_attack</th>\n",
       "      <th>dtm_insult</th>\n",
       "      <th>dtm_threat</th>\n",
       "      <th>dtm_sexual_explicit</th>\n",
       "      <th>hb_bert_off</th>\n",
       "      <th>hb_bert_abu</th>\n",
       "      <th>hb_hatebert_off</th>\n",
       "      <th>hb_hatebert_abu</th>\n",
       "      <th>te_roberta_off</th>\n",
       "      <th>te_roberta_emo_anger</th>\n",
       "      <th>te_roberta_snt_neg</th>\n",
       "      <th>te_roberta_iro</th>\n",
       "      <th>te_xlm_roberta_snt_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5.710000e+03</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.915587</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.787317</td>\n",
       "      <td>0.173301</td>\n",
       "      <td>0.035892</td>\n",
       "      <td>0.031720</td>\n",
       "      <td>1.307030</td>\n",
       "      <td>13.239110</td>\n",
       "      <td>9.545128</td>\n",
       "      <td>74.979500</td>\n",
       "      <td>6.491471</td>\n",
       "      <td>8.701601</td>\n",
       "      <td>3.175884</td>\n",
       "      <td>7.604343</td>\n",
       "      <td>7.027691</td>\n",
       "      <td>8.015270</td>\n",
       "      <td>8.399787</td>\n",
       "      <td>0.177269</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>0.116036</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>4.827425e-03</td>\n",
       "      <td>0.116517</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>0.082358</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.041887</td>\n",
       "      <td>0.204815</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.109037</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.083703</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>0.334841</td>\n",
       "      <td>0.166219</td>\n",
       "      <td>0.328586</td>\n",
       "      <td>0.141803</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.503257</td>\n",
       "      <td>0.504242</td>\n",
       "      <td>0.303546</td>\n",
       "      <td>0.579387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1648.47935</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.109023</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.048117</td>\n",
       "      <td>0.199335</td>\n",
       "      <td>7.826234</td>\n",
       "      <td>5.379773</td>\n",
       "      <td>19.854204</td>\n",
       "      <td>4.237190</td>\n",
       "      <td>4.464397</td>\n",
       "      <td>4.698273</td>\n",
       "      <td>5.243802</td>\n",
       "      <td>3.855352</td>\n",
       "      <td>5.516964</td>\n",
       "      <td>2.254551</td>\n",
       "      <td>0.327141</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.285578</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.172480</td>\n",
       "      <td>0.062570</td>\n",
       "      <td>0.344887</td>\n",
       "      <td>2.284678e-02</td>\n",
       "      <td>0.290073</td>\n",
       "      <td>0.074058</td>\n",
       "      <td>0.209154</td>\n",
       "      <td>0.068646</td>\n",
       "      <td>0.154251</td>\n",
       "      <td>0.348054</td>\n",
       "      <td>0.028899</td>\n",
       "      <td>0.278013</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0.215425</td>\n",
       "      <td>0.078792</td>\n",
       "      <td>0.161162</td>\n",
       "      <td>0.333870</td>\n",
       "      <td>0.279103</td>\n",
       "      <td>0.284754</td>\n",
       "      <td>0.219147</td>\n",
       "      <td>0.250738</td>\n",
       "      <td>0.358158</td>\n",
       "      <td>0.318861</td>\n",
       "      <td>0.271424</td>\n",
       "      <td>0.299713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-48.980000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.800000</td>\n",
       "      <td>-10.160000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.469297e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.009455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>58.09000</td>\n",
       "      <td>-0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670577</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>19.439399</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.727200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1.082210e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>0.019474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>286.45000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729800</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.441999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.689000</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1.201370e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.036119</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.073817</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>0.054882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>571.90000</td>\n",
       "      <td>-0.426000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.270000</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.270248e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.028689</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.049691</td>\n",
       "      <td>0.015893</td>\n",
       "      <td>0.091589</td>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.032618</td>\n",
       "      <td>0.046842</td>\n",
       "      <td>0.114343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1142.80000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>60.139999</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>7.010000</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>1.407515e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.077647</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.123787</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>0.141338</td>\n",
       "      <td>0.070889</td>\n",
       "      <td>0.246842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>1713.70000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.164983</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>66.407003</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.297000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>1.642735e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.071853</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.160974</td>\n",
       "      <td>0.173743</td>\n",
       "      <td>0.285689</td>\n",
       "      <td>0.098981</td>\n",
       "      <td>0.390838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>2284.60000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784656</td>\n",
       "      <td>0.169903</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>1.255814</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>7.612000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>2.273925e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.109913</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.156008</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.204146</td>\n",
       "      <td>0.315728</td>\n",
       "      <td>0.410188</td>\n",
       "      <td>0.140475</td>\n",
       "      <td>0.520841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791066</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>75.910004</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>8.320000</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>4.181050e-06</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.173715</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>0.213557</td>\n",
       "      <td>0.046689</td>\n",
       "      <td>0.259306</td>\n",
       "      <td>0.513784</td>\n",
       "      <td>0.530066</td>\n",
       "      <td>0.190954</td>\n",
       "      <td>0.647479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>3426.40000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>1.346154</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.620003</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>9.234000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>1.011796e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.283199</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>0.309697</td>\n",
       "      <td>0.066254</td>\n",
       "      <td>0.336382</td>\n",
       "      <td>0.706412</td>\n",
       "      <td>0.647328</td>\n",
       "      <td>0.275314</td>\n",
       "      <td>0.753702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3997.30000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.397827</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>85.238000</td>\n",
       "      <td>8.030000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.076205</td>\n",
       "      <td>3.135838e-05</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.090152</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.470841</td>\n",
       "      <td>0.096444</td>\n",
       "      <td>0.439921</td>\n",
       "      <td>0.102355</td>\n",
       "      <td>0.442974</td>\n",
       "      <td>0.835034</td>\n",
       "      <td>0.752938</td>\n",
       "      <td>0.394859</td>\n",
       "      <td>0.830389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4568.20000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811607</td>\n",
       "      <td>0.189204</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.040029</td>\n",
       "      <td>1.460359</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>90.769997</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>11.720000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>9.940000</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>0.303395</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.439856</td>\n",
       "      <td>1.696009e-04</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.042739</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.506172</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.737019</td>\n",
       "      <td>0.247729</td>\n",
       "      <td>0.612586</td>\n",
       "      <td>0.183996</td>\n",
       "      <td>0.583173</td>\n",
       "      <td>0.910471</td>\n",
       "      <td>0.843231</td>\n",
       "      <td>0.561646</td>\n",
       "      <td>0.884877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5139.10000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>99.230003</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>14.060000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>14.516667</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>0.888687</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.695707</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.165501</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.936631</td>\n",
       "      <td>5.042182e-03</td>\n",
       "      <td>0.768034</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.299006</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.045684</td>\n",
       "      <td>0.930868</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.706515</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.303327</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>0.088817</td>\n",
       "      <td>0.929624</td>\n",
       "      <td>0.718718</td>\n",
       "      <td>0.822292</td>\n",
       "      <td>0.443144</td>\n",
       "      <td>0.784419</td>\n",
       "      <td>0.955121</td>\n",
       "      <td>0.917976</td>\n",
       "      <td>0.765539</td>\n",
       "      <td>0.921445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5424.55000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576.100000</td>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>27.333334</td>\n",
       "      <td>19.333334</td>\n",
       "      <td>105.660004</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>16.160000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>16.155001</td>\n",
       "      <td>13.031000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>0.984879</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>0.949036</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.474006</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.979690</td>\n",
       "      <td>2.323853e-02</td>\n",
       "      <td>0.936220</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.664790</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.310832</td>\n",
       "      <td>0.975692</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.914408</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.694838</td>\n",
       "      <td>0.037409</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>0.960857</td>\n",
       "      <td>0.911460</td>\n",
       "      <td>0.910589</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.855381</td>\n",
       "      <td>0.968415</td>\n",
       "      <td>0.951282</td>\n",
       "      <td>0.871590</td>\n",
       "      <td>0.938671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5652.91000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745.910000</td>\n",
       "      <td>0.060597</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.221166</td>\n",
       "      <td>0.130309</td>\n",
       "      <td>0.156738</td>\n",
       "      <td>1.839400</td>\n",
       "      <td>37.651668</td>\n",
       "      <td>25.666666</td>\n",
       "      <td>116.150002</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>22.609299</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>23.191001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>26.727500</td>\n",
       "      <td>14.610000</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.276383</td>\n",
       "      <td>0.984813</td>\n",
       "      <td>0.318713</td>\n",
       "      <td>0.885210</td>\n",
       "      <td>0.267540</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.125103e-01</td>\n",
       "      <td>0.974933</td>\n",
       "      <td>0.457575</td>\n",
       "      <td>0.947763</td>\n",
       "      <td>0.368233</td>\n",
       "      <td>0.876286</td>\n",
       "      <td>0.994125</td>\n",
       "      <td>0.129190</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>0.431208</td>\n",
       "      <td>0.968596</td>\n",
       "      <td>0.472689</td>\n",
       "      <td>0.908064</td>\n",
       "      <td>0.972352</td>\n",
       "      <td>0.967271</td>\n",
       "      <td>0.957644</td>\n",
       "      <td>0.947910</td>\n",
       "      <td>0.912107</td>\n",
       "      <td>0.979446</td>\n",
       "      <td>0.973460</td>\n",
       "      <td>0.957325</td>\n",
       "      <td>0.955707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>118.680000</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>55.520000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.570000</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.764529</td>\n",
       "      <td>0.994431</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>4.605981e-01</td>\n",
       "      <td>0.989358</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>0.981085</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.993893</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>0.978722</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.985453</td>\n",
       "      <td>0.982451</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.965045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label          bws  worker       length   digit_frac  letter_frac  \\\n",
       "count  5710.00000  5710.000000  5710.0  5710.000000  5710.000000  5710.000000   \n",
       "mean   2855.50000    -0.027706     0.0   196.915587     0.003490     0.787317   \n",
       "std    1648.47935     0.334195     0.0   171.109023     0.012540     0.034357   \n",
       "min       1.00000    -0.889000     0.0    14.000000     0.000000     0.298246   \n",
       "1%       58.09000    -0.667000     0.0    24.000000     0.000000     0.670577   \n",
       "5%      286.45000    -0.521000     0.0    33.000000     0.000000     0.729800   \n",
       "10%     571.90000    -0.426000     0.0    42.000000     0.000000     0.747899   \n",
       "20%    1142.80000    -0.312000     0.0    61.000000     0.000000     0.767677   \n",
       "30%    1713.70000    -0.213000     0.0    82.000000     0.000000     0.777778   \n",
       "40%    2284.60000    -0.146000     0.0   106.000000     0.000000     0.784656   \n",
       "50%    2855.50000    -0.062000     0.0   137.000000     0.000000     0.791066   \n",
       "60%    3426.40000     0.021000     0.0   176.000000     0.000000     0.797235   \n",
       "70%    3997.30000     0.104000     0.0   232.000000     0.000000     0.804124   \n",
       "80%    4568.20000     0.229000     0.0   315.000000     0.000000     0.811607   \n",
       "90%    5139.10000     0.458000     0.0   454.000000     0.009713     0.822222   \n",
       "95%    5424.55000     0.625000     0.0   576.100000     0.022580     0.830986   \n",
       "99%    5652.91000     0.833000     0.0   745.910000     0.060597     0.854545   \n",
       "max    5710.00000     0.979000     0.0   914.000000     0.235294     0.897436   \n",
       "\n",
       "        space_frac    punc_frac   upper_frac  syllables_per_word  \\\n",
       "count  5710.000000  5710.000000  5710.000000         5710.000000   \n",
       "mean      0.173301     0.035892     0.031720            1.307030   \n",
       "std       0.020640     0.025530     0.048117            0.199335   \n",
       "min       0.040541     0.000000     0.000000            0.800000   \n",
       "1%        0.111300     0.000000     0.000000            0.857143   \n",
       "5%        0.137931     0.008264     0.007047            1.000000   \n",
       "10%       0.148148     0.013889     0.009524            1.062500   \n",
       "20%       0.158416     0.019417     0.012903            1.142857   \n",
       "30%       0.164983     0.023392     0.015850            1.206897   \n",
       "40%       0.169903     0.027027     0.018968            1.255814   \n",
       "50%       0.174419     0.030769     0.022351            1.304348   \n",
       "60%       0.178862     0.035088     0.026786            1.346154   \n",
       "70%       0.183432     0.040066     0.032258            1.397827   \n",
       "80%       0.189204     0.047619     0.040029            1.460359   \n",
       "90%       0.197605     0.062959     0.056467            1.555556   \n",
       "95%       0.204545     0.080808     0.074895            1.636364   \n",
       "99%       0.221166     0.130309     0.156738            1.839400   \n",
       "max       0.250000     0.526316     0.857143            2.500000   \n",
       "\n",
       "       syllables_per_sent  words_per_sent  flesch_reading_ease  \\\n",
       "count         5710.000000     5710.000000          5710.000000   \n",
       "mean            13.239110        9.545128            74.979500   \n",
       "std              7.826234        5.379773            19.854204   \n",
       "min              2.000000        1.500000           -48.980000   \n",
       "1%               2.666667        2.500000            19.439399   \n",
       "5%               4.000000        3.000000            41.441999   \n",
       "10%              5.000000        3.500000            50.500000   \n",
       "20%              6.500000        5.000000            60.139999   \n",
       "30%              8.190000        6.000000            66.407003   \n",
       "40%             10.000000        7.333333            71.650002   \n",
       "50%             11.800000        8.500000            75.910004   \n",
       "60%             13.800000       10.000000            80.620003   \n",
       "70%             16.000000       11.500000            85.238000   \n",
       "80%             19.000000       13.500000            90.769997   \n",
       "90%             23.500000       16.500000            99.230003   \n",
       "95%             27.333334       19.333334           105.660004   \n",
       "99%             37.651668       25.666666           116.150002   \n",
       "max             96.000000       63.500000           118.680000   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog   smog_index  \\\n",
       "count           5710.000000  5710.000000  5710.000000   \n",
       "mean               6.491471     8.701601     3.175884   \n",
       "std                4.237190     4.464397     4.698273   \n",
       "min               -2.500000     1.200000     0.000000   \n",
       "1%                -1.500000     1.727200     0.000000   \n",
       "5%                 0.500000     2.400000     0.000000   \n",
       "10%                1.700000     3.200000     0.000000   \n",
       "20%                3.100000     4.800000     0.000000   \n",
       "30%                4.200000     6.140000     0.000000   \n",
       "40%                5.200000     7.612000     0.000000   \n",
       "50%                6.200000     8.300000     0.000000   \n",
       "60%                7.100000     9.234000     0.000000   \n",
       "70%                8.030000    10.400000     6.400000   \n",
       "80%                9.500000    11.720000     8.800000   \n",
       "90%               11.500000    14.060000    10.700000   \n",
       "95%               13.400000    16.160000    11.900000   \n",
       "99%               19.299999    22.609299    14.200000   \n",
       "max               51.599998    55.520000    18.900000   \n",
       "\n",
       "       automated_readability_index  coleman_liau_index  linsear_write_formula  \\\n",
       "count                  5710.000000         5710.000000            5710.000000   \n",
       "mean                      7.604343            7.027691               8.015270   \n",
       "std                       5.243802            3.855352               5.516964   \n",
       "min                      -6.800000          -10.160000               0.500000   \n",
       "1%                       -2.800000           -2.550000               1.250000   \n",
       "5%                        0.400000            0.760000               2.000000   \n",
       "10%                       1.700000            2.230000               2.500000   \n",
       "20%                       3.600000            4.140000               3.750000   \n",
       "30%                       5.000000            5.297000               4.666667   \n",
       "40%                       6.100000            6.250000               5.666667   \n",
       "50%                       7.200000            7.090000               6.750000   \n",
       "60%                       8.300000            7.920000               7.750000   \n",
       "70%                       9.500000            8.870000               9.000000   \n",
       "80%                      11.100000            9.940000              11.833333   \n",
       "90%                      13.500000           11.550000              14.516667   \n",
       "95%                      16.155001           13.031000              17.500000   \n",
       "99%                      23.191001           16.860001              26.727500   \n",
       "max                      64.900002           40.599998              66.000000   \n",
       "\n",
       "       dale_chall_readability_score  dto_toxicity  dto_severe_toxicity  \\\n",
       "count                   5710.000000   5710.000000          5710.000000   \n",
       "mean                       8.399787      0.177269             0.012918   \n",
       "std                        2.254551      0.327141             0.052013   \n",
       "min                        0.200000      0.000508             0.000080   \n",
       "1%                         0.350000      0.000554             0.000087   \n",
       "5%                         5.689000      0.000613             0.000093   \n",
       "10%                        6.270000      0.000663             0.000097   \n",
       "20%                        7.010000      0.000786             0.000103   \n",
       "30%                        7.490000      0.000983             0.000108   \n",
       "40%                        7.920000      0.001464             0.000114   \n",
       "50%                        8.320000      0.003627             0.000120   \n",
       "60%                        8.700000      0.013429             0.000131   \n",
       "70%                        9.200000      0.052994             0.000216   \n",
       "80%                        9.920000      0.303395             0.001102   \n",
       "90%                       10.810000      0.888687             0.017391   \n",
       "95%                       11.910000      0.984879             0.085279   \n",
       "99%                       14.610000      0.997167             0.276383   \n",
       "max                       23.570000      0.999072             0.764529   \n",
       "\n",
       "       dto_obscene   dto_threat   dto_insult  dto_identity_attack  \\\n",
       "count  5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean      0.116036     0.008211     0.058580             0.011030   \n",
       "std       0.285578     0.055493     0.172480             0.062570   \n",
       "min       0.000141     0.000086     0.000164             0.000121   \n",
       "1%        0.000158     0.000096     0.000171             0.000134   \n",
       "5%        0.000165     0.000104     0.000175             0.000138   \n",
       "10%       0.000170     0.000108     0.000177             0.000140   \n",
       "20%       0.000176     0.000115     0.000181             0.000144   \n",
       "30%       0.000182     0.000121     0.000187             0.000150   \n",
       "40%       0.000194     0.000127     0.000204             0.000163   \n",
       "50%       0.000270     0.000137     0.000284             0.000206   \n",
       "60%       0.000546     0.000201     0.000626             0.000345   \n",
       "70%       0.001575     0.000420     0.001910             0.000842   \n",
       "80%       0.016387     0.001129     0.014511             0.002530   \n",
       "90%       0.695707     0.003109     0.165501             0.009528   \n",
       "95%       0.949036     0.008912     0.474006             0.031146   \n",
       "99%       0.984813     0.318713     0.885210             0.267540   \n",
       "max       0.994431     0.823060     0.980776             0.894015   \n",
       "\n",
       "       dtu_toxicity  dtu_severe_toxicity  dtu_obscene  dtu_identity_attack  \\\n",
       "count   5710.000000         5.710000e+03  5710.000000          5710.000000   \n",
       "mean       0.197880         4.827425e-03     0.116517             0.015205   \n",
       "std        0.344887         2.284678e-02     0.290073             0.074058   \n",
       "min        0.000286         9.469297e-07     0.000017             0.000052   \n",
       "1%         0.000360         1.082210e-06     0.000021             0.000063   \n",
       "5%         0.000410         1.201370e-06     0.000024             0.000070   \n",
       "10%        0.000454         1.270248e-06     0.000026             0.000076   \n",
       "20%        0.000573         1.407515e-06     0.000031             0.000089   \n",
       "30%        0.000852         1.642735e-06     0.000041             0.000113   \n",
       "40%        0.001596         2.273925e-06     0.000067             0.000175   \n",
       "50%        0.003831         4.181050e-06     0.000129             0.000362   \n",
       "60%        0.014004         1.011796e-05     0.000302             0.000838   \n",
       "70%        0.076205         3.135838e-05     0.000947             0.002069   \n",
       "80%        0.439856         1.696009e-04     0.006090             0.005074   \n",
       "90%        0.936631         5.042182e-03     0.768034             0.015747   \n",
       "95%        0.979690         2.323853e-02     0.936220             0.042194   \n",
       "99%        0.994464         1.125103e-01     0.974933             0.457575   \n",
       "max        0.998344         4.605981e-01     0.989358             0.984674   \n",
       "\n",
       "        dtu_insult   dtu_threat  dtu_sexual_explicit  dtm_toxicity  \\\n",
       "count  5710.000000  5710.000000          5710.000000   5710.000000   \n",
       "mean      0.082358     0.010820             0.041887      0.204815   \n",
       "std       0.209154     0.068646             0.154251      0.348054   \n",
       "min       0.000061     0.000012             0.000009      0.000186   \n",
       "1%        0.000092     0.000015             0.000011      0.000278   \n",
       "5%        0.000103     0.000017             0.000012      0.000351   \n",
       "10%       0.000112     0.000019             0.000013      0.000412   \n",
       "20%       0.000133     0.000023             0.000016      0.000570   \n",
       "30%       0.000178     0.000030             0.000021      0.000850   \n",
       "40%       0.000311     0.000048             0.000033      0.001615   \n",
       "50%       0.000666     0.000087             0.000069      0.004143   \n",
       "60%       0.001606     0.000173             0.000178      0.015840   \n",
       "70%       0.005542     0.000397             0.000548      0.090152   \n",
       "80%       0.042739     0.000986             0.003667      0.506172   \n",
       "90%       0.299006     0.002834             0.045684      0.930868   \n",
       "95%       0.664790     0.014624             0.310832      0.975692   \n",
       "99%       0.947763     0.368233             0.876286      0.994125   \n",
       "max       0.993023     0.925068             0.981085      0.999047   \n",
       "\n",
       "       dtm_severe_toxicity  dtm_obscene  dtm_identity_attack   dtm_insult  \\\n",
       "count          5710.000000  5710.000000          5710.000000  5710.000000   \n",
       "mean              0.006113     0.109037             0.013888     0.083703   \n",
       "std               0.028899     0.278013             0.076619     0.215425   \n",
       "min               0.000009     0.000063             0.000045     0.000095   \n",
       "1%                0.000013     0.000094             0.000066     0.000149   \n",
       "5%                0.000016     0.000114             0.000078     0.000178   \n",
       "10%               0.000018     0.000129             0.000085     0.000199   \n",
       "20%               0.000022     0.000158             0.000099     0.000246   \n",
       "30%               0.000027     0.000199             0.000117     0.000324   \n",
       "40%               0.000033     0.000270             0.000151     0.000510   \n",
       "50%               0.000047     0.000430             0.000244     0.001032   \n",
       "60%               0.000085     0.000755             0.000525     0.002430   \n",
       "70%               0.000209     0.001608             0.001276     0.007841   \n",
       "80%               0.000867     0.005910             0.003361     0.043004   \n",
       "90%               0.008763     0.706515             0.011492     0.303327   \n",
       "95%               0.031727     0.914408             0.032573     0.694838   \n",
       "99%               0.129190     0.978410             0.431208     0.968596   \n",
       "max               0.672039     0.993893             0.965869     0.994790   \n",
       "\n",
       "        dtm_threat  dtm_sexual_explicit  hb_bert_off  hb_bert_abu  \\\n",
       "count  5710.000000          5710.000000  5710.000000  5710.000000   \n",
       "mean      0.014809             0.046989     0.334841     0.166219   \n",
       "std       0.078792             0.161162     0.333870     0.279103   \n",
       "min       0.000014             0.000012     0.008981     0.002733   \n",
       "1%        0.000021             0.000017     0.013535     0.003709   \n",
       "5%        0.000027             0.000020     0.020864     0.005157   \n",
       "10%       0.000030             0.000022     0.028689     0.006384   \n",
       "20%       0.000037             0.000026     0.045573     0.009076   \n",
       "30%       0.000045             0.000032     0.071853     0.012562   \n",
       "40%       0.000064             0.000044     0.109913     0.017949   \n",
       "50%       0.000123             0.000090     0.173715     0.027664   \n",
       "60%       0.000311             0.000241     0.283199     0.047053   \n",
       "70%       0.000973             0.000804     0.470841     0.096444   \n",
       "80%       0.003094             0.004985     0.737019     0.247729   \n",
       "90%       0.011159             0.088817     0.929624     0.718718   \n",
       "95%       0.037409             0.348995     0.960857     0.911460   \n",
       "99%       0.472689             0.908064     0.972352     0.967271   \n",
       "max       0.962406             0.982923     0.978722     0.977543   \n",
       "\n",
       "       hb_hatebert_off  hb_hatebert_abu  te_roberta_off  te_roberta_emo_anger  \\\n",
       "count      5710.000000      5710.000000     5710.000000           5710.000000   \n",
       "mean          0.328586         0.141803        0.346535              0.503257   \n",
       "std           0.284754         0.219147        0.250738              0.358158   \n",
       "min           0.006939         0.007050        0.023256              0.004901   \n",
       "1%            0.021296         0.010223        0.050360              0.011169   \n",
       "5%            0.036119         0.013418        0.073817              0.022917   \n",
       "10%           0.049691         0.015893        0.091589              0.038438   \n",
       "20%           0.077647         0.020805        0.123787              0.087268   \n",
       "30%           0.112063         0.026856        0.160974              0.173743   \n",
       "40%           0.156008         0.034969        0.204146              0.315728   \n",
       "50%           0.213557         0.046689        0.259306              0.513784   \n",
       "60%           0.309697         0.066254        0.336382              0.706412   \n",
       "70%           0.439921         0.102355        0.442974              0.835034   \n",
       "80%           0.612586         0.183996        0.583173              0.910471   \n",
       "90%           0.822292         0.443144        0.784419              0.955121   \n",
       "95%           0.910589         0.732377        0.855381              0.968415   \n",
       "99%           0.957644         0.947910        0.912107              0.979446   \n",
       "max           0.979833         0.977078        0.950407              0.985453   \n",
       "\n",
       "       te_roberta_snt_neg  te_roberta_iro  te_xlm_roberta_snt_neg  \n",
       "count         5710.000000     5710.000000             5710.000000  \n",
       "mean             0.504242        0.303546                0.579387  \n",
       "std              0.318861        0.271424                0.299713  \n",
       "min              0.000799        0.014366                0.009455  \n",
       "1%               0.001821        0.022659                0.019474  \n",
       "5%               0.008920        0.034882                0.054882  \n",
       "10%              0.032618        0.046842                0.114343  \n",
       "20%              0.141338        0.070889                0.246842  \n",
       "30%              0.285689        0.098981                0.390838  \n",
       "40%              0.410188        0.140475                0.520841  \n",
       "50%              0.530066        0.190954                0.647479  \n",
       "60%              0.647328        0.275314                0.753702  \n",
       "70%              0.752938        0.394859                0.830389  \n",
       "80%              0.843231        0.561646                0.884877  \n",
       "90%              0.917976        0.765539                0.921445  \n",
       "95%              0.951282        0.871590                0.938671  \n",
       "99%              0.973460        0.957325                0.955707  \n",
       "max              0.982451        0.990079                0.965045  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"label\", \"bws\", \"worker\", \"length\"]\n",
    "cols += list(char_fns.keys())\n",
    "cols += list(textstat_fns.keys())\n",
    "cols += dtfy_fs\n",
    "cols += list(conf.hatebert_models.keys()) \n",
    "cols += list(conf.tweeteval_models.keys()) \n",
    "df[cols].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bddf8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 433 columns):\n",
      " #    Column                        Non-Null Count  Dtype  \n",
      "---   ------                        --------------  -----  \n",
      " 0    label                         5710 non-null   int32  \n",
      " 1    bws                           5710 non-null   float32\n",
      " 2    worker                        5710 non-null   int8   \n",
      " 3    length                        5710 non-null   int16  \n",
      " 4    digit_frac                    5710 non-null   float32\n",
      " 5    letter_frac                   5710 non-null   float32\n",
      " 6    space_frac                    5710 non-null   float32\n",
      " 7    punc_frac                     5710 non-null   float32\n",
      " 8    upper_frac                    5710 non-null   float32\n",
      " 9    syllables_per_word            5710 non-null   float32\n",
      " 10   syllables_per_sent            5710 non-null   float32\n",
      " 11   words_per_sent                5710 non-null   float32\n",
      " 12   flesch_reading_ease           5710 non-null   float32\n",
      " 13   flesch_kincaid_grade          5710 non-null   float32\n",
      " 14   gunning_fog                   5710 non-null   float32\n",
      " 15   smog_index                    5710 non-null   float32\n",
      " 16   automated_readability_index   5710 non-null   float32\n",
      " 17   coleman_liau_index            5710 non-null   float32\n",
      " 18   linsear_write_formula         5710 non-null   float32\n",
      " 19   dale_chall_readability_score  5710 non-null   float32\n",
      " 20   dto_toxicity                  5710 non-null   float32\n",
      " 21   dto_severe_toxicity           5710 non-null   float32\n",
      " 22   dto_obscene                   5710 non-null   float32\n",
      " 23   dto_threat                    5710 non-null   float32\n",
      " 24   dto_insult                    5710 non-null   float32\n",
      " 25   dto_identity_attack           5710 non-null   float32\n",
      " 26   dtu_toxicity                  5710 non-null   float32\n",
      " 27   dtu_severe_toxicity           5710 non-null   float32\n",
      " 28   dtu_obscene                   5710 non-null   float32\n",
      " 29   dtu_identity_attack           5710 non-null   float32\n",
      " 30   dtu_insult                    5710 non-null   float32\n",
      " 31   dtu_threat                    5710 non-null   float32\n",
      " 32   dtu_sexual_explicit           5710 non-null   float32\n",
      " 33   dtm_toxicity                  5710 non-null   float32\n",
      " 34   dtm_severe_toxicity           5710 non-null   float32\n",
      " 35   dtm_obscene                   5710 non-null   float32\n",
      " 36   dtm_identity_attack           5710 non-null   float32\n",
      " 37   dtm_insult                    5710 non-null   float32\n",
      " 38   dtm_threat                    5710 non-null   float32\n",
      " 39   dtm_sexual_explicit           5710 non-null   float32\n",
      " 40   hb_bert_off                   5710 non-null   float32\n",
      " 41   hb_bert_abu                   5710 non-null   float32\n",
      " 42   hb_hatebert_off               5710 non-null   float32\n",
      " 43   hb_hatebert_abu               5710 non-null   float32\n",
      " 44   te_roberta_off                5710 non-null   float32\n",
      " 45   te_roberta_emo_anger          5710 non-null   float32\n",
      " 46   te_roberta_snt_neg            5710 non-null   float32\n",
      " 47   te_roberta_iro                5710 non-null   float32\n",
      " 48   te_xlm_roberta_snt_neg        5710 non-null   float32\n",
      " 49   zz0000                        5710 non-null   float32\n",
      " 50   zz0001                        5710 non-null   float32\n",
      " 51   zz0002                        5710 non-null   float32\n",
      " 52   zz0003                        5710 non-null   float32\n",
      " 53   zz0004                        5710 non-null   float32\n",
      " 54   zz0005                        5710 non-null   float32\n",
      " 55   zz0006                        5710 non-null   float32\n",
      " 56   zz0007                        5710 non-null   float32\n",
      " 57   zz0008                        5710 non-null   float32\n",
      " 58   zz0009                        5710 non-null   float32\n",
      " 59   zz0010                        5710 non-null   float32\n",
      " 60   zz0011                        5710 non-null   float32\n",
      " 61   zz0012                        5710 non-null   float32\n",
      " 62   zz0013                        5710 non-null   float32\n",
      " 63   zz0014                        5710 non-null   float32\n",
      " 64   zz0015                        5710 non-null   float32\n",
      " 65   zz0016                        5710 non-null   float32\n",
      " 66   zz0017                        5710 non-null   float32\n",
      " 67   zz0018                        5710 non-null   float32\n",
      " 68   zz0019                        5710 non-null   float32\n",
      " 69   zz0020                        5710 non-null   float32\n",
      " 70   zz0021                        5710 non-null   float32\n",
      " 71   zz0022                        5710 non-null   float32\n",
      " 72   zz0023                        5710 non-null   float32\n",
      " 73   zz0024                        5710 non-null   float32\n",
      " 74   zz0025                        5710 non-null   float32\n",
      " 75   zz0026                        5710 non-null   float32\n",
      " 76   zz0027                        5710 non-null   float32\n",
      " 77   zz0028                        5710 non-null   float32\n",
      " 78   zz0029                        5710 non-null   float32\n",
      " 79   zz0030                        5710 non-null   float32\n",
      " 80   zz0031                        5710 non-null   float32\n",
      " 81   zz0032                        5710 non-null   float32\n",
      " 82   zz0033                        5710 non-null   float32\n",
      " 83   zz0034                        5710 non-null   float32\n",
      " 84   zz0035                        5710 non-null   float32\n",
      " 85   zz0036                        5710 non-null   float32\n",
      " 86   zz0037                        5710 non-null   float32\n",
      " 87   zz0038                        5710 non-null   float32\n",
      " 88   zz0039                        5710 non-null   float32\n",
      " 89   zz0040                        5710 non-null   float32\n",
      " 90   zz0041                        5710 non-null   float32\n",
      " 91   zz0042                        5710 non-null   float32\n",
      " 92   zz0043                        5710 non-null   float32\n",
      " 93   zz0044                        5710 non-null   float32\n",
      " 94   zz0045                        5710 non-null   float32\n",
      " 95   zz0046                        5710 non-null   float32\n",
      " 96   zz0047                        5710 non-null   float32\n",
      " 97   zz0048                        5710 non-null   float32\n",
      " 98   zz0049                        5710 non-null   float32\n",
      " 99   zz0050                        5710 non-null   float32\n",
      " 100  zz0051                        5710 non-null   float32\n",
      " 101  zz0052                        5710 non-null   float32\n",
      " 102  zz0053                        5710 non-null   float32\n",
      " 103  zz0054                        5710 non-null   float32\n",
      " 104  zz0055                        5710 non-null   float32\n",
      " 105  zz0056                        5710 non-null   float32\n",
      " 106  zz0057                        5710 non-null   float32\n",
      " 107  zz0058                        5710 non-null   float32\n",
      " 108  zz0059                        5710 non-null   float32\n",
      " 109  zz0060                        5710 non-null   float32\n",
      " 110  zz0061                        5710 non-null   float32\n",
      " 111  zz0062                        5710 non-null   float32\n",
      " 112  zz0063                        5710 non-null   float32\n",
      " 113  zz0064                        5710 non-null   float32\n",
      " 114  zz0065                        5710 non-null   float32\n",
      " 115  zz0066                        5710 non-null   float32\n",
      " 116  zz0067                        5710 non-null   float32\n",
      " 117  zz0068                        5710 non-null   float32\n",
      " 118  zz0069                        5710 non-null   float32\n",
      " 119  zz0070                        5710 non-null   float32\n",
      " 120  zz0071                        5710 non-null   float32\n",
      " 121  zz0072                        5710 non-null   float32\n",
      " 122  zz0073                        5710 non-null   float32\n",
      " 123  zz0074                        5710 non-null   float32\n",
      " 124  zz0075                        5710 non-null   float32\n",
      " 125  zz0076                        5710 non-null   float32\n",
      " 126  zz0077                        5710 non-null   float32\n",
      " 127  zz0078                        5710 non-null   float32\n",
      " 128  zz0079                        5710 non-null   float32\n",
      " 129  zz0080                        5710 non-null   float32\n",
      " 130  zz0081                        5710 non-null   float32\n",
      " 131  zz0082                        5710 non-null   float32\n",
      " 132  zz0083                        5710 non-null   float32\n",
      " 133  zz0084                        5710 non-null   float32\n",
      " 134  zz0085                        5710 non-null   float32\n",
      " 135  zz0086                        5710 non-null   float32\n",
      " 136  zz0087                        5710 non-null   float32\n",
      " 137  zz0088                        5710 non-null   float32\n",
      " 138  zz0089                        5710 non-null   float32\n",
      " 139  zz0090                        5710 non-null   float32\n",
      " 140  zz0091                        5710 non-null   float32\n",
      " 141  zz0092                        5710 non-null   float32\n",
      " 142  zz0093                        5710 non-null   float32\n",
      " 143  zz0094                        5710 non-null   float32\n",
      " 144  zz0095                        5710 non-null   float32\n",
      " 145  zz0096                        5710 non-null   float32\n",
      " 146  zz0097                        5710 non-null   float32\n",
      " 147  zz0098                        5710 non-null   float32\n",
      " 148  zz0099                        5710 non-null   float32\n",
      " 149  zz0100                        5710 non-null   float32\n",
      " 150  zz0101                        5710 non-null   float32\n",
      " 151  zz0102                        5710 non-null   float32\n",
      " 152  zz0103                        5710 non-null   float32\n",
      " 153  zz0104                        5710 non-null   float32\n",
      " 154  zz0105                        5710 non-null   float32\n",
      " 155  zz0106                        5710 non-null   float32\n",
      " 156  zz0107                        5710 non-null   float32\n",
      " 157  zz0108                        5710 non-null   float32\n",
      " 158  zz0109                        5710 non-null   float32\n",
      " 159  zz0110                        5710 non-null   float32\n",
      " 160  zz0111                        5710 non-null   float32\n",
      " 161  zz0112                        5710 non-null   float32\n",
      " 162  zz0113                        5710 non-null   float32\n",
      " 163  zz0114                        5710 non-null   float32\n",
      " 164  zz0115                        5710 non-null   float32\n",
      " 165  zz0116                        5710 non-null   float32\n",
      " 166  zz0117                        5710 non-null   float32\n",
      " 167  zz0118                        5710 non-null   float32\n",
      " 168  zz0119                        5710 non-null   float32\n",
      " 169  zz0120                        5710 non-null   float32\n",
      " 170  zz0121                        5710 non-null   float32\n",
      " 171  zz0122                        5710 non-null   float32\n",
      " 172  zz0123                        5710 non-null   float32\n",
      " 173  zz0124                        5710 non-null   float32\n",
      " 174  zz0125                        5710 non-null   float32\n",
      " 175  zz0126                        5710 non-null   float32\n",
      " 176  zz0127                        5710 non-null   float32\n",
      " 177  zz0128                        5710 non-null   float32\n",
      " 178  zz0129                        5710 non-null   float32\n",
      " 179  zz0130                        5710 non-null   float32\n",
      " 180  zz0131                        5710 non-null   float32\n",
      " 181  zz0132                        5710 non-null   float32\n",
      " 182  zz0133                        5710 non-null   float32\n",
      " 183  zz0134                        5710 non-null   float32\n",
      " 184  zz0135                        5710 non-null   float32\n",
      " 185  zz0136                        5710 non-null   float32\n",
      " 186  zz0137                        5710 non-null   float32\n",
      " 187  zz0138                        5710 non-null   float32\n",
      " 188  zz0139                        5710 non-null   float32\n",
      " 189  zz0140                        5710 non-null   float32\n",
      " 190  zz0141                        5710 non-null   float32\n",
      " 191  zz0142                        5710 non-null   float32\n",
      " 192  zz0143                        5710 non-null   float32\n",
      " 193  zz0144                        5710 non-null   float32\n",
      " 194  zz0145                        5710 non-null   float32\n",
      " 195  zz0146                        5710 non-null   float32\n",
      " 196  zz0147                        5710 non-null   float32\n",
      " 197  zz0148                        5710 non-null   float32\n",
      " 198  zz0149                        5710 non-null   float32\n",
      " 199  zz0150                        5710 non-null   float32\n",
      " 200  zz0151                        5710 non-null   float32\n",
      " 201  zz0152                        5710 non-null   float32\n",
      " 202  zz0153                        5710 non-null   float32\n",
      " 203  zz0154                        5710 non-null   float32\n",
      " 204  zz0155                        5710 non-null   float32\n",
      " 205  zz0156                        5710 non-null   float32\n",
      " 206  zz0157                        5710 non-null   float32\n",
      " 207  zz0158                        5710 non-null   float32\n",
      " 208  zz0159                        5710 non-null   float32\n",
      " 209  zz0160                        5710 non-null   float32\n",
      " 210  zz0161                        5710 non-null   float32\n",
      " 211  zz0162                        5710 non-null   float32\n",
      " 212  zz0163                        5710 non-null   float32\n",
      " 213  zz0164                        5710 non-null   float32\n",
      " 214  zz0165                        5710 non-null   float32\n",
      " 215  zz0166                        5710 non-null   float32\n",
      " 216  zz0167                        5710 non-null   float32\n",
      " 217  zz0168                        5710 non-null   float32\n",
      " 218  zz0169                        5710 non-null   float32\n",
      " 219  zz0170                        5710 non-null   float32\n",
      " 220  zz0171                        5710 non-null   float32\n",
      " 221  zz0172                        5710 non-null   float32\n",
      " 222  zz0173                        5710 non-null   float32\n",
      " 223  zz0174                        5710 non-null   float32\n",
      " 224  zz0175                        5710 non-null   float32\n",
      " 225  zz0176                        5710 non-null   float32\n",
      " 226  zz0177                        5710 non-null   float32\n",
      " 227  zz0178                        5710 non-null   float32\n",
      " 228  zz0179                        5710 non-null   float32\n",
      " 229  zz0180                        5710 non-null   float32\n",
      " 230  zz0181                        5710 non-null   float32\n",
      " 231  zz0182                        5710 non-null   float32\n",
      " 232  zz0183                        5710 non-null   float32\n",
      " 233  zz0184                        5710 non-null   float32\n",
      " 234  zz0185                        5710 non-null   float32\n",
      " 235  zz0186                        5710 non-null   float32\n",
      " 236  zz0187                        5710 non-null   float32\n",
      " 237  zz0188                        5710 non-null   float32\n",
      " 238  zz0189                        5710 non-null   float32\n",
      " 239  zz0190                        5710 non-null   float32\n",
      " 240  zz0191                        5710 non-null   float32\n",
      " 241  zz0192                        5710 non-null   float32\n",
      " 242  zz0193                        5710 non-null   float32\n",
      " 243  zz0194                        5710 non-null   float32\n",
      " 244  zz0195                        5710 non-null   float32\n",
      " 245  zz0196                        5710 non-null   float32\n",
      " 246  zz0197                        5710 non-null   float32\n",
      " 247  zz0198                        5710 non-null   float32\n",
      " 248  zz0199                        5710 non-null   float32\n",
      " 249  zz0200                        5710 non-null   float32\n",
      " 250  zz0201                        5710 non-null   float32\n",
      " 251  zz0202                        5710 non-null   float32\n",
      " 252  zz0203                        5710 non-null   float32\n",
      " 253  zz0204                        5710 non-null   float32\n",
      " 254  zz0205                        5710 non-null   float32\n",
      " 255  zz0206                        5710 non-null   float32\n",
      " 256  zz0207                        5710 non-null   float32\n",
      " 257  zz0208                        5710 non-null   float32\n",
      " 258  zz0209                        5710 non-null   float32\n",
      " 259  zz0210                        5710 non-null   float32\n",
      " 260  zz0211                        5710 non-null   float32\n",
      " 261  zz0212                        5710 non-null   float32\n",
      " 262  zz0213                        5710 non-null   float32\n",
      " 263  zz0214                        5710 non-null   float32\n",
      " 264  zz0215                        5710 non-null   float32\n",
      " 265  zz0216                        5710 non-null   float32\n",
      " 266  zz0217                        5710 non-null   float32\n",
      " 267  zz0218                        5710 non-null   float32\n",
      " 268  zz0219                        5710 non-null   float32\n",
      " 269  zz0220                        5710 non-null   float32\n",
      " 270  zz0221                        5710 non-null   float32\n",
      " 271  zz0222                        5710 non-null   float32\n",
      " 272  zz0223                        5710 non-null   float32\n",
      " 273  zz0224                        5710 non-null   float32\n",
      " 274  zz0225                        5710 non-null   float32\n",
      " 275  zz0226                        5710 non-null   float32\n",
      " 276  zz0227                        5710 non-null   float32\n",
      " 277  zz0228                        5710 non-null   float32\n",
      " 278  zz0229                        5710 non-null   float32\n",
      " 279  zz0230                        5710 non-null   float32\n",
      " 280  zz0231                        5710 non-null   float32\n",
      " 281  zz0232                        5710 non-null   float32\n",
      " 282  zz0233                        5710 non-null   float32\n",
      " 283  zz0234                        5710 non-null   float32\n",
      " 284  zz0235                        5710 non-null   float32\n",
      " 285  zz0236                        5710 non-null   float32\n",
      " 286  zz0237                        5710 non-null   float32\n",
      " 287  zz0238                        5710 non-null   float32\n",
      " 288  zz0239                        5710 non-null   float32\n",
      " 289  zz0240                        5710 non-null   float32\n",
      " 290  zz0241                        5710 non-null   float32\n",
      " 291  zz0242                        5710 non-null   float32\n",
      " 292  zz0243                        5710 non-null   float32\n",
      " 293  zz0244                        5710 non-null   float32\n",
      " 294  zz0245                        5710 non-null   float32\n",
      " 295  zz0246                        5710 non-null   float32\n",
      " 296  zz0247                        5710 non-null   float32\n",
      " 297  zz0248                        5710 non-null   float32\n",
      " 298  zz0249                        5710 non-null   float32\n",
      " 299  zz0250                        5710 non-null   float32\n",
      " 300  zz0251                        5710 non-null   float32\n",
      " 301  zz0252                        5710 non-null   float32\n",
      " 302  zz0253                        5710 non-null   float32\n",
      " 303  zz0254                        5710 non-null   float32\n",
      " 304  zz0255                        5710 non-null   float32\n",
      " 305  zz0256                        5710 non-null   float32\n",
      " 306  zz0257                        5710 non-null   float32\n",
      " 307  zz0258                        5710 non-null   float32\n",
      " 308  zz0259                        5710 non-null   float32\n",
      " 309  zz0260                        5710 non-null   float32\n",
      " 310  zz0261                        5710 non-null   float32\n",
      " 311  zz0262                        5710 non-null   float32\n",
      " 312  zz0263                        5710 non-null   float32\n",
      " 313  zz0264                        5710 non-null   float32\n",
      " 314  zz0265                        5710 non-null   float32\n",
      " 315  zz0266                        5710 non-null   float32\n",
      " 316  zz0267                        5710 non-null   float32\n",
      " 317  zz0268                        5710 non-null   float32\n",
      " 318  zz0269                        5710 non-null   float32\n",
      " 319  zz0270                        5710 non-null   float32\n",
      " 320  zz0271                        5710 non-null   float32\n",
      " 321  zz0272                        5710 non-null   float32\n",
      " 322  zz0273                        5710 non-null   float32\n",
      " 323  zz0274                        5710 non-null   float32\n",
      " 324  zz0275                        5710 non-null   float32\n",
      " 325  zz0276                        5710 non-null   float32\n",
      " 326  zz0277                        5710 non-null   float32\n",
      " 327  zz0278                        5710 non-null   float32\n",
      " 328  zz0279                        5710 non-null   float32\n",
      " 329  zz0280                        5710 non-null   float32\n",
      " 330  zz0281                        5710 non-null   float32\n",
      " 331  zz0282                        5710 non-null   float32\n",
      " 332  zz0283                        5710 non-null   float32\n",
      " 333  zz0284                        5710 non-null   float32\n",
      " 334  zz0285                        5710 non-null   float32\n",
      " 335  zz0286                        5710 non-null   float32\n",
      " 336  zz0287                        5710 non-null   float32\n",
      " 337  zz0288                        5710 non-null   float32\n",
      " 338  zz0289                        5710 non-null   float32\n",
      " 339  zz0290                        5710 non-null   float32\n",
      " 340  zz0291                        5710 non-null   float32\n",
      " 341  zz0292                        5710 non-null   float32\n",
      " 342  zz0293                        5710 non-null   float32\n",
      " 343  zz0294                        5710 non-null   float32\n",
      " 344  zz0295                        5710 non-null   float32\n",
      " 345  zz0296                        5710 non-null   float32\n",
      " 346  zz0297                        5710 non-null   float32\n",
      " 347  zz0298                        5710 non-null   float32\n",
      " 348  zz0299                        5710 non-null   float32\n",
      " 349  zz0300                        5710 non-null   float32\n",
      " 350  zz0301                        5710 non-null   float32\n",
      " 351  zz0302                        5710 non-null   float32\n",
      " 352  zz0303                        5710 non-null   float32\n",
      " 353  zz0304                        5710 non-null   float32\n",
      " 354  zz0305                        5710 non-null   float32\n",
      " 355  zz0306                        5710 non-null   float32\n",
      " 356  zz0307                        5710 non-null   float32\n",
      " 357  zz0308                        5710 non-null   float32\n",
      " 358  zz0309                        5710 non-null   float32\n",
      " 359  zz0310                        5710 non-null   float32\n",
      " 360  zz0311                        5710 non-null   float32\n",
      " 361  zz0312                        5710 non-null   float32\n",
      " 362  zz0313                        5710 non-null   float32\n",
      " 363  zz0314                        5710 non-null   float32\n",
      " 364  zz0315                        5710 non-null   float32\n",
      " 365  zz0316                        5710 non-null   float32\n",
      " 366  zz0317                        5710 non-null   float32\n",
      " 367  zz0318                        5710 non-null   float32\n",
      " 368  zz0319                        5710 non-null   float32\n",
      " 369  zz0320                        5710 non-null   float32\n",
      " 370  zz0321                        5710 non-null   float32\n",
      " 371  zz0322                        5710 non-null   float32\n",
      " 372  zz0323                        5710 non-null   float32\n",
      " 373  zz0324                        5710 non-null   float32\n",
      " 374  zz0325                        5710 non-null   float32\n",
      " 375  zz0326                        5710 non-null   float32\n",
      " 376  zz0327                        5710 non-null   float32\n",
      " 377  zz0328                        5710 non-null   float32\n",
      " 378  zz0329                        5710 non-null   float32\n",
      " 379  zz0330                        5710 non-null   float32\n",
      " 380  zz0331                        5710 non-null   float32\n",
      " 381  zz0332                        5710 non-null   float32\n",
      " 382  zz0333                        5710 non-null   float32\n",
      " 383  zz0334                        5710 non-null   float32\n",
      " 384  zz0335                        5710 non-null   float32\n",
      " 385  zz0336                        5710 non-null   float32\n",
      " 386  zz0337                        5710 non-null   float32\n",
      " 387  zz0338                        5710 non-null   float32\n",
      " 388  zz0339                        5710 non-null   float32\n",
      " 389  zz0340                        5710 non-null   float32\n",
      " 390  zz0341                        5710 non-null   float32\n",
      " 391  zz0342                        5710 non-null   float32\n",
      " 392  zz0343                        5710 non-null   float32\n",
      " 393  zz0344                        5710 non-null   float32\n",
      " 394  zz0345                        5710 non-null   float32\n",
      " 395  zz0346                        5710 non-null   float32\n",
      " 396  zz0347                        5710 non-null   float32\n",
      " 397  zz0348                        5710 non-null   float32\n",
      " 398  zz0349                        5710 non-null   float32\n",
      " 399  zz0350                        5710 non-null   float32\n",
      " 400  zz0351                        5710 non-null   float32\n",
      " 401  zz0352                        5710 non-null   float32\n",
      " 402  zz0353                        5710 non-null   float32\n",
      " 403  zz0354                        5710 non-null   float32\n",
      " 404  zz0355                        5710 non-null   float32\n",
      " 405  zz0356                        5710 non-null   float32\n",
      " 406  zz0357                        5710 non-null   float32\n",
      " 407  zz0358                        5710 non-null   float32\n",
      " 408  zz0359                        5710 non-null   float32\n",
      " 409  zz0360                        5710 non-null   float32\n",
      " 410  zz0361                        5710 non-null   float32\n",
      " 411  zz0362                        5710 non-null   float32\n",
      " 412  zz0363                        5710 non-null   float32\n",
      " 413  zz0364                        5710 non-null   float32\n",
      " 414  zz0365                        5710 non-null   float32\n",
      " 415  zz0366                        5710 non-null   float32\n",
      " 416  zz0367                        5710 non-null   float32\n",
      " 417  zz0368                        5710 non-null   float32\n",
      " 418  zz0369                        5710 non-null   float32\n",
      " 419  zz0370                        5710 non-null   float32\n",
      " 420  zz0371                        5710 non-null   float32\n",
      " 421  zz0372                        5710 non-null   float32\n",
      " 422  zz0373                        5710 non-null   float32\n",
      " 423  zz0374                        5710 non-null   float32\n",
      " 424  zz0375                        5710 non-null   float32\n",
      " 425  zz0376                        5710 non-null   float32\n",
      " 426  zz0377                        5710 non-null   float32\n",
      " 427  zz0378                        5710 non-null   float32\n",
      " 428  zz0379                        5710 non-null   float32\n",
      " 429  zz0380                        5710 non-null   float32\n",
      " 430  zz0381                        5710 non-null   float32\n",
      " 431  zz0382                        5710 non-null   float32\n",
      " 432  zz0383                        5710 non-null   float32\n",
      "dtypes: float32(430), int16(1), int32(1), int8(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "cols += em_cols\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b13fb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[cols].to_parquet(\"output/tra.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
