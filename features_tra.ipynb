{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b888a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import rankdata\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import textstat\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8f39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', dtfy_model_max_length=512, dtfy_batch_size=256, dtfy_models={'dto_': 'pretrained/unitaryai/detoxify/toxic_original-c1212f89.ckpt', 'dtu_': 'pretrained/unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt', 'dtm_': 'pretrained/unitaryai/detoxify/multilingual_debiased-0b549669.ckpt'}, dtfy_configs={'dto_': 'pretrained/bert-base-uncased', 'dtu_': 'pretrained/roberta-base', 'dtm_': 'pretrained/xlm-roberta-base'}, tweeteval_model_max_length=512, tweeteval_batch_size=64, tweeteval_models={'te_roberta_off': 'pretrained/cardiffnlp/twitter-roberta-base-offensive', 'te_roberta_emo_anger': 'pretrained/cardiffnlp/twitter-roberta-base-emotion', 'te_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-roberta-base-sentiment', 'te_roberta_iro': 'pretrained/cardiffnlp/twitter-roberta-base-irony', 'te_xlm_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-xlm-roberta-base-sentiment'}, tweeteval_label_index={'te_roberta_off': 1, 'te_roberta_emo_anger': 0, 'te_roberta_snt_neg': 0, 'te_roberta_iro': 1, 'te_xlm_roberta_snt_neg': 0}, hatebert_model_max_length=512, hatebert_batch_size=128, hatebert_models={'hb_bert_off': 'pretrained/hatebert/bert-offenseval', 'hb_bert_abu': 'pretrained/hatebert/bert-abuseval', 'hb_hatebert_off': 'pretrained/hatebert/hatebert-offenseval', 'hb_hatebert_abu': 'pretrained/hatebert/hatebert-abuseval'}, em_max_seq_length=128, em_batch_size=1000, em_models={'paraphrase-MiniLM-L6-v2': 'pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2'})\n",
      "NVIDIA GeForce GTX 1060 6GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    dtfy_model_max_length: int = 512\n",
    "    dtfy_batch_size: int = 256\n",
    "    dtfy_models: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_original-c1212f89.ckpt\",\n",
    "        \"dtu_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt\",\n",
    "        \"dtm_\": f\"{pretrained_dir}unitaryai/detoxify/multilingual_debiased-0b549669.ckpt\"\n",
    "    }\n",
    "    dtfy_configs: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}bert-base-uncased\",\n",
    "        \"dtu_\": f\"{pretrained_dir}roberta-base\",\n",
    "        \"dtm_\": f\"{pretrained_dir}xlm-roberta-base\"\n",
    "    }\n",
    "    tweeteval_model_max_length: int = 512\n",
    "    tweeteval_batch_size: int = 64\n",
    "    tweeteval_models: Dict[str, str] = {\n",
    "        \"te_roberta_off\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-offensive\",\n",
    "        \"te_roberta_emo_anger\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        \"te_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        \"te_roberta_iro\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-irony\",\n",
    "        \"te_xlm_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    }\n",
    "    tweeteval_label_index: Dict[str, int] = {\n",
    "        \"te_roberta_off\": 1,\n",
    "        \"te_roberta_emo_anger\": 0,\n",
    "        \"te_roberta_snt_neg\": 0,\n",
    "        \"te_roberta_iro\": 1,\n",
    "        \"te_xlm_roberta_snt_neg\": 0,\n",
    "    }\n",
    "    hatebert_model_max_length: int = 512\n",
    "    hatebert_batch_size: int = 128\n",
    "    hatebert_models: Dict[str, str] = {\n",
    "        \"hb_bert_off\": f\"{pretrained_dir}hatebert/bert-offenseval\",\n",
    "        \"hb_bert_abu\" : f\"{pretrained_dir}hatebert/bert-abuseval\",\n",
    "        \"hb_hatebert_off\": f\"{pretrained_dir}hatebert/hatebert-offenseval\",\n",
    "        \"hb_hatebert_abu\" : f\"{pretrained_dir}hatebert/hatebert-abuseval\",\n",
    "    }\n",
    "    em_max_seq_length: int = 128\n",
    "    em_batch_size: int = 1000\n",
    "    em_models: Dict[str, str] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "    }\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   5710 non-null   int32  \n",
      " 1   bws     5710 non-null   float32\n",
      " 2   worker  5710 non-null   int8   \n",
      " 3   text    5710 non-null   object \n",
      " 4   text1   5710 non-null   object \n",
      "dtypes: float32(1), int32(1), int8(1), object(2)\n",
      "memory usage: 139.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/pre_ruddit.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752d7ac",
   "metadata": {},
   "source": [
    "# Character level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71d6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col = \"length\"\n",
    "df[col] = df[\"text1\"].str.len()\n",
    "df[col] = df[col].astype(np.int16)\n",
    "char_fs = [col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74a87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[\"text1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 38846.48it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"digit_frac\"\n",
    "df[col] = df.progress_apply(digit_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddc24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 38270.85it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"letter_frac\"\n",
    "df[col] = df.progress_apply(letter_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ca5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39534.55it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"space_frac\"\n",
    "df[col] = df.progress_apply(space_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5701ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 35017.13it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"punc_frac\"\n",
    "df[col] = df.progress_apply(punc_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a860959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39104.25it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"upper_frac\"\n",
    "df[col] = df.progress_apply(upper_frac, axis=1)\n",
    "df[col] = df[col].astype(np.float32)\n",
    "char_fs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c7b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length', 'digit_frac', 'letter_frac', 'space_frac', 'punc_frac', 'upper_frac']\n"
     ]
    }
   ],
   "source": [
    "print(char_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d4202",
   "metadata": {},
   "source": [
    "# Textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def syllables_per_word(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"lexicon_count\"] + 1)\n",
    "\n",
    "\n",
    "def syllables_per_sent(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def words_per_sent(row) -> float:\n",
    "    return row[\"lexicon_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[\"text1\"])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[\"text1\"])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[\"text1\"])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[\"text1\"])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[\"text1\"])\n",
    "\n",
    "\n",
    "textstat_fns: Dict[str, Callable] = {\n",
    "    \"syllables_per_word\": syllables_per_word,\n",
    "    \"syllables_per_sent\": syllables_per_sent,\n",
    "    \"words_per_sent\": words_per_sent,\n",
    "    \"flesch_reading_ease\": flesch_reading_ease,\n",
    "    \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
    "    \"gunning_fog\": gunning_fog,\n",
    "    \"smog_index\": smog_index,\n",
    "    \"automated_readability_index\": automated_readability_index,\n",
    "    \"coleman_liau_index\": coleman_liau_index,\n",
    "    \"linsear_write_formula\": linsear_write_formula,\n",
    "    \"dale_chall_readability_score\": dale_chall_readability_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d91172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 8097.44it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"syllable_count\"\n",
    "df[col] = df.progress_apply(syllable_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc45e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 68526.73it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"lexicon_count\"\n",
    "df[col] = df.progress_apply(lexicon_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "245bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 41327.97it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"sentence_count\"\n",
    "df[col] = df.progress_apply(sentence_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c32df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 90637.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 90187.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 88197.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_reading_ease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12167.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_kincaid_grade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12979.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunning_fog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10040.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smog_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 16696.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automated_readability_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 27272.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coleman_liau_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 24109.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linsear_write_formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 11960.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dale_chall_readability_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10486.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in textstat_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285247d",
   "metadata": {},
   "source": [
    "# TweetEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "167d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9025, 0.0975],\n",
      "        [0.5804, 0.4196],\n",
      "        [0.6679, 0.3321],\n",
      "        [0.8045, 0.1955],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.7749, 0.2251],\n",
      "        [0.8272, 0.1728],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.7598, 0.2402],\n",
      "        [0.9035, 0.0965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_emo_anger torch.Size([5710, 4])\n",
      "logits[:10]=tensor([[0.0376, 0.0565, 0.8628, 0.0431],\n",
      "        [0.1369, 0.1012, 0.2558, 0.5061],\n",
      "        [0.8166, 0.0105, 0.0391, 0.1338],\n",
      "        [0.9419, 0.0041, 0.0231, 0.0308],\n",
      "        [0.6140, 0.0225, 0.1561, 0.2074],\n",
      "        [0.8744, 0.0085, 0.0585, 0.0586],\n",
      "        [0.8556, 0.0071, 0.0948, 0.0425],\n",
      "        [0.8475, 0.0155, 0.0260, 0.1111],\n",
      "        [0.8054, 0.0086, 0.0704, 0.1156],\n",
      "        [0.1417, 0.3192, 0.3703, 0.1687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:04<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.0407, 0.7561, 0.2032],\n",
      "        [0.4268, 0.5488, 0.0244],\n",
      "        [0.7662, 0.2259, 0.0080],\n",
      "        [0.6066, 0.3729, 0.0206],\n",
      "        [0.5169, 0.4232, 0.0599],\n",
      "        [0.5795, 0.3848, 0.0357],\n",
      "        [0.3226, 0.6394, 0.0380],\n",
      "        [0.7787, 0.2147, 0.0066],\n",
      "        [0.7998, 0.1863, 0.0139],\n",
      "        [0.1055, 0.6091, 0.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:04<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_iro torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.7999, 0.2001],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.3392, 0.6608],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.8869, 0.1131],\n",
      "        [0.4666, 0.5334],\n",
      "        [0.7453, 0.2547],\n",
      "        [0.0874, 0.9126],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.6555, 0.3445]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:04<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_xlm_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.1049, 0.7652, 0.1299],\n",
      "        [0.1865, 0.7562, 0.0573],\n",
      "        [0.4178, 0.4738, 0.1084],\n",
      "        [0.7074, 0.2630, 0.0296],\n",
      "        [0.8242, 0.1541, 0.0217],\n",
      "        [0.5170, 0.4337, 0.0493],\n",
      "        [0.5321, 0.4271, 0.0408],\n",
      "        [0.5248, 0.4357, 0.0396],\n",
      "        [0.9013, 0.0858, 0.0129],\n",
      "        [0.3988, 0.4830, 0.1182]])\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df[\"text1\"])\n",
    "for col, model_dir in conf.tweeteval_models.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir, \n",
    "        model_max_length=conf.tweeteval_model_max_length\n",
    "    )\n",
    "    #print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")\n",
    "    x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "    batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.tweeteval_batch_size, shuffle=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,conf.tweeteval_label_index[col]]\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "    del tokenizer, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e694b",
   "metadata": {},
   "source": [
    "# HateBert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d49676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/hatebert/hatebert-offenseval', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# all Hatebert models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.hatebert_models[\"hb_hatebert_off\"], \n",
    "    model_max_length=conf.hatebert_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12e71aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 956 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baba8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9598, 0.0402],\n",
      "        [0.7718, 0.2282],\n",
      "        [0.7567, 0.2433],\n",
      "        [0.9064, 0.0936],\n",
      "        [0.8356, 0.1644],\n",
      "        [0.7731, 0.2269],\n",
      "        [0.5952, 0.4048],\n",
      "        [0.8502, 0.1498],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9258, 0.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:12<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9910, 0.0090],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9631, 0.0369],\n",
      "        [0.9727, 0.0273],\n",
      "        [0.8744, 0.1256],\n",
      "        [0.9001, 0.0999],\n",
      "        [0.8544, 0.1456],\n",
      "        [0.8708, 0.1292],\n",
      "        [0.9881, 0.0119]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:15<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9377, 0.0623],\n",
      "        [0.5526, 0.4474],\n",
      "        [0.7553, 0.2447],\n",
      "        [0.7828, 0.2172],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9279, 0.0721],\n",
      "        [0.8304, 0.1696],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8965, 0.1035]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:11<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9846, 0.0154],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9699, 0.0301],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.9775, 0.0225],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9733, 0.0267],\n",
      "        [0.9407, 0.0593],\n",
      "        [0.9795, 0.0205]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.hatebert_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.hatebert_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,1]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f069f2",
   "metadata": {},
   "source": [
    "# Detoxify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a45a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 3/3 [04:01<00:00, 80.52s/it]\n"
     ]
    }
   ],
   "source": [
    "dtfy_fs = []\n",
    "for prefix, checkpoint in tqdm(conf.dtfy_models.items()):\n",
    "    res = mylib.detoxify_labels(\n",
    "        sentences,\n",
    "        checkpoint=checkpoint,\n",
    "        config_dir=conf.dtfy_configs[prefix],\n",
    "        model_max_length=conf.dtfy_model_max_length,\n",
    "        device=conf.device,\n",
    "        batch_size=conf.dtfy_batch_size\n",
    "    )\n",
    "    for k, v in res.items():\n",
    "        col = prefix + k\n",
    "        df[col] = v\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        dtfy_fs.append(col)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6312beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dto_toxicity', 'dto_severe_toxicity', 'dto_obscene', 'dto_threat', 'dto_insult', 'dto_identity_attack', 'dtu_toxicity', 'dtu_severe_toxicity', 'dtu_obscene', 'dtu_identity_attack', 'dtu_insult', 'dtu_threat', 'dtu_sexual_explicit', 'dtm_toxicity', 'dtm_severe_toxicity', 'dtm_obscene', 'dtm_identity_attack', 'dtm_insult', 'dtm_threat', 'dtm_sexual_explicit']\n"
     ]
    }
   ],
   "source": [
    "print(dtfy_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e5b5d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d1f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|SentenceTransformer.py:60] 2021-12-27 08:25:02,501 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333ad7f105f641e79016538561f5de29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(5710, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(conf.em_models[\"paraphrase-MiniLM-L6-v2\"], device=conf.device)\n",
    "model.max_seq_length = conf.em_max_seq_length\n",
    "em = model.encode(sentences=sentences, batch_size=conf.em_batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bdd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 242 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "em_size = em.shape[1]\n",
    "em_cols = [f\"zz{i:04d}\" for i in range(em_size)]\n",
    "df[em_cols] = em\n",
    "df[em_cols] = df[em_cols].astype(np.float32)\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335287",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15b1d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bws</th>\n",
       "      <th>worker</th>\n",
       "      <th>length</th>\n",
       "      <th>digit_frac</th>\n",
       "      <th>letter_frac</th>\n",
       "      <th>space_frac</th>\n",
       "      <th>punc_frac</th>\n",
       "      <th>upper_frac</th>\n",
       "      <th>dto_toxicity</th>\n",
       "      <th>dto_severe_toxicity</th>\n",
       "      <th>dto_obscene</th>\n",
       "      <th>dto_threat</th>\n",
       "      <th>dto_insult</th>\n",
       "      <th>dto_identity_attack</th>\n",
       "      <th>dtu_toxicity</th>\n",
       "      <th>dtu_severe_toxicity</th>\n",
       "      <th>dtu_obscene</th>\n",
       "      <th>dtu_identity_attack</th>\n",
       "      <th>dtu_insult</th>\n",
       "      <th>dtu_threat</th>\n",
       "      <th>dtu_sexual_explicit</th>\n",
       "      <th>dtm_toxicity</th>\n",
       "      <th>dtm_severe_toxicity</th>\n",
       "      <th>dtm_obscene</th>\n",
       "      <th>dtm_identity_attack</th>\n",
       "      <th>dtm_insult</th>\n",
       "      <th>dtm_threat</th>\n",
       "      <th>dtm_sexual_explicit</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>syllables_per_sent</th>\n",
       "      <th>words_per_sent</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>hb_bert_off</th>\n",
       "      <th>hb_bert_abu</th>\n",
       "      <th>hb_hatebert_off</th>\n",
       "      <th>hb_hatebert_abu</th>\n",
       "      <th>te_roberta_off</th>\n",
       "      <th>te_roberta_emo_anger</th>\n",
       "      <th>te_roberta_snt_neg</th>\n",
       "      <th>te_roberta_iro</th>\n",
       "      <th>te_xlm_roberta_snt_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5.710000e+03</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.560420</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.788887</td>\n",
       "      <td>0.177650</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.177866</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.113684</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.195835</td>\n",
       "      <td>4.691700e-03</td>\n",
       "      <td>0.113012</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.040173</td>\n",
       "      <td>0.203089</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.105199</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.083620</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.044624</td>\n",
       "      <td>1.293951</td>\n",
       "      <td>13.776946</td>\n",
       "      <td>10.047346</td>\n",
       "      <td>75.315521</td>\n",
       "      <td>6.677233</td>\n",
       "      <td>8.998837</td>\n",
       "      <td>3.062960</td>\n",
       "      <td>7.479265</td>\n",
       "      <td>6.629302</td>\n",
       "      <td>8.560555</td>\n",
       "      <td>8.298417</td>\n",
       "      <td>0.332527</td>\n",
       "      <td>0.166042</td>\n",
       "      <td>0.329949</td>\n",
       "      <td>0.144240</td>\n",
       "      <td>0.350055</td>\n",
       "      <td>0.507478</td>\n",
       "      <td>0.508562</td>\n",
       "      <td>0.313064</td>\n",
       "      <td>0.576870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1648.47935</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.022817</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.021401</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>0.049024</td>\n",
       "      <td>0.326329</td>\n",
       "      <td>0.053001</td>\n",
       "      <td>0.282483</td>\n",
       "      <td>0.056295</td>\n",
       "      <td>0.175396</td>\n",
       "      <td>0.064743</td>\n",
       "      <td>0.341330</td>\n",
       "      <td>2.270452e-02</td>\n",
       "      <td>0.285394</td>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.207764</td>\n",
       "      <td>0.069502</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.345338</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.272974</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>0.215015</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.155257</td>\n",
       "      <td>0.195812</td>\n",
       "      <td>8.243071</td>\n",
       "      <td>5.753373</td>\n",
       "      <td>19.910217</td>\n",
       "      <td>4.433799</td>\n",
       "      <td>4.646113</td>\n",
       "      <td>4.695702</td>\n",
       "      <td>5.569417</td>\n",
       "      <td>3.869099</td>\n",
       "      <td>5.905854</td>\n",
       "      <td>2.263760</td>\n",
       "      <td>0.331918</td>\n",
       "      <td>0.278423</td>\n",
       "      <td>0.284725</td>\n",
       "      <td>0.221207</td>\n",
       "      <td>0.251345</td>\n",
       "      <td>0.357471</td>\n",
       "      <td>0.319236</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.301809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.529070e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-48.980000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.700000</td>\n",
       "      <td>-10.160000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.007853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>58.09000</td>\n",
       "      <td>-0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673311</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>1.083922e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-2.928200</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.049784</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.022383</td>\n",
       "      <td>0.019069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>286.45000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.141495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1.200329e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.040001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>0.021369</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.036441</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>0.052166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>571.90000</td>\n",
       "      <td>-0.426000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.151251</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.270754e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>50.509998</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.016068</td>\n",
       "      <td>0.091998</td>\n",
       "      <td>0.040597</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.107149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1142.80000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770103</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>1.407515e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.137931</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>60.139999</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.078535</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>0.124509</td>\n",
       "      <td>0.091023</td>\n",
       "      <td>0.146773</td>\n",
       "      <td>0.071837</td>\n",
       "      <td>0.242166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>1713.70000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779726</td>\n",
       "      <td>0.168605</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>1.639610e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.193548</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>66.739998</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>6.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.112946</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.161733</td>\n",
       "      <td>0.176001</td>\n",
       "      <td>0.295404</td>\n",
       "      <td>0.102690</td>\n",
       "      <td>0.384754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>2284.60000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.021684</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>2.274377e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.245283</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>72.160004</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>0.109342</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.157483</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.208334</td>\n",
       "      <td>0.321663</td>\n",
       "      <td>0.416598</td>\n",
       "      <td>0.144715</td>\n",
       "      <td>0.515363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>4.155347e-06</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1.287618</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>76.220001</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.171859</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.218302</td>\n",
       "      <td>0.047660</td>\n",
       "      <td>0.265682</td>\n",
       "      <td>0.526801</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.200425</td>\n",
       "      <td>0.644186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>3426.40000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798769</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>1.014265e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>80.959999</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>7.474000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>0.282521</td>\n",
       "      <td>0.048030</td>\n",
       "      <td>0.310856</td>\n",
       "      <td>0.067523</td>\n",
       "      <td>0.342524</td>\n",
       "      <td>0.714927</td>\n",
       "      <td>0.652219</td>\n",
       "      <td>0.290468</td>\n",
       "      <td>0.752811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3997.30000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805529</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.056457</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>3.191344e-05</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.382353</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>85.690002</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>10.853000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>8.453000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>0.459815</td>\n",
       "      <td>0.097012</td>\n",
       "      <td>0.439863</td>\n",
       "      <td>0.106683</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>0.837082</td>\n",
       "      <td>0.758305</td>\n",
       "      <td>0.415063</td>\n",
       "      <td>0.831708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4568.20000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.812852</td>\n",
       "      <td>0.194030</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.316727</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.429854</td>\n",
       "      <td>1.706842e-04</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.041563</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.488582</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>1.442371</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>91.110001</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>12.134000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>9.520000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>0.719315</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.615395</td>\n",
       "      <td>0.190064</td>\n",
       "      <td>0.589677</td>\n",
       "      <td>0.911722</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.583751</td>\n",
       "      <td>0.885076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5139.10000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.822926</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.670921</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.168232</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.930485</td>\n",
       "      <td>4.385715e-03</td>\n",
       "      <td>0.736248</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>0.297081</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.042555</td>\n",
       "      <td>0.927456</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.658297</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.306216</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.079575</td>\n",
       "      <td>1.533957</td>\n",
       "      <td>24.755000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>99.570000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.501000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>11.140000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.928643</td>\n",
       "      <td>0.709186</td>\n",
       "      <td>0.823997</td>\n",
       "      <td>0.460149</td>\n",
       "      <td>0.784447</td>\n",
       "      <td>0.955451</td>\n",
       "      <td>0.921544</td>\n",
       "      <td>0.785951</td>\n",
       "      <td>0.921948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5424.55000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577.550000</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.985316</td>\n",
       "      <td>0.086339</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.480859</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>0.979385</td>\n",
       "      <td>2.221569e-02</td>\n",
       "      <td>0.934339</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.288302</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.911508</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.686739</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>1.622100</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>105.660004</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>12.615500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.830000</td>\n",
       "      <td>0.960791</td>\n",
       "      <td>0.913868</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.738755</td>\n",
       "      <td>0.858253</td>\n",
       "      <td>0.968323</td>\n",
       "      <td>0.953920</td>\n",
       "      <td>0.885475</td>\n",
       "      <td>0.938447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5652.91000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.820000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.119969</td>\n",
       "      <td>0.159718</td>\n",
       "      <td>0.997169</td>\n",
       "      <td>0.282513</td>\n",
       "      <td>0.984720</td>\n",
       "      <td>0.317607</td>\n",
       "      <td>0.887015</td>\n",
       "      <td>0.265168</td>\n",
       "      <td>0.994499</td>\n",
       "      <td>1.104572e-01</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.454090</td>\n",
       "      <td>0.947763</td>\n",
       "      <td>0.401428</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.994160</td>\n",
       "      <td>0.127040</td>\n",
       "      <td>0.977242</td>\n",
       "      <td>0.404110</td>\n",
       "      <td>0.969594</td>\n",
       "      <td>0.472689</td>\n",
       "      <td>0.890709</td>\n",
       "      <td>1.824868</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>116.150002</td>\n",
       "      <td>20.373000</td>\n",
       "      <td>23.709999</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>16.376399</td>\n",
       "      <td>29.455000</td>\n",
       "      <td>14.606400</td>\n",
       "      <td>0.972489</td>\n",
       "      <td>0.967271</td>\n",
       "      <td>0.957988</td>\n",
       "      <td>0.945889</td>\n",
       "      <td>0.913508</td>\n",
       "      <td>0.979008</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.960554</td>\n",
       "      <td>0.955456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.764529</td>\n",
       "      <td>0.994431</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>4.605981e-01</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>118.680000</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>55.520000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.985018</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.966720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label          bws  worker       length   digit_frac  letter_frac  \\\n",
       "count  5710.00000  5710.000000  5710.0  5710.000000  5710.000000  5710.000000   \n",
       "mean   2855.50000    -0.027706     0.0   197.560420     0.003544     0.788887   \n",
       "std    1648.47935     0.334195     0.0   172.022817     0.012997     0.034284   \n",
       "min       1.00000    -0.889000     0.0    15.000000     0.000000     0.400000   \n",
       "1%       58.09000    -0.667000     0.0    24.000000     0.000000     0.673311   \n",
       "5%      286.45000    -0.521000     0.0    33.000000     0.000000     0.733333   \n",
       "10%     571.90000    -0.426000     0.0    42.000000     0.000000     0.750000   \n",
       "20%    1142.80000    -0.312000     0.0    60.000000     0.000000     0.770103   \n",
       "30%    1713.70000    -0.213000     0.0    82.000000     0.000000     0.779726   \n",
       "40%    2284.60000    -0.146000     0.0   106.000000     0.000000     0.786667   \n",
       "50%    2855.50000    -0.062000     0.0   137.000000     0.000000     0.792857   \n",
       "60%    3426.40000     0.021000     0.0   177.000000     0.000000     0.798769   \n",
       "70%    3997.30000     0.104000     0.0   233.000000     0.000000     0.805529   \n",
       "80%    4568.20000     0.229000     0.0   317.000000     0.000000     0.812852   \n",
       "90%    5139.10000     0.458000     0.0   458.000000     0.009662     0.822926   \n",
       "95%    5424.55000     0.625000     0.0   577.550000     0.022415     0.831579   \n",
       "99%    5652.91000     0.833000     0.0   749.820000     0.060606     0.857143   \n",
       "max    5710.00000     0.979000     0.0   917.000000     0.235294     0.897436   \n",
       "\n",
       "        space_frac    punc_frac   upper_frac  dto_toxicity  \\\n",
       "count  5710.000000  5710.000000  5710.000000   5710.000000   \n",
       "mean      0.177650     0.029919     0.030518      0.177866   \n",
       "std       0.021401     0.023991     0.049024      0.326329   \n",
       "min       0.040541     0.000000     0.000000      0.000506   \n",
       "1%        0.117647     0.000000     0.000000      0.000556   \n",
       "5%        0.141495     0.000000     0.005062      0.000614   \n",
       "10%       0.151251     0.010417     0.008333      0.000668   \n",
       "20%       0.161905     0.015385     0.011759      0.000798   \n",
       "30%       0.168605     0.018710     0.014599      0.001007   \n",
       "40%       0.173913     0.021684     0.017857      0.001533   \n",
       "50%       0.178862     0.025000     0.021277      0.004124   \n",
       "60%       0.183333     0.028571     0.025485      0.015243   \n",
       "70%       0.188235     0.032787     0.030912      0.056457   \n",
       "80%       0.194030     0.040000     0.038981      0.316727   \n",
       "90%       0.202703     0.054054     0.054560      0.887332   \n",
       "95%       0.210526     0.069767     0.074074      0.985316   \n",
       "99%       0.227273     0.119969     0.159718      0.997169   \n",
       "max       0.272727     0.397849     0.857143      0.999072   \n",
       "\n",
       "       dto_severe_toxicity  dto_obscene   dto_threat   dto_insult  \\\n",
       "count          5710.000000  5710.000000  5710.000000  5710.000000   \n",
       "mean              0.013084     0.113684     0.008402     0.059691   \n",
       "std               0.053001     0.282483     0.056295     0.175396   \n",
       "min               0.000080     0.000141     0.000086     0.000164   \n",
       "1%                0.000087     0.000158     0.000096     0.000171   \n",
       "5%                0.000093     0.000165     0.000103     0.000175   \n",
       "10%               0.000097     0.000170     0.000108     0.000177   \n",
       "20%               0.000103     0.000176     0.000115     0.000181   \n",
       "30%               0.000108     0.000183     0.000121     0.000188   \n",
       "40%               0.000114     0.000196     0.000127     0.000207   \n",
       "50%               0.000121     0.000280     0.000138     0.000298   \n",
       "60%               0.000132     0.000579     0.000209     0.000679   \n",
       "70%               0.000225     0.001716     0.000431     0.002063   \n",
       "80%               0.001120     0.018481     0.001117     0.014511   \n",
       "90%               0.016841     0.670921     0.003118     0.168232   \n",
       "95%               0.086339     0.948901     0.009527     0.480859   \n",
       "99%               0.282513     0.984720     0.317607     0.887015   \n",
       "max               0.764529     0.994431     0.823060     0.980776   \n",
       "\n",
       "       dto_identity_attack  dtu_toxicity  dtu_severe_toxicity  dtu_obscene  \\\n",
       "count          5710.000000   5710.000000         5.710000e+03  5710.000000   \n",
       "mean              0.011463      0.195835         4.691700e-03     0.113012   \n",
       "std               0.064743      0.341330         2.270452e-02     0.285394   \n",
       "min               0.000121      0.000286         9.529070e-07     0.000017   \n",
       "1%                0.000134      0.000359         1.083922e-06     0.000021   \n",
       "5%                0.000138      0.000410         1.200329e-06     0.000024   \n",
       "10%               0.000140      0.000454         1.270754e-06     0.000026   \n",
       "20%               0.000145      0.000568         1.407515e-06     0.000031   \n",
       "30%               0.000151      0.000846         1.639610e-06     0.000041   \n",
       "40%               0.000165      0.001601         2.274377e-06     0.000067   \n",
       "50%               0.000211      0.003782         4.155347e-06     0.000130   \n",
       "60%               0.000361      0.014255         1.014265e-05     0.000302   \n",
       "70%               0.000866      0.078342         3.191344e-05     0.000956   \n",
       "80%               0.002608      0.429854         1.706842e-04     0.006377   \n",
       "90%               0.009993      0.930485         4.385715e-03     0.736248   \n",
       "95%               0.032305      0.979385         2.221569e-02     0.934339   \n",
       "99%               0.265168      0.994499         1.104572e-01     0.975236   \n",
       "max               0.894015      0.998344         4.605981e-01     0.987875   \n",
       "\n",
       "       dtu_identity_attack   dtu_insult   dtu_threat  dtu_sexual_explicit  \\\n",
       "count          5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean              0.015220     0.081488     0.010987             0.040173   \n",
       "std               0.074318     0.207764     0.069502             0.149440   \n",
       "min               0.000052     0.000061     0.000012             0.000009   \n",
       "1%                0.000063     0.000091     0.000015             0.000011   \n",
       "5%                0.000070     0.000103     0.000017             0.000012   \n",
       "10%               0.000076     0.000111     0.000019             0.000013   \n",
       "20%               0.000089     0.000132     0.000023             0.000016   \n",
       "30%               0.000112     0.000177     0.000030             0.000021   \n",
       "40%               0.000175     0.000308     0.000048             0.000033   \n",
       "50%               0.000364     0.000657     0.000088             0.000068   \n",
       "60%               0.000845     0.001621     0.000179             0.000176   \n",
       "70%               0.002036     0.005588     0.000396             0.000531   \n",
       "80%               0.004938     0.041563     0.000966             0.003241   \n",
       "90%               0.015779     0.297081     0.002905             0.042555   \n",
       "95%               0.041931     0.656381     0.014624             0.288302   \n",
       "99%               0.454090     0.947763     0.401428             0.863210   \n",
       "max               0.984674     0.993023     0.925068             0.974648   \n",
       "\n",
       "       dtm_toxicity  dtm_severe_toxicity  dtm_obscene  dtm_identity_attack  \\\n",
       "count   5710.000000          5710.000000  5710.000000          5710.000000   \n",
       "mean       0.203089             0.005749     0.105199             0.013481   \n",
       "std        0.345338             0.027229     0.272974             0.075221   \n",
       "min        0.000178             0.000009     0.000063             0.000045   \n",
       "1%         0.000281             0.000013     0.000094             0.000066   \n",
       "5%         0.000356             0.000016     0.000115             0.000078   \n",
       "10%        0.000416             0.000019     0.000129             0.000086   \n",
       "20%        0.000577             0.000023     0.000159             0.000099   \n",
       "30%        0.000855             0.000027     0.000201             0.000118   \n",
       "40%        0.001660             0.000033     0.000272             0.000152   \n",
       "50%        0.004238             0.000046     0.000438             0.000244   \n",
       "60%        0.015996             0.000085     0.000755             0.000513   \n",
       "70%        0.091257             0.000209     0.001610             0.001241   \n",
       "80%        0.488582             0.000820     0.005910             0.003262   \n",
       "90%        0.927456             0.007909     0.658297             0.010893   \n",
       "95%        0.976718             0.029604     0.911508             0.031883   \n",
       "99%        0.994160             0.127040     0.977242             0.404110   \n",
       "max        0.999047             0.672039     0.993243             0.965869   \n",
       "\n",
       "        dtm_insult   dtm_threat  dtm_sexual_explicit  syllables_per_word  \\\n",
       "count  5710.000000  5710.000000          5710.000000         5710.000000   \n",
       "mean      0.083620     0.014731             0.044624            1.293951   \n",
       "std       0.215015     0.078795             0.155257            0.195812   \n",
       "min       0.000095     0.000014             0.000012            0.800000   \n",
       "1%        0.000149     0.000021             0.000017            0.857143   \n",
       "5%        0.000177     0.000027             0.000020            1.000000   \n",
       "10%       0.000200     0.000031             0.000022            1.050000   \n",
       "20%       0.000247     0.000037             0.000026            1.137931   \n",
       "30%       0.000326     0.000046             0.000032            1.193548   \n",
       "40%       0.000511     0.000065             0.000044            1.245283   \n",
       "50%       0.001041     0.000123             0.000090            1.287618   \n",
       "60%       0.002461     0.000309             0.000239            1.333333   \n",
       "70%       0.007907     0.000952             0.000792            1.382353   \n",
       "80%       0.041335     0.002956             0.004626            1.442371   \n",
       "90%       0.306216     0.010762             0.079575            1.533957   \n",
       "95%       0.686739     0.036829             0.330517            1.622100   \n",
       "99%       0.969594     0.472689             0.890709            1.824868   \n",
       "max       0.994790     0.962406             0.982923            2.500000   \n",
       "\n",
       "       syllables_per_sent  words_per_sent  flesch_reading_ease  \\\n",
       "count         5710.000000     5710.000000          5710.000000   \n",
       "mean            13.776946       10.047346            75.315521   \n",
       "std              8.243071        5.753373            19.910217   \n",
       "min              2.000000        1.500000           -48.980000   \n",
       "1%               3.000000        2.500000            20.040001   \n",
       "5%               4.000000        3.000000            42.040001   \n",
       "10%              5.000000        3.666667            50.509998   \n",
       "20%              6.500000        5.000000            60.139999   \n",
       "30%              8.500000        6.333333            66.739998   \n",
       "40%             10.000000        7.500000            72.160004   \n",
       "50%             12.250000        9.000000            76.220001   \n",
       "60%             14.500000       10.500000            80.959999   \n",
       "70%             16.799999       12.250000            85.690002   \n",
       "80%             20.000000       14.500000            91.110001   \n",
       "90%             24.755000       17.600000            99.570000   \n",
       "95%             29.000000       20.500000           105.660004   \n",
       "99%             39.000000       27.000000           116.150002   \n",
       "max             96.000000       65.000000           118.680000   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog   smog_index  \\\n",
       "count           5710.000000  5710.000000  5710.000000   \n",
       "mean               6.677233     8.998837     3.062960   \n",
       "std                4.433799     4.646113     4.695702   \n",
       "min               -2.500000     1.200000     0.000000   \n",
       "1%                -1.500000     2.000000     0.000000   \n",
       "5%                 0.500000     2.400000     0.000000   \n",
       "10%                1.700000     3.200000     0.000000   \n",
       "20%                3.100000     4.870000     0.000000   \n",
       "30%                4.300000     6.370000     0.000000   \n",
       "40%                5.200000     8.000000     0.000000   \n",
       "50%                6.400000     8.510000     0.000000   \n",
       "60%                7.200000     9.600000     0.000000   \n",
       "70%                8.400000    10.853000     6.000000   \n",
       "80%                9.900000    12.134000     8.800000   \n",
       "90%               12.000000    14.501000    10.700000   \n",
       "95%               14.200000    16.930000    12.000000   \n",
       "99%               20.373000    23.709999    14.300000   \n",
       "max               51.599998    55.520000    18.900000   \n",
       "\n",
       "       automated_readability_index  coleman_liau_index  linsear_write_formula  \\\n",
       "count                  5710.000000         5710.000000            5710.000000   \n",
       "mean                      7.479265            6.629302               8.560555   \n",
       "std                       5.569417            3.869099               5.905854   \n",
       "min                      -8.700000          -10.160000               0.500000   \n",
       "1%                       -3.000000           -2.928200               1.500000   \n",
       "5%                       -0.200000            0.329000               2.000000   \n",
       "10%                       1.290000            1.820000               2.666667   \n",
       "20%                       3.200000            3.700000               4.000000   \n",
       "30%                       4.600000            4.930000               5.000000   \n",
       "40%                       5.800000            5.900000               6.000000   \n",
       "50%                       7.000000            6.680000               7.000000   \n",
       "60%                       8.200000            7.474000               8.250000   \n",
       "70%                       9.400000            8.453000              10.666667   \n",
       "80%                      11.200000            9.520000              12.500000   \n",
       "90%                      13.800000           11.140000              15.625000   \n",
       "95%                      16.600000           12.615500              19.000000   \n",
       "99%                      24.799999           16.376399              29.455000   \n",
       "max                      64.900002           40.599998              66.000000   \n",
       "\n",
       "       dale_chall_readability_score  hb_bert_off  hb_bert_abu  \\\n",
       "count                   5710.000000  5710.000000  5710.000000   \n",
       "mean                       8.298417     0.332527     0.166042   \n",
       "std                        2.263760     0.331918     0.278423   \n",
       "min                        0.200000     0.008860     0.002739   \n",
       "1%                         0.350000     0.013618     0.003847   \n",
       "5%                         5.620000     0.021369     0.005177   \n",
       "10%                        6.240000     0.029108     0.006430   \n",
       "20%                        6.930000     0.045573     0.009145   \n",
       "30%                        7.380000     0.071743     0.012772   \n",
       "40%                        7.820000     0.109342     0.018211   \n",
       "50%                        8.200000     0.171859     0.027692   \n",
       "60%                        8.590000     0.282521     0.048030   \n",
       "70%                        9.120000     0.459815     0.097012   \n",
       "80%                        9.760000     0.719315     0.248265   \n",
       "90%                       10.750000     0.928643     0.709186   \n",
       "95%                       11.830000     0.960791     0.913868   \n",
       "99%                       14.606400     0.972489     0.967271   \n",
       "max                       24.990000     0.978723     0.977543   \n",
       "\n",
       "       hb_hatebert_off  hb_hatebert_abu  te_roberta_off  te_roberta_emo_anger  \\\n",
       "count      5710.000000      5710.000000     5710.000000           5710.000000   \n",
       "mean          0.329949         0.144240        0.350055              0.507478   \n",
       "std           0.284725         0.221207        0.251345              0.357471   \n",
       "min           0.007778         0.007624        0.022149              0.004901   \n",
       "1%            0.021895         0.010283        0.049784              0.011352   \n",
       "5%            0.036441         0.013695        0.074366              0.024138   \n",
       "10%           0.049935         0.016068        0.091998              0.040597   \n",
       "20%           0.078535         0.020987        0.124509              0.091023   \n",
       "30%           0.112946         0.027233        0.161733              0.176001   \n",
       "40%           0.157483         0.035524        0.208334              0.321663   \n",
       "50%           0.218302         0.047660        0.265682              0.526801   \n",
       "60%           0.310856         0.067523        0.342524              0.714927   \n",
       "70%           0.439863         0.106683        0.449289              0.837082   \n",
       "80%           0.615395         0.190064        0.589677              0.911722   \n",
       "90%           0.823997         0.460149        0.784447              0.955451   \n",
       "95%           0.908639         0.738755        0.858253              0.968323   \n",
       "99%           0.957988         0.945889        0.913508              0.979008   \n",
       "max           0.979833         0.977078        0.950407              0.985018   \n",
       "\n",
       "       te_roberta_snt_neg  te_roberta_iro  te_xlm_roberta_snt_neg  \n",
       "count         5710.000000     5710.000000             5710.000000  \n",
       "mean             0.508562        0.313064                0.576870  \n",
       "std              0.319236        0.276420                0.301809  \n",
       "min              0.000799        0.014366                0.007853  \n",
       "1%               0.001795        0.022383                0.019069  \n",
       "5%               0.008893        0.034852                0.052166  \n",
       "10%              0.032693        0.046528                0.107149  \n",
       "20%              0.146773        0.071837                0.242166  \n",
       "30%              0.295404        0.102690                0.384754  \n",
       "40%              0.416598        0.144715                0.515363  \n",
       "50%              0.535722        0.200425                0.644186  \n",
       "60%              0.652219        0.290468                0.752811  \n",
       "70%              0.758305        0.415063                0.831708  \n",
       "80%              0.846273        0.583751                0.885076  \n",
       "90%              0.921544        0.785951                0.921948  \n",
       "95%              0.953920        0.885475                0.938447  \n",
       "99%              0.973875        0.960554                0.955456  \n",
       "max              0.982809        0.990079                0.966720  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"label\", \"bws\", \"worker\"]\n",
    "cols += char_fs + dtfy_fs\n",
    "cols += list(textstat_fns.keys())\n",
    "cols += list(conf.hatebert_models.keys()) \n",
    "cols += list(conf.tweeteval_models.keys()) \n",
    "df[cols].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bddf8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 433 columns):\n",
      " #    Column                        Non-Null Count  Dtype  \n",
      "---   ------                        --------------  -----  \n",
      " 0    label                         5710 non-null   int32  \n",
      " 1    bws                           5710 non-null   float32\n",
      " 2    worker                        5710 non-null   int8   \n",
      " 3    length                        5710 non-null   int16  \n",
      " 4    digit_frac                    5710 non-null   float32\n",
      " 5    letter_frac                   5710 non-null   float32\n",
      " 6    space_frac                    5710 non-null   float32\n",
      " 7    punc_frac                     5710 non-null   float32\n",
      " 8    upper_frac                    5710 non-null   float32\n",
      " 9    dto_toxicity                  5710 non-null   float32\n",
      " 10   dto_severe_toxicity           5710 non-null   float32\n",
      " 11   dto_obscene                   5710 non-null   float32\n",
      " 12   dto_threat                    5710 non-null   float32\n",
      " 13   dto_insult                    5710 non-null   float32\n",
      " 14   dto_identity_attack           5710 non-null   float32\n",
      " 15   dtu_toxicity                  5710 non-null   float32\n",
      " 16   dtu_severe_toxicity           5710 non-null   float32\n",
      " 17   dtu_obscene                   5710 non-null   float32\n",
      " 18   dtu_identity_attack           5710 non-null   float32\n",
      " 19   dtu_insult                    5710 non-null   float32\n",
      " 20   dtu_threat                    5710 non-null   float32\n",
      " 21   dtu_sexual_explicit           5710 non-null   float32\n",
      " 22   dtm_toxicity                  5710 non-null   float32\n",
      " 23   dtm_severe_toxicity           5710 non-null   float32\n",
      " 24   dtm_obscene                   5710 non-null   float32\n",
      " 25   dtm_identity_attack           5710 non-null   float32\n",
      " 26   dtm_insult                    5710 non-null   float32\n",
      " 27   dtm_threat                    5710 non-null   float32\n",
      " 28   dtm_sexual_explicit           5710 non-null   float32\n",
      " 29   syllables_per_word            5710 non-null   float32\n",
      " 30   syllables_per_sent            5710 non-null   float32\n",
      " 31   words_per_sent                5710 non-null   float32\n",
      " 32   flesch_reading_ease           5710 non-null   float32\n",
      " 33   flesch_kincaid_grade          5710 non-null   float32\n",
      " 34   gunning_fog                   5710 non-null   float32\n",
      " 35   smog_index                    5710 non-null   float32\n",
      " 36   automated_readability_index   5710 non-null   float32\n",
      " 37   coleman_liau_index            5710 non-null   float32\n",
      " 38   linsear_write_formula         5710 non-null   float32\n",
      " 39   dale_chall_readability_score  5710 non-null   float32\n",
      " 40   hb_bert_off                   5710 non-null   float32\n",
      " 41   hb_bert_abu                   5710 non-null   float32\n",
      " 42   hb_hatebert_off               5710 non-null   float32\n",
      " 43   hb_hatebert_abu               5710 non-null   float32\n",
      " 44   te_roberta_off                5710 non-null   float32\n",
      " 45   te_roberta_emo_anger          5710 non-null   float32\n",
      " 46   te_roberta_snt_neg            5710 non-null   float32\n",
      " 47   te_roberta_iro                5710 non-null   float32\n",
      " 48   te_xlm_roberta_snt_neg        5710 non-null   float32\n",
      " 49   zz0000                        5710 non-null   float32\n",
      " 50   zz0001                        5710 non-null   float32\n",
      " 51   zz0002                        5710 non-null   float32\n",
      " 52   zz0003                        5710 non-null   float32\n",
      " 53   zz0004                        5710 non-null   float32\n",
      " 54   zz0005                        5710 non-null   float32\n",
      " 55   zz0006                        5710 non-null   float32\n",
      " 56   zz0007                        5710 non-null   float32\n",
      " 57   zz0008                        5710 non-null   float32\n",
      " 58   zz0009                        5710 non-null   float32\n",
      " 59   zz0010                        5710 non-null   float32\n",
      " 60   zz0011                        5710 non-null   float32\n",
      " 61   zz0012                        5710 non-null   float32\n",
      " 62   zz0013                        5710 non-null   float32\n",
      " 63   zz0014                        5710 non-null   float32\n",
      " 64   zz0015                        5710 non-null   float32\n",
      " 65   zz0016                        5710 non-null   float32\n",
      " 66   zz0017                        5710 non-null   float32\n",
      " 67   zz0018                        5710 non-null   float32\n",
      " 68   zz0019                        5710 non-null   float32\n",
      " 69   zz0020                        5710 non-null   float32\n",
      " 70   zz0021                        5710 non-null   float32\n",
      " 71   zz0022                        5710 non-null   float32\n",
      " 72   zz0023                        5710 non-null   float32\n",
      " 73   zz0024                        5710 non-null   float32\n",
      " 74   zz0025                        5710 non-null   float32\n",
      " 75   zz0026                        5710 non-null   float32\n",
      " 76   zz0027                        5710 non-null   float32\n",
      " 77   zz0028                        5710 non-null   float32\n",
      " 78   zz0029                        5710 non-null   float32\n",
      " 79   zz0030                        5710 non-null   float32\n",
      " 80   zz0031                        5710 non-null   float32\n",
      " 81   zz0032                        5710 non-null   float32\n",
      " 82   zz0033                        5710 non-null   float32\n",
      " 83   zz0034                        5710 non-null   float32\n",
      " 84   zz0035                        5710 non-null   float32\n",
      " 85   zz0036                        5710 non-null   float32\n",
      " 86   zz0037                        5710 non-null   float32\n",
      " 87   zz0038                        5710 non-null   float32\n",
      " 88   zz0039                        5710 non-null   float32\n",
      " 89   zz0040                        5710 non-null   float32\n",
      " 90   zz0041                        5710 non-null   float32\n",
      " 91   zz0042                        5710 non-null   float32\n",
      " 92   zz0043                        5710 non-null   float32\n",
      " 93   zz0044                        5710 non-null   float32\n",
      " 94   zz0045                        5710 non-null   float32\n",
      " 95   zz0046                        5710 non-null   float32\n",
      " 96   zz0047                        5710 non-null   float32\n",
      " 97   zz0048                        5710 non-null   float32\n",
      " 98   zz0049                        5710 non-null   float32\n",
      " 99   zz0050                        5710 non-null   float32\n",
      " 100  zz0051                        5710 non-null   float32\n",
      " 101  zz0052                        5710 non-null   float32\n",
      " 102  zz0053                        5710 non-null   float32\n",
      " 103  zz0054                        5710 non-null   float32\n",
      " 104  zz0055                        5710 non-null   float32\n",
      " 105  zz0056                        5710 non-null   float32\n",
      " 106  zz0057                        5710 non-null   float32\n",
      " 107  zz0058                        5710 non-null   float32\n",
      " 108  zz0059                        5710 non-null   float32\n",
      " 109  zz0060                        5710 non-null   float32\n",
      " 110  zz0061                        5710 non-null   float32\n",
      " 111  zz0062                        5710 non-null   float32\n",
      " 112  zz0063                        5710 non-null   float32\n",
      " 113  zz0064                        5710 non-null   float32\n",
      " 114  zz0065                        5710 non-null   float32\n",
      " 115  zz0066                        5710 non-null   float32\n",
      " 116  zz0067                        5710 non-null   float32\n",
      " 117  zz0068                        5710 non-null   float32\n",
      " 118  zz0069                        5710 non-null   float32\n",
      " 119  zz0070                        5710 non-null   float32\n",
      " 120  zz0071                        5710 non-null   float32\n",
      " 121  zz0072                        5710 non-null   float32\n",
      " 122  zz0073                        5710 non-null   float32\n",
      " 123  zz0074                        5710 non-null   float32\n",
      " 124  zz0075                        5710 non-null   float32\n",
      " 125  zz0076                        5710 non-null   float32\n",
      " 126  zz0077                        5710 non-null   float32\n",
      " 127  zz0078                        5710 non-null   float32\n",
      " 128  zz0079                        5710 non-null   float32\n",
      " 129  zz0080                        5710 non-null   float32\n",
      " 130  zz0081                        5710 non-null   float32\n",
      " 131  zz0082                        5710 non-null   float32\n",
      " 132  zz0083                        5710 non-null   float32\n",
      " 133  zz0084                        5710 non-null   float32\n",
      " 134  zz0085                        5710 non-null   float32\n",
      " 135  zz0086                        5710 non-null   float32\n",
      " 136  zz0087                        5710 non-null   float32\n",
      " 137  zz0088                        5710 non-null   float32\n",
      " 138  zz0089                        5710 non-null   float32\n",
      " 139  zz0090                        5710 non-null   float32\n",
      " 140  zz0091                        5710 non-null   float32\n",
      " 141  zz0092                        5710 non-null   float32\n",
      " 142  zz0093                        5710 non-null   float32\n",
      " 143  zz0094                        5710 non-null   float32\n",
      " 144  zz0095                        5710 non-null   float32\n",
      " 145  zz0096                        5710 non-null   float32\n",
      " 146  zz0097                        5710 non-null   float32\n",
      " 147  zz0098                        5710 non-null   float32\n",
      " 148  zz0099                        5710 non-null   float32\n",
      " 149  zz0100                        5710 non-null   float32\n",
      " 150  zz0101                        5710 non-null   float32\n",
      " 151  zz0102                        5710 non-null   float32\n",
      " 152  zz0103                        5710 non-null   float32\n",
      " 153  zz0104                        5710 non-null   float32\n",
      " 154  zz0105                        5710 non-null   float32\n",
      " 155  zz0106                        5710 non-null   float32\n",
      " 156  zz0107                        5710 non-null   float32\n",
      " 157  zz0108                        5710 non-null   float32\n",
      " 158  zz0109                        5710 non-null   float32\n",
      " 159  zz0110                        5710 non-null   float32\n",
      " 160  zz0111                        5710 non-null   float32\n",
      " 161  zz0112                        5710 non-null   float32\n",
      " 162  zz0113                        5710 non-null   float32\n",
      " 163  zz0114                        5710 non-null   float32\n",
      " 164  zz0115                        5710 non-null   float32\n",
      " 165  zz0116                        5710 non-null   float32\n",
      " 166  zz0117                        5710 non-null   float32\n",
      " 167  zz0118                        5710 non-null   float32\n",
      " 168  zz0119                        5710 non-null   float32\n",
      " 169  zz0120                        5710 non-null   float32\n",
      " 170  zz0121                        5710 non-null   float32\n",
      " 171  zz0122                        5710 non-null   float32\n",
      " 172  zz0123                        5710 non-null   float32\n",
      " 173  zz0124                        5710 non-null   float32\n",
      " 174  zz0125                        5710 non-null   float32\n",
      " 175  zz0126                        5710 non-null   float32\n",
      " 176  zz0127                        5710 non-null   float32\n",
      " 177  zz0128                        5710 non-null   float32\n",
      " 178  zz0129                        5710 non-null   float32\n",
      " 179  zz0130                        5710 non-null   float32\n",
      " 180  zz0131                        5710 non-null   float32\n",
      " 181  zz0132                        5710 non-null   float32\n",
      " 182  zz0133                        5710 non-null   float32\n",
      " 183  zz0134                        5710 non-null   float32\n",
      " 184  zz0135                        5710 non-null   float32\n",
      " 185  zz0136                        5710 non-null   float32\n",
      " 186  zz0137                        5710 non-null   float32\n",
      " 187  zz0138                        5710 non-null   float32\n",
      " 188  zz0139                        5710 non-null   float32\n",
      " 189  zz0140                        5710 non-null   float32\n",
      " 190  zz0141                        5710 non-null   float32\n",
      " 191  zz0142                        5710 non-null   float32\n",
      " 192  zz0143                        5710 non-null   float32\n",
      " 193  zz0144                        5710 non-null   float32\n",
      " 194  zz0145                        5710 non-null   float32\n",
      " 195  zz0146                        5710 non-null   float32\n",
      " 196  zz0147                        5710 non-null   float32\n",
      " 197  zz0148                        5710 non-null   float32\n",
      " 198  zz0149                        5710 non-null   float32\n",
      " 199  zz0150                        5710 non-null   float32\n",
      " 200  zz0151                        5710 non-null   float32\n",
      " 201  zz0152                        5710 non-null   float32\n",
      " 202  zz0153                        5710 non-null   float32\n",
      " 203  zz0154                        5710 non-null   float32\n",
      " 204  zz0155                        5710 non-null   float32\n",
      " 205  zz0156                        5710 non-null   float32\n",
      " 206  zz0157                        5710 non-null   float32\n",
      " 207  zz0158                        5710 non-null   float32\n",
      " 208  zz0159                        5710 non-null   float32\n",
      " 209  zz0160                        5710 non-null   float32\n",
      " 210  zz0161                        5710 non-null   float32\n",
      " 211  zz0162                        5710 non-null   float32\n",
      " 212  zz0163                        5710 non-null   float32\n",
      " 213  zz0164                        5710 non-null   float32\n",
      " 214  zz0165                        5710 non-null   float32\n",
      " 215  zz0166                        5710 non-null   float32\n",
      " 216  zz0167                        5710 non-null   float32\n",
      " 217  zz0168                        5710 non-null   float32\n",
      " 218  zz0169                        5710 non-null   float32\n",
      " 219  zz0170                        5710 non-null   float32\n",
      " 220  zz0171                        5710 non-null   float32\n",
      " 221  zz0172                        5710 non-null   float32\n",
      " 222  zz0173                        5710 non-null   float32\n",
      " 223  zz0174                        5710 non-null   float32\n",
      " 224  zz0175                        5710 non-null   float32\n",
      " 225  zz0176                        5710 non-null   float32\n",
      " 226  zz0177                        5710 non-null   float32\n",
      " 227  zz0178                        5710 non-null   float32\n",
      " 228  zz0179                        5710 non-null   float32\n",
      " 229  zz0180                        5710 non-null   float32\n",
      " 230  zz0181                        5710 non-null   float32\n",
      " 231  zz0182                        5710 non-null   float32\n",
      " 232  zz0183                        5710 non-null   float32\n",
      " 233  zz0184                        5710 non-null   float32\n",
      " 234  zz0185                        5710 non-null   float32\n",
      " 235  zz0186                        5710 non-null   float32\n",
      " 236  zz0187                        5710 non-null   float32\n",
      " 237  zz0188                        5710 non-null   float32\n",
      " 238  zz0189                        5710 non-null   float32\n",
      " 239  zz0190                        5710 non-null   float32\n",
      " 240  zz0191                        5710 non-null   float32\n",
      " 241  zz0192                        5710 non-null   float32\n",
      " 242  zz0193                        5710 non-null   float32\n",
      " 243  zz0194                        5710 non-null   float32\n",
      " 244  zz0195                        5710 non-null   float32\n",
      " 245  zz0196                        5710 non-null   float32\n",
      " 246  zz0197                        5710 non-null   float32\n",
      " 247  zz0198                        5710 non-null   float32\n",
      " 248  zz0199                        5710 non-null   float32\n",
      " 249  zz0200                        5710 non-null   float32\n",
      " 250  zz0201                        5710 non-null   float32\n",
      " 251  zz0202                        5710 non-null   float32\n",
      " 252  zz0203                        5710 non-null   float32\n",
      " 253  zz0204                        5710 non-null   float32\n",
      " 254  zz0205                        5710 non-null   float32\n",
      " 255  zz0206                        5710 non-null   float32\n",
      " 256  zz0207                        5710 non-null   float32\n",
      " 257  zz0208                        5710 non-null   float32\n",
      " 258  zz0209                        5710 non-null   float32\n",
      " 259  zz0210                        5710 non-null   float32\n",
      " 260  zz0211                        5710 non-null   float32\n",
      " 261  zz0212                        5710 non-null   float32\n",
      " 262  zz0213                        5710 non-null   float32\n",
      " 263  zz0214                        5710 non-null   float32\n",
      " 264  zz0215                        5710 non-null   float32\n",
      " 265  zz0216                        5710 non-null   float32\n",
      " 266  zz0217                        5710 non-null   float32\n",
      " 267  zz0218                        5710 non-null   float32\n",
      " 268  zz0219                        5710 non-null   float32\n",
      " 269  zz0220                        5710 non-null   float32\n",
      " 270  zz0221                        5710 non-null   float32\n",
      " 271  zz0222                        5710 non-null   float32\n",
      " 272  zz0223                        5710 non-null   float32\n",
      " 273  zz0224                        5710 non-null   float32\n",
      " 274  zz0225                        5710 non-null   float32\n",
      " 275  zz0226                        5710 non-null   float32\n",
      " 276  zz0227                        5710 non-null   float32\n",
      " 277  zz0228                        5710 non-null   float32\n",
      " 278  zz0229                        5710 non-null   float32\n",
      " 279  zz0230                        5710 non-null   float32\n",
      " 280  zz0231                        5710 non-null   float32\n",
      " 281  zz0232                        5710 non-null   float32\n",
      " 282  zz0233                        5710 non-null   float32\n",
      " 283  zz0234                        5710 non-null   float32\n",
      " 284  zz0235                        5710 non-null   float32\n",
      " 285  zz0236                        5710 non-null   float32\n",
      " 286  zz0237                        5710 non-null   float32\n",
      " 287  zz0238                        5710 non-null   float32\n",
      " 288  zz0239                        5710 non-null   float32\n",
      " 289  zz0240                        5710 non-null   float32\n",
      " 290  zz0241                        5710 non-null   float32\n",
      " 291  zz0242                        5710 non-null   float32\n",
      " 292  zz0243                        5710 non-null   float32\n",
      " 293  zz0244                        5710 non-null   float32\n",
      " 294  zz0245                        5710 non-null   float32\n",
      " 295  zz0246                        5710 non-null   float32\n",
      " 296  zz0247                        5710 non-null   float32\n",
      " 297  zz0248                        5710 non-null   float32\n",
      " 298  zz0249                        5710 non-null   float32\n",
      " 299  zz0250                        5710 non-null   float32\n",
      " 300  zz0251                        5710 non-null   float32\n",
      " 301  zz0252                        5710 non-null   float32\n",
      " 302  zz0253                        5710 non-null   float32\n",
      " 303  zz0254                        5710 non-null   float32\n",
      " 304  zz0255                        5710 non-null   float32\n",
      " 305  zz0256                        5710 non-null   float32\n",
      " 306  zz0257                        5710 non-null   float32\n",
      " 307  zz0258                        5710 non-null   float32\n",
      " 308  zz0259                        5710 non-null   float32\n",
      " 309  zz0260                        5710 non-null   float32\n",
      " 310  zz0261                        5710 non-null   float32\n",
      " 311  zz0262                        5710 non-null   float32\n",
      " 312  zz0263                        5710 non-null   float32\n",
      " 313  zz0264                        5710 non-null   float32\n",
      " 314  zz0265                        5710 non-null   float32\n",
      " 315  zz0266                        5710 non-null   float32\n",
      " 316  zz0267                        5710 non-null   float32\n",
      " 317  zz0268                        5710 non-null   float32\n",
      " 318  zz0269                        5710 non-null   float32\n",
      " 319  zz0270                        5710 non-null   float32\n",
      " 320  zz0271                        5710 non-null   float32\n",
      " 321  zz0272                        5710 non-null   float32\n",
      " 322  zz0273                        5710 non-null   float32\n",
      " 323  zz0274                        5710 non-null   float32\n",
      " 324  zz0275                        5710 non-null   float32\n",
      " 325  zz0276                        5710 non-null   float32\n",
      " 326  zz0277                        5710 non-null   float32\n",
      " 327  zz0278                        5710 non-null   float32\n",
      " 328  zz0279                        5710 non-null   float32\n",
      " 329  zz0280                        5710 non-null   float32\n",
      " 330  zz0281                        5710 non-null   float32\n",
      " 331  zz0282                        5710 non-null   float32\n",
      " 332  zz0283                        5710 non-null   float32\n",
      " 333  zz0284                        5710 non-null   float32\n",
      " 334  zz0285                        5710 non-null   float32\n",
      " 335  zz0286                        5710 non-null   float32\n",
      " 336  zz0287                        5710 non-null   float32\n",
      " 337  zz0288                        5710 non-null   float32\n",
      " 338  zz0289                        5710 non-null   float32\n",
      " 339  zz0290                        5710 non-null   float32\n",
      " 340  zz0291                        5710 non-null   float32\n",
      " 341  zz0292                        5710 non-null   float32\n",
      " 342  zz0293                        5710 non-null   float32\n",
      " 343  zz0294                        5710 non-null   float32\n",
      " 344  zz0295                        5710 non-null   float32\n",
      " 345  zz0296                        5710 non-null   float32\n",
      " 346  zz0297                        5710 non-null   float32\n",
      " 347  zz0298                        5710 non-null   float32\n",
      " 348  zz0299                        5710 non-null   float32\n",
      " 349  zz0300                        5710 non-null   float32\n",
      " 350  zz0301                        5710 non-null   float32\n",
      " 351  zz0302                        5710 non-null   float32\n",
      " 352  zz0303                        5710 non-null   float32\n",
      " 353  zz0304                        5710 non-null   float32\n",
      " 354  zz0305                        5710 non-null   float32\n",
      " 355  zz0306                        5710 non-null   float32\n",
      " 356  zz0307                        5710 non-null   float32\n",
      " 357  zz0308                        5710 non-null   float32\n",
      " 358  zz0309                        5710 non-null   float32\n",
      " 359  zz0310                        5710 non-null   float32\n",
      " 360  zz0311                        5710 non-null   float32\n",
      " 361  zz0312                        5710 non-null   float32\n",
      " 362  zz0313                        5710 non-null   float32\n",
      " 363  zz0314                        5710 non-null   float32\n",
      " 364  zz0315                        5710 non-null   float32\n",
      " 365  zz0316                        5710 non-null   float32\n",
      " 366  zz0317                        5710 non-null   float32\n",
      " 367  zz0318                        5710 non-null   float32\n",
      " 368  zz0319                        5710 non-null   float32\n",
      " 369  zz0320                        5710 non-null   float32\n",
      " 370  zz0321                        5710 non-null   float32\n",
      " 371  zz0322                        5710 non-null   float32\n",
      " 372  zz0323                        5710 non-null   float32\n",
      " 373  zz0324                        5710 non-null   float32\n",
      " 374  zz0325                        5710 non-null   float32\n",
      " 375  zz0326                        5710 non-null   float32\n",
      " 376  zz0327                        5710 non-null   float32\n",
      " 377  zz0328                        5710 non-null   float32\n",
      " 378  zz0329                        5710 non-null   float32\n",
      " 379  zz0330                        5710 non-null   float32\n",
      " 380  zz0331                        5710 non-null   float32\n",
      " 381  zz0332                        5710 non-null   float32\n",
      " 382  zz0333                        5710 non-null   float32\n",
      " 383  zz0334                        5710 non-null   float32\n",
      " 384  zz0335                        5710 non-null   float32\n",
      " 385  zz0336                        5710 non-null   float32\n",
      " 386  zz0337                        5710 non-null   float32\n",
      " 387  zz0338                        5710 non-null   float32\n",
      " 388  zz0339                        5710 non-null   float32\n",
      " 389  zz0340                        5710 non-null   float32\n",
      " 390  zz0341                        5710 non-null   float32\n",
      " 391  zz0342                        5710 non-null   float32\n",
      " 392  zz0343                        5710 non-null   float32\n",
      " 393  zz0344                        5710 non-null   float32\n",
      " 394  zz0345                        5710 non-null   float32\n",
      " 395  zz0346                        5710 non-null   float32\n",
      " 396  zz0347                        5710 non-null   float32\n",
      " 397  zz0348                        5710 non-null   float32\n",
      " 398  zz0349                        5710 non-null   float32\n",
      " 399  zz0350                        5710 non-null   float32\n",
      " 400  zz0351                        5710 non-null   float32\n",
      " 401  zz0352                        5710 non-null   float32\n",
      " 402  zz0353                        5710 non-null   float32\n",
      " 403  zz0354                        5710 non-null   float32\n",
      " 404  zz0355                        5710 non-null   float32\n",
      " 405  zz0356                        5710 non-null   float32\n",
      " 406  zz0357                        5710 non-null   float32\n",
      " 407  zz0358                        5710 non-null   float32\n",
      " 408  zz0359                        5710 non-null   float32\n",
      " 409  zz0360                        5710 non-null   float32\n",
      " 410  zz0361                        5710 non-null   float32\n",
      " 411  zz0362                        5710 non-null   float32\n",
      " 412  zz0363                        5710 non-null   float32\n",
      " 413  zz0364                        5710 non-null   float32\n",
      " 414  zz0365                        5710 non-null   float32\n",
      " 415  zz0366                        5710 non-null   float32\n",
      " 416  zz0367                        5710 non-null   float32\n",
      " 417  zz0368                        5710 non-null   float32\n",
      " 418  zz0369                        5710 non-null   float32\n",
      " 419  zz0370                        5710 non-null   float32\n",
      " 420  zz0371                        5710 non-null   float32\n",
      " 421  zz0372                        5710 non-null   float32\n",
      " 422  zz0373                        5710 non-null   float32\n",
      " 423  zz0374                        5710 non-null   float32\n",
      " 424  zz0375                        5710 non-null   float32\n",
      " 425  zz0376                        5710 non-null   float32\n",
      " 426  zz0377                        5710 non-null   float32\n",
      " 427  zz0378                        5710 non-null   float32\n",
      " 428  zz0379                        5710 non-null   float32\n",
      " 429  zz0380                        5710 non-null   float32\n",
      " 430  zz0381                        5710 non-null   float32\n",
      " 431  zz0382                        5710 non-null   float32\n",
      " 432  zz0383                        5710 non-null   float32\n",
      "dtypes: float32(430), int16(1), int32(1), int8(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "cols += em_cols\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b13fb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[cols].to_parquet(\"output/tra.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
