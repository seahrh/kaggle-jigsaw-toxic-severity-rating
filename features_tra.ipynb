{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b888a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import rankdata\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import textstat\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8f39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(device=device(type='cuda'), pretrained_dir='pretrained/', dtfy_model_max_length=512, dtfy_batch_size=256, dtfy_models={'dto_': 'pretrained/unitaryai/detoxify/toxic_original-c1212f89.ckpt', 'dtu_': 'pretrained/unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt', 'dtm_': 'pretrained/unitaryai/detoxify/multilingual_debiased-0b549669.ckpt'}, dtfy_configs={'dto_': 'pretrained/bert-base-uncased', 'dtu_': 'pretrained/roberta-base', 'dtm_': 'pretrained/xlm-roberta-base'}, tweeteval_model_max_length=512, tweeteval_batch_size=64, tweeteval_models={'te_roberta_off': 'pretrained/cardiffnlp/twitter-roberta-base-offensive', 'te_roberta_emo_anger': 'pretrained/cardiffnlp/twitter-roberta-base-emotion', 'te_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-roberta-base-sentiment', 'te_roberta_iro': 'pretrained/cardiffnlp/twitter-roberta-base-irony', 'te_xlm_roberta_snt_neg': 'pretrained/cardiffnlp/twitter-xlm-roberta-base-sentiment'}, tweeteval_label_index={'te_roberta_off': 1, 'te_roberta_emo_anger': 0, 'te_roberta_snt_neg': 0, 'te_roberta_iro': 1, 'te_xlm_roberta_snt_neg': 0}, hatebert_model_max_length=512, hatebert_batch_size=128, hatebert_models={'hb_bert_off': 'pretrained/hatebert/bert-offenseval', 'hb_bert_abu': 'pretrained/hatebert/bert-abuseval', 'hb_hatebert_off': 'pretrained/hatebert/hatebert-offenseval', 'hb_hatebert_abu': 'pretrained/hatebert/hatebert-abuseval'}, em_max_seq_length=128, em_batch_size=1000, em_models={'paraphrase-MiniLM-L6-v2': 'pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2'})\n",
      "NVIDIA GeForce GTX 1060 6GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "class Conf(NamedTuple):\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pretrained_dir: str = \"pretrained/\"\n",
    "    dtfy_model_max_length: int = 512\n",
    "    dtfy_batch_size: int = 256\n",
    "    dtfy_models: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_original-c1212f89.ckpt\",\n",
    "        \"dtu_\": f\"{pretrained_dir}unitaryai/detoxify/toxic_debiased-c7548aa0.ckpt\",\n",
    "        \"dtm_\": f\"{pretrained_dir}unitaryai/detoxify/multilingual_debiased-0b549669.ckpt\"\n",
    "    }\n",
    "    dtfy_configs: Dict[str, str] = {\n",
    "        \"dto_\": f\"{pretrained_dir}bert-base-uncased\",\n",
    "        \"dtu_\": f\"{pretrained_dir}roberta-base\",\n",
    "        \"dtm_\": f\"{pretrained_dir}xlm-roberta-base\"\n",
    "    }\n",
    "    tweeteval_model_max_length: int = 512\n",
    "    tweeteval_batch_size: int = 64\n",
    "    tweeteval_models: Dict[str, str] = {\n",
    "        \"te_roberta_off\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-offensive\",\n",
    "        \"te_roberta_emo_anger\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        \"te_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "        \"te_roberta_iro\": f\"{pretrained_dir}cardiffnlp/twitter-roberta-base-irony\",\n",
    "        \"te_xlm_roberta_snt_neg\": f\"{pretrained_dir}cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    }\n",
    "    tweeteval_label_index: Dict[str, int] = {\n",
    "        \"te_roberta_off\": 1,\n",
    "        \"te_roberta_emo_anger\": 0,\n",
    "        \"te_roberta_snt_neg\": 0,\n",
    "        \"te_roberta_iro\": 1,\n",
    "        \"te_xlm_roberta_snt_neg\": 0,\n",
    "    }\n",
    "    hatebert_model_max_length: int = 512\n",
    "    hatebert_batch_size: int = 128\n",
    "    hatebert_models: Dict[str, str] = {\n",
    "        \"hb_bert_off\": f\"{pretrained_dir}hatebert/bert-offenseval\",\n",
    "        \"hb_bert_abu\" : f\"{pretrained_dir}hatebert/bert-abuseval\",\n",
    "        \"hb_hatebert_off\": f\"{pretrained_dir}hatebert/hatebert-offenseval\",\n",
    "        \"hb_hatebert_abu\" : f\"{pretrained_dir}hatebert/hatebert-abuseval\",\n",
    "    }\n",
    "    em_max_seq_length: int = 128\n",
    "    em_batch_size: int = 1000\n",
    "    em_models: Dict[str, str] = {\n",
    "        \"paraphrase-MiniLM-L6-v2\": f\"{pretrained_dir}sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "    }\n",
    "        \n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "if conf.device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   5710 non-null   int32  \n",
      " 1   bws     5710 non-null   float32\n",
      " 2   worker  5710 non-null   int8   \n",
      " 3   text    5710 non-null   object \n",
      " 4   text1   5710 non-null   object \n",
      " 5   text2   5710 non-null   object \n",
      "dtypes: float32(1), int32(1), int8(1), object(3)\n",
      "memory usage: 184.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/pre_ruddit.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752d7ac",
   "metadata": {},
   "source": [
    "# Character level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71d6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col = \"length\"\n",
    "df[col] = df[\"text1\"].str.len()\n",
    "df[col] = df[col].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74a87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[\"text1\"])\n",
    "\n",
    "\n",
    "char_fns: Dict[str, Callable] = {\n",
    "    \"digit_frac\": digit_frac,\n",
    "    \"letter_frac\": letter_frac,\n",
    "    \"space_frac\": space_frac,\n",
    "    \"punc_frac\": punc_frac,\n",
    "    \"upper_frac\": upper_frac,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5f55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39379.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 38574.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39652.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punc_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 35025.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39379.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in char_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d4202",
   "metadata": {},
   "source": [
    "# Textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[\"text1\"])\n",
    "\n",
    "\n",
    "def syllables_per_word(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"lexicon_count\"] + 1)\n",
    "\n",
    "\n",
    "def syllables_per_sent(row) -> float:\n",
    "    return row[\"syllable_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def words_per_sent(row) -> float:\n",
    "    return row[\"lexicon_count\"] / (row[\"sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[\"text1\"])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[\"text1\"])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[\"text1\"])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[\"text1\"])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[\"text1\"])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[\"text1\"])\n",
    "\n",
    "\n",
    "textstat_fns: Dict[str, Callable] = {\n",
    "    \"syllables_per_word\": syllables_per_word,\n",
    "    \"syllables_per_sent\": syllables_per_sent,\n",
    "    \"words_per_sent\": words_per_sent,\n",
    "    \"flesch_reading_ease\": flesch_reading_ease,\n",
    "    \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
    "    \"gunning_fog\": gunning_fog,\n",
    "    \"smog_index\": smog_index,\n",
    "    \"automated_readability_index\": automated_readability_index,\n",
    "    \"coleman_liau_index\": coleman_liau_index,\n",
    "    \"linsear_write_formula\": linsear_write_formula,\n",
    "    \"dale_chall_readability_score\": dale_chall_readability_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d91172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 7893.61it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"syllable_count\"\n",
    "df[col] = df.progress_apply(syllable_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc45e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 62067.30it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"lexicon_count\"\n",
    "df[col] = df.progress_apply(lexicon_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 39372.26it/s]\n"
     ]
    }
   ],
   "source": [
    "col = \"sentence_count\"\n",
    "df[col] = df.progress_apply(sentence_count, axis=1)\n",
    "df[col] = df[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 89180.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syllables_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 83970.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 81571.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_reading_ease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12071.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch_kincaid_grade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 12426.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunning_fog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5710/5710 [00:00<00:00, 9898.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smog_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 15949.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automated_readability_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 27451.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coleman_liau_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 23595.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linsear_write_formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 11419.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dale_chall_readability_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 5710/5710 [00:00<00:00, 10214.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for col, fn in textstat_fns.items():\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285247d",
   "metadata": {},
   "source": [
    "# TweetEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:10<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9025, 0.0975],\n",
      "        [0.5804, 0.4196],\n",
      "        [0.6679, 0.3321],\n",
      "        [0.8045, 0.1955],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.7749, 0.2251],\n",
      "        [0.8272, 0.1728],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.7598, 0.2402],\n",
      "        [0.9035, 0.0965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_emo_anger torch.Size([5710, 4])\n",
      "logits[:10]=tensor([[0.0376, 0.0565, 0.8628, 0.0431],\n",
      "        [0.1369, 0.1012, 0.2558, 0.5061],\n",
      "        [0.8166, 0.0105, 0.0391, 0.1338],\n",
      "        [0.9419, 0.0041, 0.0231, 0.0308],\n",
      "        [0.6140, 0.0225, 0.1561, 0.2074],\n",
      "        [0.8744, 0.0085, 0.0585, 0.0586],\n",
      "        [0.8556, 0.0071, 0.0948, 0.0425],\n",
      "        [0.8475, 0.0155, 0.0260, 0.1111],\n",
      "        [0.8054, 0.0086, 0.0704, 0.1156],\n",
      "        [0.1417, 0.3192, 0.3703, 0.1687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.0407, 0.7561, 0.2032],\n",
      "        [0.4268, 0.5488, 0.0244],\n",
      "        [0.7662, 0.2259, 0.0080],\n",
      "        [0.6066, 0.3729, 0.0206],\n",
      "        [0.5169, 0.4232, 0.0599],\n",
      "        [0.5795, 0.3848, 0.0357],\n",
      "        [0.3226, 0.6394, 0.0380],\n",
      "        [0.7787, 0.2147, 0.0066],\n",
      "        [0.7998, 0.1863, 0.0139],\n",
      "        [0.1055, 0.6091, 0.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_roberta_iro torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.7999, 0.2001],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.3392, 0.6608],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.8869, 0.1131],\n",
      "        [0.4666, 0.5334],\n",
      "        [0.7453, 0.2547],\n",
      "        [0.0874, 0.9126],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.6555, 0.3445]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 90/90 [04:12<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te_xlm_roberta_snt_neg torch.Size([5710, 3])\n",
      "logits[:10]=tensor([[0.1049, 0.7652, 0.1299],\n",
      "        [0.1865, 0.7562, 0.0573],\n",
      "        [0.4178, 0.4738, 0.1084],\n",
      "        [0.7074, 0.2630, 0.0296],\n",
      "        [0.8242, 0.1541, 0.0217],\n",
      "        [0.5170, 0.4337, 0.0493],\n",
      "        [0.5321, 0.4271, 0.0408],\n",
      "        [0.5248, 0.4357, 0.0396],\n",
      "        [0.9013, 0.0858, 0.0129],\n",
      "        [0.3988, 0.4830, 0.1182]])\n"
     ]
    }
   ],
   "source": [
    "sentences = list(df[\"text2\"])\n",
    "for col, model_dir in conf.tweeteval_models.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir, \n",
    "        model_max_length=conf.tweeteval_model_max_length\n",
    "    )\n",
    "    #print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")\n",
    "    x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "    batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.tweeteval_batch_size, shuffle=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,conf.tweeteval_label_index[col]]\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "    del tokenizer, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e694b",
   "metadata": {},
   "source": [
    "# HateBert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/hatebert/hatebert-offenseval', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "model_input_names=['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# all Hatebert models use the same tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    conf.hatebert_models[\"hb_hatebert_off\"], \n",
    "    model_max_length=conf.hatebert_model_max_length\n",
    ")\n",
    "print(f\"{repr(tokenizer)}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e71aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=5710\n",
      "Wall time: 988 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = tokenizer(sentences, truncation=True, padding=\"max_length\")\n",
    "print(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baba8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:10<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9598, 0.0402],\n",
      "        [0.7718, 0.2282],\n",
      "        [0.7567, 0.2433],\n",
      "        [0.9064, 0.0936],\n",
      "        [0.8356, 0.1644],\n",
      "        [0.7731, 0.2269],\n",
      "        [0.5952, 0.4048],\n",
      "        [0.8502, 0.1498],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9258, 0.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:10<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_bert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9910, 0.0090],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9631, 0.0369],\n",
      "        [0.9727, 0.0273],\n",
      "        [0.8744, 0.1256],\n",
      "        [0.9001, 0.0999],\n",
      "        [0.8544, 0.1456],\n",
      "        [0.8708, 0.1292],\n",
      "        [0.9881, 0.0119]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_off torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9377, 0.0623],\n",
      "        [0.5526, 0.4474],\n",
      "        [0.7553, 0.2447],\n",
      "        [0.7828, 0.2172],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9279, 0.0721],\n",
      "        [0.8304, 0.1696],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8965, 0.1035]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 45/45 [04:08<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_hatebert_abu torch.Size([5710, 2])\n",
      "logits[:10]=tensor([[0.9846, 0.0154],\n",
      "        [0.9717, 0.0283],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9699, 0.0301],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.9775, 0.0225],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9733, 0.0267],\n",
      "        [0.9407, 0.0593],\n",
      "        [0.9795, 0.0205]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=conf.hatebert_batch_size, shuffle=False)\n",
    "for col, model_dir in conf.hatebert_models.items():    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    model.to(conf.device)\n",
    "    logits = None\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(batches):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(conf.device)\n",
    "            outputs = model(**batch)\n",
    "            tmp = outputs.logits.detach().cpu()\n",
    "            if logits is None:\n",
    "                logits = tmp\n",
    "            else:\n",
    "                logits = torch.cat((logits, tmp), 0)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "    print(f\"{col} {logits.size()}\\nlogits[:10]={logits[:10]}\")\n",
    "    df[col] = logits[:,1]\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f069f2",
   "metadata": {},
   "source": [
    "# Detoxify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a45a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 3/3 [03:59<00:00, 79.96s/it]\n"
     ]
    }
   ],
   "source": [
    "dtfy_fs = []\n",
    "for prefix, checkpoint in tqdm(conf.dtfy_models.items()):\n",
    "    res = mylib.detoxify_labels(\n",
    "        sentences,\n",
    "        checkpoint=checkpoint,\n",
    "        config_dir=conf.dtfy_configs[prefix],\n",
    "        model_max_length=conf.dtfy_model_max_length,\n",
    "        device=conf.device,\n",
    "        batch_size=conf.dtfy_batch_size\n",
    "    )\n",
    "    for k, v in res.items():\n",
    "        col = prefix + k\n",
    "        df[col] = v\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        dtfy_fs.append(col)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6312beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dto_toxicity', 'dto_severe_toxicity', 'dto_obscene', 'dto_threat', 'dto_insult', 'dto_identity_attack', 'dtu_toxicity', 'dtu_severe_toxicity', 'dtu_obscene', 'dtu_identity_attack', 'dtu_insult', 'dtu_threat', 'dtu_sexual_explicit', 'dtm_toxicity', 'dtm_severe_toxicity', 'dtm_obscene', 'dtm_identity_attack', 'dtm_insult', 'dtm_threat', 'dtm_sexual_explicit']\n"
     ]
    }
   ],
   "source": [
    "print(dtfy_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e5b5d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d1f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|SentenceTransformer.py:60] 2022-01-09 11:44:11,328 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "[INFO|SentenceTransformer.py:60] 2022-01-09 11:44:11,328 >> Load pretrained SentenceTransformer: pretrained/sentence-transformers/paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57ca935a0e24f8d9ee0bdd91fc27f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em.shape=(5710, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(conf.em_models[\"paraphrase-MiniLM-L6-v2\"], device=conf.device)\n",
    "model.max_seq_length = conf.em_max_seq_length\n",
    "em = model.encode(sentences=sentences, batch_size=conf.em_batch_size, show_progress_bar=True, convert_to_numpy=True)\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73bdd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\dev\\seahrh\\kaggle-jigsaw-toxic-severity-rating\\env\\lib\\site-packages\\pandas\\core\\frame.py:3673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 242 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "em_size = em.shape[1]\n",
    "em_cols = [f\"zz{i:04d}\" for i in range(em_size)]\n",
    "df[em_cols] = em\n",
    "df[em_cols] = df[em_cols].astype(np.float32)\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335287",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15b1d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bws</th>\n",
       "      <th>worker</th>\n",
       "      <th>length</th>\n",
       "      <th>digit_frac</th>\n",
       "      <th>letter_frac</th>\n",
       "      <th>space_frac</th>\n",
       "      <th>punc_frac</th>\n",
       "      <th>upper_frac</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>syllables_per_sent</th>\n",
       "      <th>words_per_sent</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>dto_toxicity</th>\n",
       "      <th>dto_severe_toxicity</th>\n",
       "      <th>dto_obscene</th>\n",
       "      <th>dto_threat</th>\n",
       "      <th>dto_insult</th>\n",
       "      <th>dto_identity_attack</th>\n",
       "      <th>dtu_toxicity</th>\n",
       "      <th>dtu_severe_toxicity</th>\n",
       "      <th>dtu_obscene</th>\n",
       "      <th>dtu_identity_attack</th>\n",
       "      <th>dtu_insult</th>\n",
       "      <th>dtu_threat</th>\n",
       "      <th>dtu_sexual_explicit</th>\n",
       "      <th>dtm_toxicity</th>\n",
       "      <th>dtm_severe_toxicity</th>\n",
       "      <th>dtm_obscene</th>\n",
       "      <th>dtm_identity_attack</th>\n",
       "      <th>dtm_insult</th>\n",
       "      <th>dtm_threat</th>\n",
       "      <th>dtm_sexual_explicit</th>\n",
       "      <th>hb_bert_off</th>\n",
       "      <th>hb_bert_abu</th>\n",
       "      <th>hb_hatebert_off</th>\n",
       "      <th>hb_hatebert_abu</th>\n",
       "      <th>te_roberta_off</th>\n",
       "      <th>te_roberta_emo_anger</th>\n",
       "      <th>te_roberta_snt_neg</th>\n",
       "      <th>te_roberta_iro</th>\n",
       "      <th>te_xlm_roberta_snt_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5.710000e+03</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>5710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.027706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.434501</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.787127</td>\n",
       "      <td>0.173322</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>1.306213</td>\n",
       "      <td>13.194283</td>\n",
       "      <td>9.516296</td>\n",
       "      <td>75.075684</td>\n",
       "      <td>6.465289</td>\n",
       "      <td>8.678009</td>\n",
       "      <td>3.174711</td>\n",
       "      <td>7.575517</td>\n",
       "      <td>7.008681</td>\n",
       "      <td>7.984055</td>\n",
       "      <td>8.397984</td>\n",
       "      <td>0.178017</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.116018</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.058905</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.198142</td>\n",
       "      <td>4.805578e-03</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.082434</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.205323</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.108231</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.084179</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>0.047063</td>\n",
       "      <td>0.334793</td>\n",
       "      <td>0.167132</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>0.143653</td>\n",
       "      <td>0.348313</td>\n",
       "      <td>0.503608</td>\n",
       "      <td>0.505888</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.579380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1648.47935</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.036190</td>\n",
       "      <td>0.012874</td>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.025652</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>0.199887</td>\n",
       "      <td>7.814633</td>\n",
       "      <td>5.374849</td>\n",
       "      <td>19.881145</td>\n",
       "      <td>4.232607</td>\n",
       "      <td>4.458600</td>\n",
       "      <td>4.696062</td>\n",
       "      <td>5.256020</td>\n",
       "      <td>3.881966</td>\n",
       "      <td>5.502464</td>\n",
       "      <td>2.272001</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>0.285371</td>\n",
       "      <td>0.055856</td>\n",
       "      <td>0.173173</td>\n",
       "      <td>0.063640</td>\n",
       "      <td>0.344199</td>\n",
       "      <td>2.266139e-02</td>\n",
       "      <td>0.288667</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>0.208794</td>\n",
       "      <td>0.069327</td>\n",
       "      <td>0.153310</td>\n",
       "      <td>0.347693</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.276257</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.215207</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.161288</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>0.279580</td>\n",
       "      <td>0.284592</td>\n",
       "      <td>0.220860</td>\n",
       "      <td>0.251150</td>\n",
       "      <td>0.358048</td>\n",
       "      <td>0.319222</td>\n",
       "      <td>0.273608</td>\n",
       "      <td>0.300933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-48.980000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.800000</td>\n",
       "      <td>-10.160000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.529070e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.007853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>58.09000</td>\n",
       "      <td>-0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>19.439399</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>-2.680100</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>1.083922e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.021539</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>0.049472</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.022383</td>\n",
       "      <td>0.019090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>286.45000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729363</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.606500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.689000</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>1.200621e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.021235</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.036289</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.073940</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>0.053520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>571.90000</td>\n",
       "      <td>-0.426000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747601</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>50.680001</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.258000</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1.270202e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.028724</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.049613</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.091332</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.112013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>1142.80000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.158407</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>60.296001</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>7.010000</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1.407515e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.045517</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.078329</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.123751</td>\n",
       "      <td>0.087335</td>\n",
       "      <td>0.142043</td>\n",
       "      <td>0.071495</td>\n",
       "      <td>0.245301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>1713.70000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.165022</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>1.205374</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>66.440002</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.277000</td>\n",
       "      <td>4.632954</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>1.639610e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.071203</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.112309</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.161146</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.289854</td>\n",
       "      <td>0.101327</td>\n",
       "      <td>0.388927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>2284.60000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.170004</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>1.251515</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>2.270376e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.109697</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>0.156718</td>\n",
       "      <td>0.035112</td>\n",
       "      <td>0.206264</td>\n",
       "      <td>0.316501</td>\n",
       "      <td>0.412298</td>\n",
       "      <td>0.142517</td>\n",
       "      <td>0.521514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2855.50000</td>\n",
       "      <td>-0.062000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>1.303030</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>8.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>4.237992e-06</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.215901</td>\n",
       "      <td>0.047124</td>\n",
       "      <td>0.263219</td>\n",
       "      <td>0.516670</td>\n",
       "      <td>0.532186</td>\n",
       "      <td>0.195142</td>\n",
       "      <td>0.647636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>3426.40000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797224</td>\n",
       "      <td>0.178964</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>1.344828</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.820000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>1.026577e-05</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.286969</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.309187</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.340614</td>\n",
       "      <td>0.707297</td>\n",
       "      <td>0.648439</td>\n",
       "      <td>0.282336</td>\n",
       "      <td>0.755627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>3997.30000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.183544</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.397009</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>85.389999</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.393000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>9.430000</td>\n",
       "      <td>8.833000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.190000</td>\n",
       "      <td>0.054273</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.079215</td>\n",
       "      <td>3.243160e-05</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.092651</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.469389</td>\n",
       "      <td>0.098105</td>\n",
       "      <td>0.438910</td>\n",
       "      <td>0.105317</td>\n",
       "      <td>0.446956</td>\n",
       "      <td>0.835034</td>\n",
       "      <td>0.755154</td>\n",
       "      <td>0.405658</td>\n",
       "      <td>0.832475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>4568.20000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811607</td>\n",
       "      <td>0.189336</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.040149</td>\n",
       "      <td>1.459459</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>90.769997</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>11.670000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>9.940000</td>\n",
       "      <td>11.806667</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>0.311318</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.014517</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.438595</td>\n",
       "      <td>1.825476e-04</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.503942</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.044463</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.731942</td>\n",
       "      <td>0.251565</td>\n",
       "      <td>0.613122</td>\n",
       "      <td>0.188452</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>0.910890</td>\n",
       "      <td>0.844584</td>\n",
       "      <td>0.570127</td>\n",
       "      <td>0.885213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5139.10000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453.100000</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>99.230003</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>0.890399</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.701841</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.166622</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.934102</td>\n",
       "      <td>4.849900e-03</td>\n",
       "      <td>0.759786</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.045876</td>\n",
       "      <td>0.932564</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.309165</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.086770</td>\n",
       "      <td>0.929209</td>\n",
       "      <td>0.716078</td>\n",
       "      <td>0.822385</td>\n",
       "      <td>0.459093</td>\n",
       "      <td>0.785050</td>\n",
       "      <td>0.955080</td>\n",
       "      <td>0.920020</td>\n",
       "      <td>0.776994</td>\n",
       "      <td>0.921563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5424.55000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574.550000</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.075207</td>\n",
       "      <td>1.635882</td>\n",
       "      <td>27.333334</td>\n",
       "      <td>19.295834</td>\n",
       "      <td>105.660004</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>0.984864</td>\n",
       "      <td>0.085570</td>\n",
       "      <td>0.948558</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.475696</td>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.979486</td>\n",
       "      <td>2.292557e-02</td>\n",
       "      <td>0.934832</td>\n",
       "      <td>0.042541</td>\n",
       "      <td>0.664003</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>0.305666</td>\n",
       "      <td>0.976163</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.912582</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.692006</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>0.350494</td>\n",
       "      <td>0.960915</td>\n",
       "      <td>0.915928</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>0.856582</td>\n",
       "      <td>0.968033</td>\n",
       "      <td>0.952814</td>\n",
       "      <td>0.875112</td>\n",
       "      <td>0.939005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5652.91000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745.910000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.221305</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.162032</td>\n",
       "      <td>1.839400</td>\n",
       "      <td>37.333332</td>\n",
       "      <td>25.651666</td>\n",
       "      <td>116.150002</td>\n",
       "      <td>19.263999</td>\n",
       "      <td>22.609299</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>22.891000</td>\n",
       "      <td>16.869101</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>15.151300</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.278206</td>\n",
       "      <td>0.984811</td>\n",
       "      <td>0.317607</td>\n",
       "      <td>0.886046</td>\n",
       "      <td>0.269520</td>\n",
       "      <td>0.994496</td>\n",
       "      <td>1.118167e-01</td>\n",
       "      <td>0.975074</td>\n",
       "      <td>0.458844</td>\n",
       "      <td>0.950283</td>\n",
       "      <td>0.399319</td>\n",
       "      <td>0.871108</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.128034</td>\n",
       "      <td>0.978346</td>\n",
       "      <td>0.441439</td>\n",
       "      <td>0.968596</td>\n",
       "      <td>0.472689</td>\n",
       "      <td>0.912474</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>0.967271</td>\n",
       "      <td>0.957404</td>\n",
       "      <td>0.947910</td>\n",
       "      <td>0.912711</td>\n",
       "      <td>0.979053</td>\n",
       "      <td>0.973873</td>\n",
       "      <td>0.958096</td>\n",
       "      <td>0.955797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5710.00000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>118.680000</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>55.520000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>0.999088</td>\n",
       "      <td>0.764529</td>\n",
       "      <td>0.994431</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>4.605981e-01</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.993023</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>0.984203</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.993893</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>0.994790</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.979106</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.979833</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.985266</td>\n",
       "      <td>0.982451</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.966720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label          bws  worker       length   digit_frac  letter_frac  \\\n",
       "count  5710.00000  5710.000000  5710.0  5710.000000  5710.000000  5710.000000   \n",
       "mean   2855.50000    -0.027706     0.0   196.434501     0.003538     0.787127   \n",
       "std    1648.47935     0.334195     0.0   171.036190     0.012874     0.034742   \n",
       "min       1.00000    -0.889000     0.0    14.000000     0.000000     0.400000   \n",
       "1%       58.09000    -0.667000     0.0    24.000000     0.000000     0.666667   \n",
       "5%      286.45000    -0.521000     0.0    33.000000     0.000000     0.729363   \n",
       "10%     571.90000    -0.426000     0.0    42.000000     0.000000     0.747601   \n",
       "20%    1142.80000    -0.312000     0.0    60.000000     0.000000     0.767442   \n",
       "30%    1713.70000    -0.213000     0.0    82.000000     0.000000     0.777778   \n",
       "40%    2284.60000    -0.146000     0.0   106.000000     0.000000     0.784615   \n",
       "50%    2855.50000    -0.062000     0.0   136.000000     0.000000     0.791045   \n",
       "60%    3426.40000     0.021000     0.0   175.000000     0.000000     0.797224   \n",
       "70%    3997.30000     0.104000     0.0   231.000000     0.000000     0.804124   \n",
       "80%    4568.20000     0.229000     0.0   315.000000     0.000000     0.811607   \n",
       "90%    5139.10000     0.458000     0.0   453.100000     0.009713     0.822222   \n",
       "95%    5424.55000     0.625000     0.0   574.550000     0.022669     0.830986   \n",
       "99%    5652.91000     0.833000     0.0   745.910000     0.060606     0.854545   \n",
       "max    5710.00000     0.979000     0.0   914.000000     0.235294     0.897436   \n",
       "\n",
       "        space_frac    punc_frac   upper_frac  syllables_per_word  \\\n",
       "count  5710.000000  5710.000000  5710.000000         5710.000000   \n",
       "mean      0.173322     0.036013     0.031820            1.306213   \n",
       "std       0.020724     0.025652     0.048489            0.199887   \n",
       "min       0.040541     0.000000     0.000000            0.800000   \n",
       "1%        0.111300     0.000000     0.000000            0.857143   \n",
       "5%        0.137931     0.008264     0.007042            1.000000   \n",
       "10%       0.148148     0.013889     0.009479            1.058824   \n",
       "20%       0.158407     0.019417     0.012821            1.142857   \n",
       "30%       0.165022     0.023389     0.015789            1.205374   \n",
       "40%       0.170004     0.027027     0.018921            1.251515   \n",
       "50%       0.174419     0.030769     0.022351            1.303030   \n",
       "60%       0.178964     0.035088     0.026786            1.344828   \n",
       "70%       0.183544     0.040230     0.032258            1.397009   \n",
       "80%       0.189336     0.047619     0.040149            1.459459   \n",
       "90%       0.197674     0.063492     0.056604            1.555556   \n",
       "95%       0.204545     0.081081     0.075207            1.635882   \n",
       "99%       0.221305     0.133333     0.162032            1.839400   \n",
       "max       0.250000     0.397849     0.857143            2.500000   \n",
       "\n",
       "       syllables_per_sent  words_per_sent  flesch_reading_ease  \\\n",
       "count         5710.000000     5710.000000          5710.000000   \n",
       "mean            13.194283        9.516296            75.075684   \n",
       "std              7.814633        5.374849            19.881145   \n",
       "min              2.000000        1.500000           -48.980000   \n",
       "1%               2.500000        2.333333            19.439399   \n",
       "5%               4.000000        3.000000            41.606500   \n",
       "10%              4.666667        3.500000            50.680001   \n",
       "20%              6.500000        5.000000            60.296001   \n",
       "30%              8.000000        6.000000            66.440002   \n",
       "40%             10.000000        7.250000            71.650002   \n",
       "50%             11.750000        8.500000            76.050003   \n",
       "60%             13.750000       10.000000            80.820000   \n",
       "70%             16.000000       11.500000            85.389999   \n",
       "80%             19.000000       13.500000            90.769997   \n",
       "90%             23.500000       16.500000            99.230003   \n",
       "95%             27.333334       19.295834           105.660004   \n",
       "99%             37.333332       25.651666           116.150002   \n",
       "max             96.000000       63.500000           118.680000   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog   smog_index  \\\n",
       "count           5710.000000  5710.000000  5710.000000   \n",
       "mean               6.465289     8.678009     3.174711   \n",
       "std                4.232607     4.458600     4.696062   \n",
       "min               -2.500000     1.200000     0.000000   \n",
       "1%                -1.500000     1.600000     0.000000   \n",
       "5%                 0.500000     2.400000     0.000000   \n",
       "10%                1.700000     3.200000     0.000000   \n",
       "20%                3.100000     4.800000     0.000000   \n",
       "30%                4.200000     6.100000     0.000000   \n",
       "40%                5.200000     7.600000     0.000000   \n",
       "50%                6.100000     8.280000     0.000000   \n",
       "60%                7.000000     9.200000     0.000000   \n",
       "70%                8.000000    10.393000     6.400000   \n",
       "80%                9.500000    11.670000     8.800000   \n",
       "90%               11.500000    14.000000    10.700000   \n",
       "95%               13.400000    16.080000    11.900000   \n",
       "99%               19.263999    22.609299    14.200000   \n",
       "max               51.599998    55.520000    18.900000   \n",
       "\n",
       "       automated_readability_index  coleman_liau_index  linsear_write_formula  \\\n",
       "count                  5710.000000         5710.000000            5710.000000   \n",
       "mean                      7.575517            7.008681               7.984055   \n",
       "std                       5.256020            3.881966               5.502464   \n",
       "min                      -6.800000          -10.160000               0.500000   \n",
       "1%                       -2.800000           -2.680100               1.250000   \n",
       "5%                        0.345000            0.760000               2.000000   \n",
       "10%                       1.700000            2.200000               2.500000   \n",
       "20%                       3.600000            4.110000               3.750000   \n",
       "30%                       4.900000            5.277000               4.632954   \n",
       "40%                       6.100000            6.240000               5.666667   \n",
       "50%                       7.100000            7.070000               6.666667   \n",
       "60%                       8.300000            7.900000               7.750000   \n",
       "70%                       9.430000            8.833000               9.000000   \n",
       "80%                      11.100000            9.940000              11.806667   \n",
       "90%                      13.500000           11.550000              14.500000   \n",
       "95%                      16.100000           13.040000              17.500000   \n",
       "99%                      22.891000           16.869101              26.500000   \n",
       "max                      64.900002           40.599998              66.000000   \n",
       "\n",
       "       dale_chall_readability_score  dto_toxicity  dto_severe_toxicity  \\\n",
       "count                   5710.000000   5710.000000          5710.000000   \n",
       "mean                       8.397984      0.178017             0.013053   \n",
       "std                        2.272001      0.327531             0.052672   \n",
       "min                        0.200000      0.000506             0.000080   \n",
       "1%                         0.350000      0.000554             0.000087   \n",
       "5%                         5.689000      0.000613             0.000093   \n",
       "10%                        6.258000      0.000664             0.000097   \n",
       "20%                        7.010000      0.000790             0.000103   \n",
       "30%                        7.490000      0.000995             0.000108   \n",
       "40%                        7.920000      0.001491             0.000114   \n",
       "50%                        8.310000      0.003831             0.000120   \n",
       "60%                        8.700000      0.014143             0.000131   \n",
       "70%                        9.190000      0.054273             0.000218   \n",
       "80%                        9.920000      0.311318             0.001142   \n",
       "90%                       10.810000      0.890399             0.017812   \n",
       "95%                       11.910000      0.984864             0.085570   \n",
       "99%                       15.151300      0.997188             0.278206   \n",
       "max                       24.990000      0.999088             0.764529   \n",
       "\n",
       "       dto_obscene   dto_threat   dto_insult  dto_identity_attack  \\\n",
       "count  5710.000000  5710.000000  5710.000000          5710.000000   \n",
       "mean      0.116018     0.008281     0.058905             0.011259   \n",
       "std       0.285371     0.055856     0.173173             0.063640   \n",
       "min       0.000141     0.000086     0.000164             0.000121   \n",
       "1%        0.000158     0.000096     0.000171             0.000134   \n",
       "5%        0.000165     0.000104     0.000175             0.000138   \n",
       "10%       0.000170     0.000108     0.000177             0.000140   \n",
       "20%       0.000176     0.000115     0.000181             0.000144   \n",
       "30%       0.000182     0.000121     0.000187             0.000150   \n",
       "40%       0.000195     0.000127     0.000205             0.000164   \n",
       "50%       0.000275     0.000138     0.000290             0.000208   \n",
       "60%       0.000560     0.000204     0.000651             0.000348   \n",
       "70%       0.001638     0.000424     0.001950             0.000847   \n",
       "80%       0.017729     0.001137     0.014517             0.002615   \n",
       "90%       0.701841     0.003109     0.166622             0.009797   \n",
       "95%       0.948558     0.009130     0.475696             0.031769   \n",
       "99%       0.984811     0.317607     0.886046             0.269520   \n",
       "max       0.994431     0.823060     0.980776             0.894015   \n",
       "\n",
       "       dtu_toxicity  dtu_severe_toxicity  dtu_obscene  dtu_identity_attack  \\\n",
       "count   5710.000000         5.710000e+03  5710.000000          5710.000000   \n",
       "mean       0.198142         4.805578e-03     0.116087             0.015345   \n",
       "std        0.344199         2.266139e-02     0.288667             0.074686   \n",
       "min        0.000286         9.529070e-07     0.000017             0.000052   \n",
       "1%         0.000359         1.083922e-06     0.000021             0.000063   \n",
       "5%         0.000409         1.200621e-06     0.000024             0.000070   \n",
       "10%        0.000453         1.270202e-06     0.000026             0.000076   \n",
       "20%        0.000567         1.407515e-06     0.000031             0.000089   \n",
       "30%        0.000847         1.639610e-06     0.000041             0.000113   \n",
       "40%        0.001593         2.270376e-06     0.000067             0.000176   \n",
       "50%        0.003826         4.237992e-06     0.000129             0.000364   \n",
       "60%        0.014458         1.026577e-05     0.000307             0.000841   \n",
       "70%        0.079215         3.243160e-05     0.000976             0.002075   \n",
       "80%        0.438595         1.825476e-04     0.006367             0.005022   \n",
       "90%        0.934102         4.849900e-03     0.759786             0.015939   \n",
       "95%        0.979486         2.292557e-02     0.934832             0.042541   \n",
       "99%        0.994496         1.118167e-01     0.975074             0.458844   \n",
       "max        0.998344         4.605981e-01     0.987875             0.984674   \n",
       "\n",
       "        dtu_insult   dtu_threat  dtu_sexual_explicit  dtm_toxicity  \\\n",
       "count  5710.000000  5710.000000          5710.000000   5710.000000   \n",
       "mean      0.082434     0.010953             0.041588      0.205323   \n",
       "std       0.208794     0.069327             0.153310      0.347693   \n",
       "min       0.000061     0.000012             0.000009      0.000186   \n",
       "1%        0.000091     0.000015             0.000011      0.000280   \n",
       "5%        0.000102     0.000017             0.000012      0.000353   \n",
       "10%       0.000111     0.000019             0.000013      0.000413   \n",
       "20%       0.000132     0.000023             0.000016      0.000569   \n",
       "30%       0.000176     0.000030             0.000021      0.000846   \n",
       "40%       0.000309     0.000048             0.000033      0.001640   \n",
       "50%       0.000663     0.000088             0.000069      0.004218   \n",
       "60%       0.001618     0.000177             0.000179      0.016230   \n",
       "70%       0.005639     0.000400             0.000549      0.092651   \n",
       "80%       0.043445     0.000978             0.003527      0.503942   \n",
       "90%       0.297910     0.002866             0.045876      0.932564   \n",
       "95%       0.664003     0.014675             0.305666      0.976163   \n",
       "99%       0.950283     0.399319             0.871108      0.994074   \n",
       "max       0.993023     0.925068             0.984203      0.999047   \n",
       "\n",
       "       dtm_severe_toxicity  dtm_obscene  dtm_identity_attack   dtm_insult  \\\n",
       "count          5710.000000  5710.000000          5710.000000  5710.000000   \n",
       "mean              0.006121     0.108231             0.013962     0.084179   \n",
       "std               0.028851     0.276257             0.076959     0.215207   \n",
       "min               0.000009     0.000063             0.000045     0.000095   \n",
       "1%                0.000013     0.000094             0.000066     0.000149   \n",
       "5%                0.000016     0.000115             0.000078     0.000177   \n",
       "10%               0.000019     0.000129             0.000086     0.000199   \n",
       "20%               0.000023     0.000159             0.000099     0.000246   \n",
       "30%               0.000027     0.000200             0.000117     0.000324   \n",
       "40%               0.000033     0.000271             0.000153     0.000505   \n",
       "50%               0.000047     0.000439             0.000246     0.001038   \n",
       "60%               0.000086     0.000763             0.000522     0.002472   \n",
       "70%               0.000217     0.001618             0.001279     0.008013   \n",
       "80%               0.000871     0.005973             0.003361     0.044463   \n",
       "90%               0.008530     0.691554             0.011568     0.309165   \n",
       "95%               0.031727     0.912582             0.033529     0.692006   \n",
       "99%               0.128034     0.978346             0.441439     0.968596   \n",
       "max               0.672039     0.993893             0.965869     0.994790   \n",
       "\n",
       "        dtm_threat  dtm_sexual_explicit  hb_bert_off  hb_bert_abu  \\\n",
       "count  5710.000000          5710.000000  5710.000000  5710.000000   \n",
       "mean      0.014834             0.047063     0.334793     0.167132   \n",
       "std       0.078998             0.161288     0.333605     0.279580   \n",
       "min       0.000014             0.000012     0.008860     0.002739   \n",
       "1%        0.000021             0.000017     0.013538     0.003778   \n",
       "5%        0.000027             0.000020     0.021235     0.005182   \n",
       "10%       0.000031             0.000022     0.028724     0.006400   \n",
       "20%       0.000037             0.000026     0.045517     0.009100   \n",
       "30%       0.000046             0.000032     0.071203     0.012630   \n",
       "40%       0.000065             0.000044     0.109697     0.018195   \n",
       "50%       0.000124             0.000090     0.172586     0.027891   \n",
       "60%       0.000312             0.000240     0.286969     0.048375   \n",
       "70%       0.000974             0.000808     0.469389     0.098105   \n",
       "80%       0.003018             0.004972     0.731942     0.251565   \n",
       "90%       0.011346             0.086770     0.929209     0.716078   \n",
       "95%       0.037137             0.350494     0.960915     0.915928   \n",
       "99%       0.472689             0.912474     0.972583     0.967271   \n",
       "max       0.962406             0.986346     0.979106     0.977543   \n",
       "\n",
       "       hb_hatebert_off  hb_hatebert_abu  te_roberta_off  te_roberta_emo_anger  \\\n",
       "count      5710.000000      5710.000000     5710.000000           5710.000000   \n",
       "mean          0.328739         0.143653        0.348313              0.503608   \n",
       "std           0.284592         0.220860        0.251150              0.358048   \n",
       "min           0.006939         0.007050        0.022149              0.004901   \n",
       "1%            0.021539         0.010232        0.049472              0.010917   \n",
       "5%            0.036289         0.013514        0.073940              0.023043   \n",
       "10%           0.049613         0.015978        0.091332              0.038833   \n",
       "20%           0.078329         0.020921        0.123751              0.087335   \n",
       "30%           0.112309         0.026856        0.161146              0.173238   \n",
       "40%           0.156718         0.035112        0.206264              0.316501   \n",
       "50%           0.215901         0.047124        0.263219              0.516670   \n",
       "60%           0.309187         0.067387        0.340614              0.707297   \n",
       "70%           0.438910         0.105317        0.446956              0.835034   \n",
       "80%           0.613122         0.188452        0.587693              0.910890   \n",
       "90%           0.822385         0.459093        0.785050              0.955080   \n",
       "95%           0.909732         0.735450        0.856582              0.968033   \n",
       "99%           0.957404         0.947910        0.912711              0.979053   \n",
       "max           0.979833         0.977078        0.950407              0.985266   \n",
       "\n",
       "       te_roberta_snt_neg  te_roberta_iro  te_xlm_roberta_snt_neg  \n",
       "count         5710.000000     5710.000000             5710.000000  \n",
       "mean             0.505888        0.308120                0.579380  \n",
       "std              0.319222        0.273608                0.300933  \n",
       "min              0.000799        0.014366                0.007853  \n",
       "1%               0.001821        0.022383                0.019090  \n",
       "5%               0.008893        0.035101                0.053520  \n",
       "10%              0.031858        0.046720                0.112013  \n",
       "20%              0.142043        0.071495                0.245301  \n",
       "30%              0.289854        0.101327                0.388927  \n",
       "40%              0.412298        0.142517                0.521514  \n",
       "50%              0.532186        0.195142                0.647636  \n",
       "60%              0.648439        0.282336                0.755627  \n",
       "70%              0.755154        0.405658                0.832475  \n",
       "80%              0.844584        0.570127                0.885213  \n",
       "90%              0.920020        0.776994                0.921563  \n",
       "95%              0.952814        0.875112                0.939005  \n",
       "99%              0.973873        0.958096                0.955797  \n",
       "max              0.982451        0.990079                0.966720  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"label\", \"bws\", \"worker\", \"length\"]\n",
    "cols += list(char_fns.keys())\n",
    "cols += list(textstat_fns.keys())\n",
    "cols += dtfy_fs\n",
    "cols += list(conf.hatebert_models.keys()) \n",
    "cols += list(conf.tweeteval_models.keys()) \n",
    "df[cols].describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bddf8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5710 entries, 0 to 5709\n",
      "Data columns (total 433 columns):\n",
      " #    Column                        Non-Null Count  Dtype  \n",
      "---   ------                        --------------  -----  \n",
      " 0    label                         5710 non-null   int32  \n",
      " 1    bws                           5710 non-null   float32\n",
      " 2    worker                        5710 non-null   int8   \n",
      " 3    length                        5710 non-null   int16  \n",
      " 4    digit_frac                    5710 non-null   float32\n",
      " 5    letter_frac                   5710 non-null   float32\n",
      " 6    space_frac                    5710 non-null   float32\n",
      " 7    punc_frac                     5710 non-null   float32\n",
      " 8    upper_frac                    5710 non-null   float32\n",
      " 9    syllables_per_word            5710 non-null   float32\n",
      " 10   syllables_per_sent            5710 non-null   float32\n",
      " 11   words_per_sent                5710 non-null   float32\n",
      " 12   flesch_reading_ease           5710 non-null   float32\n",
      " 13   flesch_kincaid_grade          5710 non-null   float32\n",
      " 14   gunning_fog                   5710 non-null   float32\n",
      " 15   smog_index                    5710 non-null   float32\n",
      " 16   automated_readability_index   5710 non-null   float32\n",
      " 17   coleman_liau_index            5710 non-null   float32\n",
      " 18   linsear_write_formula         5710 non-null   float32\n",
      " 19   dale_chall_readability_score  5710 non-null   float32\n",
      " 20   dto_toxicity                  5710 non-null   float32\n",
      " 21   dto_severe_toxicity           5710 non-null   float32\n",
      " 22   dto_obscene                   5710 non-null   float32\n",
      " 23   dto_threat                    5710 non-null   float32\n",
      " 24   dto_insult                    5710 non-null   float32\n",
      " 25   dto_identity_attack           5710 non-null   float32\n",
      " 26   dtu_toxicity                  5710 non-null   float32\n",
      " 27   dtu_severe_toxicity           5710 non-null   float32\n",
      " 28   dtu_obscene                   5710 non-null   float32\n",
      " 29   dtu_identity_attack           5710 non-null   float32\n",
      " 30   dtu_insult                    5710 non-null   float32\n",
      " 31   dtu_threat                    5710 non-null   float32\n",
      " 32   dtu_sexual_explicit           5710 non-null   float32\n",
      " 33   dtm_toxicity                  5710 non-null   float32\n",
      " 34   dtm_severe_toxicity           5710 non-null   float32\n",
      " 35   dtm_obscene                   5710 non-null   float32\n",
      " 36   dtm_identity_attack           5710 non-null   float32\n",
      " 37   dtm_insult                    5710 non-null   float32\n",
      " 38   dtm_threat                    5710 non-null   float32\n",
      " 39   dtm_sexual_explicit           5710 non-null   float32\n",
      " 40   hb_bert_off                   5710 non-null   float32\n",
      " 41   hb_bert_abu                   5710 non-null   float32\n",
      " 42   hb_hatebert_off               5710 non-null   float32\n",
      " 43   hb_hatebert_abu               5710 non-null   float32\n",
      " 44   te_roberta_off                5710 non-null   float32\n",
      " 45   te_roberta_emo_anger          5710 non-null   float32\n",
      " 46   te_roberta_snt_neg            5710 non-null   float32\n",
      " 47   te_roberta_iro                5710 non-null   float32\n",
      " 48   te_xlm_roberta_snt_neg        5710 non-null   float32\n",
      " 49   zz0000                        5710 non-null   float32\n",
      " 50   zz0001                        5710 non-null   float32\n",
      " 51   zz0002                        5710 non-null   float32\n",
      " 52   zz0003                        5710 non-null   float32\n",
      " 53   zz0004                        5710 non-null   float32\n",
      " 54   zz0005                        5710 non-null   float32\n",
      " 55   zz0006                        5710 non-null   float32\n",
      " 56   zz0007                        5710 non-null   float32\n",
      " 57   zz0008                        5710 non-null   float32\n",
      " 58   zz0009                        5710 non-null   float32\n",
      " 59   zz0010                        5710 non-null   float32\n",
      " 60   zz0011                        5710 non-null   float32\n",
      " 61   zz0012                        5710 non-null   float32\n",
      " 62   zz0013                        5710 non-null   float32\n",
      " 63   zz0014                        5710 non-null   float32\n",
      " 64   zz0015                        5710 non-null   float32\n",
      " 65   zz0016                        5710 non-null   float32\n",
      " 66   zz0017                        5710 non-null   float32\n",
      " 67   zz0018                        5710 non-null   float32\n",
      " 68   zz0019                        5710 non-null   float32\n",
      " 69   zz0020                        5710 non-null   float32\n",
      " 70   zz0021                        5710 non-null   float32\n",
      " 71   zz0022                        5710 non-null   float32\n",
      " 72   zz0023                        5710 non-null   float32\n",
      " 73   zz0024                        5710 non-null   float32\n",
      " 74   zz0025                        5710 non-null   float32\n",
      " 75   zz0026                        5710 non-null   float32\n",
      " 76   zz0027                        5710 non-null   float32\n",
      " 77   zz0028                        5710 non-null   float32\n",
      " 78   zz0029                        5710 non-null   float32\n",
      " 79   zz0030                        5710 non-null   float32\n",
      " 80   zz0031                        5710 non-null   float32\n",
      " 81   zz0032                        5710 non-null   float32\n",
      " 82   zz0033                        5710 non-null   float32\n",
      " 83   zz0034                        5710 non-null   float32\n",
      " 84   zz0035                        5710 non-null   float32\n",
      " 85   zz0036                        5710 non-null   float32\n",
      " 86   zz0037                        5710 non-null   float32\n",
      " 87   zz0038                        5710 non-null   float32\n",
      " 88   zz0039                        5710 non-null   float32\n",
      " 89   zz0040                        5710 non-null   float32\n",
      " 90   zz0041                        5710 non-null   float32\n",
      " 91   zz0042                        5710 non-null   float32\n",
      " 92   zz0043                        5710 non-null   float32\n",
      " 93   zz0044                        5710 non-null   float32\n",
      " 94   zz0045                        5710 non-null   float32\n",
      " 95   zz0046                        5710 non-null   float32\n",
      " 96   zz0047                        5710 non-null   float32\n",
      " 97   zz0048                        5710 non-null   float32\n",
      " 98   zz0049                        5710 non-null   float32\n",
      " 99   zz0050                        5710 non-null   float32\n",
      " 100  zz0051                        5710 non-null   float32\n",
      " 101  zz0052                        5710 non-null   float32\n",
      " 102  zz0053                        5710 non-null   float32\n",
      " 103  zz0054                        5710 non-null   float32\n",
      " 104  zz0055                        5710 non-null   float32\n",
      " 105  zz0056                        5710 non-null   float32\n",
      " 106  zz0057                        5710 non-null   float32\n",
      " 107  zz0058                        5710 non-null   float32\n",
      " 108  zz0059                        5710 non-null   float32\n",
      " 109  zz0060                        5710 non-null   float32\n",
      " 110  zz0061                        5710 non-null   float32\n",
      " 111  zz0062                        5710 non-null   float32\n",
      " 112  zz0063                        5710 non-null   float32\n",
      " 113  zz0064                        5710 non-null   float32\n",
      " 114  zz0065                        5710 non-null   float32\n",
      " 115  zz0066                        5710 non-null   float32\n",
      " 116  zz0067                        5710 non-null   float32\n",
      " 117  zz0068                        5710 non-null   float32\n",
      " 118  zz0069                        5710 non-null   float32\n",
      " 119  zz0070                        5710 non-null   float32\n",
      " 120  zz0071                        5710 non-null   float32\n",
      " 121  zz0072                        5710 non-null   float32\n",
      " 122  zz0073                        5710 non-null   float32\n",
      " 123  zz0074                        5710 non-null   float32\n",
      " 124  zz0075                        5710 non-null   float32\n",
      " 125  zz0076                        5710 non-null   float32\n",
      " 126  zz0077                        5710 non-null   float32\n",
      " 127  zz0078                        5710 non-null   float32\n",
      " 128  zz0079                        5710 non-null   float32\n",
      " 129  zz0080                        5710 non-null   float32\n",
      " 130  zz0081                        5710 non-null   float32\n",
      " 131  zz0082                        5710 non-null   float32\n",
      " 132  zz0083                        5710 non-null   float32\n",
      " 133  zz0084                        5710 non-null   float32\n",
      " 134  zz0085                        5710 non-null   float32\n",
      " 135  zz0086                        5710 non-null   float32\n",
      " 136  zz0087                        5710 non-null   float32\n",
      " 137  zz0088                        5710 non-null   float32\n",
      " 138  zz0089                        5710 non-null   float32\n",
      " 139  zz0090                        5710 non-null   float32\n",
      " 140  zz0091                        5710 non-null   float32\n",
      " 141  zz0092                        5710 non-null   float32\n",
      " 142  zz0093                        5710 non-null   float32\n",
      " 143  zz0094                        5710 non-null   float32\n",
      " 144  zz0095                        5710 non-null   float32\n",
      " 145  zz0096                        5710 non-null   float32\n",
      " 146  zz0097                        5710 non-null   float32\n",
      " 147  zz0098                        5710 non-null   float32\n",
      " 148  zz0099                        5710 non-null   float32\n",
      " 149  zz0100                        5710 non-null   float32\n",
      " 150  zz0101                        5710 non-null   float32\n",
      " 151  zz0102                        5710 non-null   float32\n",
      " 152  zz0103                        5710 non-null   float32\n",
      " 153  zz0104                        5710 non-null   float32\n",
      " 154  zz0105                        5710 non-null   float32\n",
      " 155  zz0106                        5710 non-null   float32\n",
      " 156  zz0107                        5710 non-null   float32\n",
      " 157  zz0108                        5710 non-null   float32\n",
      " 158  zz0109                        5710 non-null   float32\n",
      " 159  zz0110                        5710 non-null   float32\n",
      " 160  zz0111                        5710 non-null   float32\n",
      " 161  zz0112                        5710 non-null   float32\n",
      " 162  zz0113                        5710 non-null   float32\n",
      " 163  zz0114                        5710 non-null   float32\n",
      " 164  zz0115                        5710 non-null   float32\n",
      " 165  zz0116                        5710 non-null   float32\n",
      " 166  zz0117                        5710 non-null   float32\n",
      " 167  zz0118                        5710 non-null   float32\n",
      " 168  zz0119                        5710 non-null   float32\n",
      " 169  zz0120                        5710 non-null   float32\n",
      " 170  zz0121                        5710 non-null   float32\n",
      " 171  zz0122                        5710 non-null   float32\n",
      " 172  zz0123                        5710 non-null   float32\n",
      " 173  zz0124                        5710 non-null   float32\n",
      " 174  zz0125                        5710 non-null   float32\n",
      " 175  zz0126                        5710 non-null   float32\n",
      " 176  zz0127                        5710 non-null   float32\n",
      " 177  zz0128                        5710 non-null   float32\n",
      " 178  zz0129                        5710 non-null   float32\n",
      " 179  zz0130                        5710 non-null   float32\n",
      " 180  zz0131                        5710 non-null   float32\n",
      " 181  zz0132                        5710 non-null   float32\n",
      " 182  zz0133                        5710 non-null   float32\n",
      " 183  zz0134                        5710 non-null   float32\n",
      " 184  zz0135                        5710 non-null   float32\n",
      " 185  zz0136                        5710 non-null   float32\n",
      " 186  zz0137                        5710 non-null   float32\n",
      " 187  zz0138                        5710 non-null   float32\n",
      " 188  zz0139                        5710 non-null   float32\n",
      " 189  zz0140                        5710 non-null   float32\n",
      " 190  zz0141                        5710 non-null   float32\n",
      " 191  zz0142                        5710 non-null   float32\n",
      " 192  zz0143                        5710 non-null   float32\n",
      " 193  zz0144                        5710 non-null   float32\n",
      " 194  zz0145                        5710 non-null   float32\n",
      " 195  zz0146                        5710 non-null   float32\n",
      " 196  zz0147                        5710 non-null   float32\n",
      " 197  zz0148                        5710 non-null   float32\n",
      " 198  zz0149                        5710 non-null   float32\n",
      " 199  zz0150                        5710 non-null   float32\n",
      " 200  zz0151                        5710 non-null   float32\n",
      " 201  zz0152                        5710 non-null   float32\n",
      " 202  zz0153                        5710 non-null   float32\n",
      " 203  zz0154                        5710 non-null   float32\n",
      " 204  zz0155                        5710 non-null   float32\n",
      " 205  zz0156                        5710 non-null   float32\n",
      " 206  zz0157                        5710 non-null   float32\n",
      " 207  zz0158                        5710 non-null   float32\n",
      " 208  zz0159                        5710 non-null   float32\n",
      " 209  zz0160                        5710 non-null   float32\n",
      " 210  zz0161                        5710 non-null   float32\n",
      " 211  zz0162                        5710 non-null   float32\n",
      " 212  zz0163                        5710 non-null   float32\n",
      " 213  zz0164                        5710 non-null   float32\n",
      " 214  zz0165                        5710 non-null   float32\n",
      " 215  zz0166                        5710 non-null   float32\n",
      " 216  zz0167                        5710 non-null   float32\n",
      " 217  zz0168                        5710 non-null   float32\n",
      " 218  zz0169                        5710 non-null   float32\n",
      " 219  zz0170                        5710 non-null   float32\n",
      " 220  zz0171                        5710 non-null   float32\n",
      " 221  zz0172                        5710 non-null   float32\n",
      " 222  zz0173                        5710 non-null   float32\n",
      " 223  zz0174                        5710 non-null   float32\n",
      " 224  zz0175                        5710 non-null   float32\n",
      " 225  zz0176                        5710 non-null   float32\n",
      " 226  zz0177                        5710 non-null   float32\n",
      " 227  zz0178                        5710 non-null   float32\n",
      " 228  zz0179                        5710 non-null   float32\n",
      " 229  zz0180                        5710 non-null   float32\n",
      " 230  zz0181                        5710 non-null   float32\n",
      " 231  zz0182                        5710 non-null   float32\n",
      " 232  zz0183                        5710 non-null   float32\n",
      " 233  zz0184                        5710 non-null   float32\n",
      " 234  zz0185                        5710 non-null   float32\n",
      " 235  zz0186                        5710 non-null   float32\n",
      " 236  zz0187                        5710 non-null   float32\n",
      " 237  zz0188                        5710 non-null   float32\n",
      " 238  zz0189                        5710 non-null   float32\n",
      " 239  zz0190                        5710 non-null   float32\n",
      " 240  zz0191                        5710 non-null   float32\n",
      " 241  zz0192                        5710 non-null   float32\n",
      " 242  zz0193                        5710 non-null   float32\n",
      " 243  zz0194                        5710 non-null   float32\n",
      " 244  zz0195                        5710 non-null   float32\n",
      " 245  zz0196                        5710 non-null   float32\n",
      " 246  zz0197                        5710 non-null   float32\n",
      " 247  zz0198                        5710 non-null   float32\n",
      " 248  zz0199                        5710 non-null   float32\n",
      " 249  zz0200                        5710 non-null   float32\n",
      " 250  zz0201                        5710 non-null   float32\n",
      " 251  zz0202                        5710 non-null   float32\n",
      " 252  zz0203                        5710 non-null   float32\n",
      " 253  zz0204                        5710 non-null   float32\n",
      " 254  zz0205                        5710 non-null   float32\n",
      " 255  zz0206                        5710 non-null   float32\n",
      " 256  zz0207                        5710 non-null   float32\n",
      " 257  zz0208                        5710 non-null   float32\n",
      " 258  zz0209                        5710 non-null   float32\n",
      " 259  zz0210                        5710 non-null   float32\n",
      " 260  zz0211                        5710 non-null   float32\n",
      " 261  zz0212                        5710 non-null   float32\n",
      " 262  zz0213                        5710 non-null   float32\n",
      " 263  zz0214                        5710 non-null   float32\n",
      " 264  zz0215                        5710 non-null   float32\n",
      " 265  zz0216                        5710 non-null   float32\n",
      " 266  zz0217                        5710 non-null   float32\n",
      " 267  zz0218                        5710 non-null   float32\n",
      " 268  zz0219                        5710 non-null   float32\n",
      " 269  zz0220                        5710 non-null   float32\n",
      " 270  zz0221                        5710 non-null   float32\n",
      " 271  zz0222                        5710 non-null   float32\n",
      " 272  zz0223                        5710 non-null   float32\n",
      " 273  zz0224                        5710 non-null   float32\n",
      " 274  zz0225                        5710 non-null   float32\n",
      " 275  zz0226                        5710 non-null   float32\n",
      " 276  zz0227                        5710 non-null   float32\n",
      " 277  zz0228                        5710 non-null   float32\n",
      " 278  zz0229                        5710 non-null   float32\n",
      " 279  zz0230                        5710 non-null   float32\n",
      " 280  zz0231                        5710 non-null   float32\n",
      " 281  zz0232                        5710 non-null   float32\n",
      " 282  zz0233                        5710 non-null   float32\n",
      " 283  zz0234                        5710 non-null   float32\n",
      " 284  zz0235                        5710 non-null   float32\n",
      " 285  zz0236                        5710 non-null   float32\n",
      " 286  zz0237                        5710 non-null   float32\n",
      " 287  zz0238                        5710 non-null   float32\n",
      " 288  zz0239                        5710 non-null   float32\n",
      " 289  zz0240                        5710 non-null   float32\n",
      " 290  zz0241                        5710 non-null   float32\n",
      " 291  zz0242                        5710 non-null   float32\n",
      " 292  zz0243                        5710 non-null   float32\n",
      " 293  zz0244                        5710 non-null   float32\n",
      " 294  zz0245                        5710 non-null   float32\n",
      " 295  zz0246                        5710 non-null   float32\n",
      " 296  zz0247                        5710 non-null   float32\n",
      " 297  zz0248                        5710 non-null   float32\n",
      " 298  zz0249                        5710 non-null   float32\n",
      " 299  zz0250                        5710 non-null   float32\n",
      " 300  zz0251                        5710 non-null   float32\n",
      " 301  zz0252                        5710 non-null   float32\n",
      " 302  zz0253                        5710 non-null   float32\n",
      " 303  zz0254                        5710 non-null   float32\n",
      " 304  zz0255                        5710 non-null   float32\n",
      " 305  zz0256                        5710 non-null   float32\n",
      " 306  zz0257                        5710 non-null   float32\n",
      " 307  zz0258                        5710 non-null   float32\n",
      " 308  zz0259                        5710 non-null   float32\n",
      " 309  zz0260                        5710 non-null   float32\n",
      " 310  zz0261                        5710 non-null   float32\n",
      " 311  zz0262                        5710 non-null   float32\n",
      " 312  zz0263                        5710 non-null   float32\n",
      " 313  zz0264                        5710 non-null   float32\n",
      " 314  zz0265                        5710 non-null   float32\n",
      " 315  zz0266                        5710 non-null   float32\n",
      " 316  zz0267                        5710 non-null   float32\n",
      " 317  zz0268                        5710 non-null   float32\n",
      " 318  zz0269                        5710 non-null   float32\n",
      " 319  zz0270                        5710 non-null   float32\n",
      " 320  zz0271                        5710 non-null   float32\n",
      " 321  zz0272                        5710 non-null   float32\n",
      " 322  zz0273                        5710 non-null   float32\n",
      " 323  zz0274                        5710 non-null   float32\n",
      " 324  zz0275                        5710 non-null   float32\n",
      " 325  zz0276                        5710 non-null   float32\n",
      " 326  zz0277                        5710 non-null   float32\n",
      " 327  zz0278                        5710 non-null   float32\n",
      " 328  zz0279                        5710 non-null   float32\n",
      " 329  zz0280                        5710 non-null   float32\n",
      " 330  zz0281                        5710 non-null   float32\n",
      " 331  zz0282                        5710 non-null   float32\n",
      " 332  zz0283                        5710 non-null   float32\n",
      " 333  zz0284                        5710 non-null   float32\n",
      " 334  zz0285                        5710 non-null   float32\n",
      " 335  zz0286                        5710 non-null   float32\n",
      " 336  zz0287                        5710 non-null   float32\n",
      " 337  zz0288                        5710 non-null   float32\n",
      " 338  zz0289                        5710 non-null   float32\n",
      " 339  zz0290                        5710 non-null   float32\n",
      " 340  zz0291                        5710 non-null   float32\n",
      " 341  zz0292                        5710 non-null   float32\n",
      " 342  zz0293                        5710 non-null   float32\n",
      " 343  zz0294                        5710 non-null   float32\n",
      " 344  zz0295                        5710 non-null   float32\n",
      " 345  zz0296                        5710 non-null   float32\n",
      " 346  zz0297                        5710 non-null   float32\n",
      " 347  zz0298                        5710 non-null   float32\n",
      " 348  zz0299                        5710 non-null   float32\n",
      " 349  zz0300                        5710 non-null   float32\n",
      " 350  zz0301                        5710 non-null   float32\n",
      " 351  zz0302                        5710 non-null   float32\n",
      " 352  zz0303                        5710 non-null   float32\n",
      " 353  zz0304                        5710 non-null   float32\n",
      " 354  zz0305                        5710 non-null   float32\n",
      " 355  zz0306                        5710 non-null   float32\n",
      " 356  zz0307                        5710 non-null   float32\n",
      " 357  zz0308                        5710 non-null   float32\n",
      " 358  zz0309                        5710 non-null   float32\n",
      " 359  zz0310                        5710 non-null   float32\n",
      " 360  zz0311                        5710 non-null   float32\n",
      " 361  zz0312                        5710 non-null   float32\n",
      " 362  zz0313                        5710 non-null   float32\n",
      " 363  zz0314                        5710 non-null   float32\n",
      " 364  zz0315                        5710 non-null   float32\n",
      " 365  zz0316                        5710 non-null   float32\n",
      " 366  zz0317                        5710 non-null   float32\n",
      " 367  zz0318                        5710 non-null   float32\n",
      " 368  zz0319                        5710 non-null   float32\n",
      " 369  zz0320                        5710 non-null   float32\n",
      " 370  zz0321                        5710 non-null   float32\n",
      " 371  zz0322                        5710 non-null   float32\n",
      " 372  zz0323                        5710 non-null   float32\n",
      " 373  zz0324                        5710 non-null   float32\n",
      " 374  zz0325                        5710 non-null   float32\n",
      " 375  zz0326                        5710 non-null   float32\n",
      " 376  zz0327                        5710 non-null   float32\n",
      " 377  zz0328                        5710 non-null   float32\n",
      " 378  zz0329                        5710 non-null   float32\n",
      " 379  zz0330                        5710 non-null   float32\n",
      " 380  zz0331                        5710 non-null   float32\n",
      " 381  zz0332                        5710 non-null   float32\n",
      " 382  zz0333                        5710 non-null   float32\n",
      " 383  zz0334                        5710 non-null   float32\n",
      " 384  zz0335                        5710 non-null   float32\n",
      " 385  zz0336                        5710 non-null   float32\n",
      " 386  zz0337                        5710 non-null   float32\n",
      " 387  zz0338                        5710 non-null   float32\n",
      " 388  zz0339                        5710 non-null   float32\n",
      " 389  zz0340                        5710 non-null   float32\n",
      " 390  zz0341                        5710 non-null   float32\n",
      " 391  zz0342                        5710 non-null   float32\n",
      " 392  zz0343                        5710 non-null   float32\n",
      " 393  zz0344                        5710 non-null   float32\n",
      " 394  zz0345                        5710 non-null   float32\n",
      " 395  zz0346                        5710 non-null   float32\n",
      " 396  zz0347                        5710 non-null   float32\n",
      " 397  zz0348                        5710 non-null   float32\n",
      " 398  zz0349                        5710 non-null   float32\n",
      " 399  zz0350                        5710 non-null   float32\n",
      " 400  zz0351                        5710 non-null   float32\n",
      " 401  zz0352                        5710 non-null   float32\n",
      " 402  zz0353                        5710 non-null   float32\n",
      " 403  zz0354                        5710 non-null   float32\n",
      " 404  zz0355                        5710 non-null   float32\n",
      " 405  zz0356                        5710 non-null   float32\n",
      " 406  zz0357                        5710 non-null   float32\n",
      " 407  zz0358                        5710 non-null   float32\n",
      " 408  zz0359                        5710 non-null   float32\n",
      " 409  zz0360                        5710 non-null   float32\n",
      " 410  zz0361                        5710 non-null   float32\n",
      " 411  zz0362                        5710 non-null   float32\n",
      " 412  zz0363                        5710 non-null   float32\n",
      " 413  zz0364                        5710 non-null   float32\n",
      " 414  zz0365                        5710 non-null   float32\n",
      " 415  zz0366                        5710 non-null   float32\n",
      " 416  zz0367                        5710 non-null   float32\n",
      " 417  zz0368                        5710 non-null   float32\n",
      " 418  zz0369                        5710 non-null   float32\n",
      " 419  zz0370                        5710 non-null   float32\n",
      " 420  zz0371                        5710 non-null   float32\n",
      " 421  zz0372                        5710 non-null   float32\n",
      " 422  zz0373                        5710 non-null   float32\n",
      " 423  zz0374                        5710 non-null   float32\n",
      " 424  zz0375                        5710 non-null   float32\n",
      " 425  zz0376                        5710 non-null   float32\n",
      " 426  zz0377                        5710 non-null   float32\n",
      " 427  zz0378                        5710 non-null   float32\n",
      " 428  zz0379                        5710 non-null   float32\n",
      " 429  zz0380                        5710 non-null   float32\n",
      " 430  zz0381                        5710 non-null   float32\n",
      " 431  zz0382                        5710 non-null   float32\n",
      " 432  zz0383                        5710 non-null   float32\n",
      "dtypes: float32(430), int16(1), int32(1), int8(1)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "cols += em_cols\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b13fb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[cols].to_parquet(\"output/tra.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
